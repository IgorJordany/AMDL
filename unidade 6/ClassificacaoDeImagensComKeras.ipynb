{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVoQdqM0FHhl"
      },
      "source": [
        "## Importação de pacotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIZ72HXuE-Dl"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpI1CXZ9FKH2"
      },
      "source": [
        "## Carregamento da base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E98EoAxdFO8D"
      },
      "source": [
        "cifar = keras.datasets.cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ka1KqYKFRgN"
      },
      "source": [
        "sampleID = 7\n",
        "\n",
        "classe = y_train[sampleID][0]\n",
        "print('Classe:', labels[classe])\n",
        "\n",
        "plt.imshow(x_train[sampleID])\n",
        "plt.show()\n",
        "\n",
        "print(x_train[sampleID])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E6QOjsiFV-3"
      },
      "source": [
        "### Normalização"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVkEeDggFWwH"
      },
      "source": [
        "x_train  = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PICb9yaFYNz"
      },
      "source": [
        "for i in range(10):\n",
        "\n",
        "  classe = y_train[i][0]\n",
        "  print('Classe:', labels[classe])\n",
        "\n",
        "  plt.imshow(x_train[i])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIKVXwLHFZPh"
      },
      "source": [
        "## Construção e treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7x71O1WFbmU"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add( keras.layers.Flatten() )\n",
        "model.add( keras.layers.Dense( 128, activation=keras.activations.relu ) )\n",
        "model.add( keras.layers.Dense( 10, activation=keras.activations.softmax ) )\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(),\n",
        "              loss = keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_x745TYFc_z"
      },
      "source": [
        "hist = model.fit(x_train, y_train, validation_split=0.2, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "949Gr5ssFeNO"
      },
      "source": [
        "## Avaliando os resultados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrYxXlAEFgEM"
      },
      "source": [
        "# Accuracy\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1axCcVOFix4"
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9h32cC4FoI2"
      },
      "source": [
        "classifications = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "  classe = np.argmax(classifications[i])\n",
        "  if classe != y_test[i]:\n",
        "    print('Erro em', i)\n",
        "    print('Vetor de resultados:', classifications[i])\n",
        "    print('Era para ser', labels[int(y_test[i])], 'mas foi classificado como', labels[classe])\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "gi2DwhGiMbXk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
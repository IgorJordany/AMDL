{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dY7yOKvocMjz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "S5gz5OD_cXMy"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sl_no</th>\n",
              "      <th>gender</th>\n",
              "      <th>ssc_p</th>\n",
              "      <th>ssc_b</th>\n",
              "      <th>hsc_p</th>\n",
              "      <th>hsc_b</th>\n",
              "      <th>hsc_s</th>\n",
              "      <th>degree_p</th>\n",
              "      <th>degree_t</th>\n",
              "      <th>workex</th>\n",
              "      <th>etest_p</th>\n",
              "      <th>specialisation</th>\n",
              "      <th>mba_p</th>\n",
              "      <th>status</th>\n",
              "      <th>salary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>M</td>\n",
              "      <td>67.00</td>\n",
              "      <td>Others</td>\n",
              "      <td>91.00</td>\n",
              "      <td>Others</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>58.00</td>\n",
              "      <td>Sci&amp;Tech</td>\n",
              "      <td>No</td>\n",
              "      <td>55.0</td>\n",
              "      <td>Mkt&amp;HR</td>\n",
              "      <td>58.80</td>\n",
              "      <td>Placed</td>\n",
              "      <td>270000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>79.33</td>\n",
              "      <td>Central</td>\n",
              "      <td>78.33</td>\n",
              "      <td>Others</td>\n",
              "      <td>Science</td>\n",
              "      <td>77.48</td>\n",
              "      <td>Sci&amp;Tech</td>\n",
              "      <td>Yes</td>\n",
              "      <td>86.5</td>\n",
              "      <td>Mkt&amp;Fin</td>\n",
              "      <td>66.28</td>\n",
              "      <td>Placed</td>\n",
              "      <td>200000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>65.00</td>\n",
              "      <td>Central</td>\n",
              "      <td>68.00</td>\n",
              "      <td>Central</td>\n",
              "      <td>Arts</td>\n",
              "      <td>64.00</td>\n",
              "      <td>Comm&amp;Mgmt</td>\n",
              "      <td>No</td>\n",
              "      <td>75.0</td>\n",
              "      <td>Mkt&amp;Fin</td>\n",
              "      <td>57.80</td>\n",
              "      <td>Placed</td>\n",
              "      <td>250000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>56.00</td>\n",
              "      <td>Central</td>\n",
              "      <td>52.00</td>\n",
              "      <td>Central</td>\n",
              "      <td>Science</td>\n",
              "      <td>52.00</td>\n",
              "      <td>Sci&amp;Tech</td>\n",
              "      <td>No</td>\n",
              "      <td>66.0</td>\n",
              "      <td>Mkt&amp;HR</td>\n",
              "      <td>59.43</td>\n",
              "      <td>Not Placed</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>85.80</td>\n",
              "      <td>Central</td>\n",
              "      <td>73.60</td>\n",
              "      <td>Central</td>\n",
              "      <td>Commerce</td>\n",
              "      <td>73.30</td>\n",
              "      <td>Comm&amp;Mgmt</td>\n",
              "      <td>No</td>\n",
              "      <td>96.8</td>\n",
              "      <td>Mkt&amp;Fin</td>\n",
              "      <td>55.50</td>\n",
              "      <td>Placed</td>\n",
              "      <td>425000.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sl_no gender  ssc_p    ssc_b  hsc_p    hsc_b     hsc_s  degree_p  \\\n",
              "0      1      M  67.00   Others  91.00   Others  Commerce     58.00   \n",
              "1      2      M  79.33  Central  78.33   Others   Science     77.48   \n",
              "2      3      M  65.00  Central  68.00  Central      Arts     64.00   \n",
              "3      4      M  56.00  Central  52.00  Central   Science     52.00   \n",
              "4      5      M  85.80  Central  73.60  Central  Commerce     73.30   \n",
              "\n",
              "    degree_t workex  etest_p specialisation  mba_p      status    salary  \n",
              "0   Sci&Tech     No     55.0         Mkt&HR  58.80      Placed  270000.0  \n",
              "1   Sci&Tech    Yes     86.5        Mkt&Fin  66.28      Placed  200000.0  \n",
              "2  Comm&Mgmt     No     75.0        Mkt&Fin  57.80      Placed  250000.0  \n",
              "3   Sci&Tech     No     66.0         Mkt&HR  59.43  Not Placed       NaN  \n",
              "4  Comm&Mgmt     No     96.8        Mkt&Fin  55.50      Placed  425000.0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('../datas/emprego.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6W5Mr6MxrZjZ"
      },
      "outputs": [],
      "source": [
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fg51DUmycjUa"
      },
      "outputs": [],
      "source": [
        "x = df[['ssc_p', 'hsc_p', 'degree_p', 'etest_p', 'mba_p']]\n",
        "y = df['salary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5HIgQXP_cYHi"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PDIqIIHZcxRZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yb3wk7OdcyNC"
      },
      "outputs": [],
      "source": [
        "modelo = MLPRegressor(\n",
        "    hidden_layer_sizes=(10, 5),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    learning_rate='constant',\n",
        "    learning_rate_init=0.001,\n",
        "    max_iter=5000,\n",
        "    shuffle=True,\n",
        "    random_state=20,\n",
        "    validation_fraction=0.2,\n",
        "    verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "E41WHxcQc4Ay"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 43757781860.27662659\n",
            "Iteration 2, loss = 43757506452.55448914\n",
            "Iteration 3, loss = 43757230708.39151764\n",
            "Iteration 4, loss = 43756958715.01194763\n",
            "Iteration 5, loss = 43756689958.90249634\n",
            "Iteration 6, loss = 43756424003.23930359\n",
            "Iteration 7, loss = 43756160563.65511322\n",
            "Iteration 8, loss = 43755900387.16944885\n",
            "Iteration 9, loss = 43755641953.47584534\n",
            "Iteration 10, loss = 43755386092.88519287\n",
            "Iteration 11, loss = 43755130944.63081360\n",
            "Iteration 12, loss = 43754877064.11284637\n",
            "Iteration 13, loss = 43754624926.44934082\n",
            "Iteration 14, loss = 43754373297.13463593\n",
            "Iteration 15, loss = 43754121606.94623566\n",
            "Iteration 16, loss = 43753869891.39821625\n",
            "Iteration 17, loss = 43753618446.91934967\n",
            "Iteration 18, loss = 43753367286.43865967\n",
            "Iteration 19, loss = 43753116127.54254150\n",
            "Iteration 20, loss = 43752864551.07371521\n",
            "Iteration 21, loss = 43752612702.70769501\n",
            "Iteration 22, loss = 43752360657.42243195\n",
            "Iteration 23, loss = 43752108415.61581421\n",
            "Iteration 24, loss = 43751855726.07202911\n",
            "Iteration 25, loss = 43751602297.66141510\n",
            "Iteration 26, loss = 43751348037.53335571\n",
            "Iteration 27, loss = 43751092157.29359436\n",
            "Iteration 28, loss = 43750834621.76531219\n",
            "Iteration 29, loss = 43750575672.63311005\n",
            "Iteration 30, loss = 43750315742.89656067\n",
            "Iteration 31, loss = 43750053984.86491394\n",
            "Iteration 32, loss = 43749790096.65944672\n",
            "Iteration 33, loss = 43749524717.51993561\n",
            "Iteration 34, loss = 43749256984.48024750\n",
            "Iteration 35, loss = 43748986924.20204163\n",
            "Iteration 36, loss = 43748714108.86282349\n",
            "Iteration 37, loss = 43748438445.73454285\n",
            "Iteration 38, loss = 43748160464.76593018\n",
            "Iteration 39, loss = 43747879894.70209503\n",
            "Iteration 40, loss = 43747595323.63938904\n",
            "Iteration 41, loss = 43747308100.55062866\n",
            "Iteration 42, loss = 43747019088.24366760\n",
            "Iteration 43, loss = 43746727490.06147003\n",
            "Iteration 44, loss = 43746433316.24826813\n",
            "Iteration 45, loss = 43746135747.51660156\n",
            "Iteration 46, loss = 43745835724.58448792\n",
            "Iteration 47, loss = 43745531939.69398499\n",
            "Iteration 48, loss = 43745223378.07537842\n",
            "Iteration 49, loss = 43744911214.09205627\n",
            "Iteration 50, loss = 43744595483.02352905\n",
            "Iteration 51, loss = 43744275103.92469025\n",
            "Iteration 52, loss = 43743948998.97184753\n",
            "Iteration 53, loss = 43743618611.87687683\n",
            "Iteration 54, loss = 43743284612.30090332\n",
            "Iteration 55, loss = 43742947322.62032318\n",
            "Iteration 56, loss = 43742606142.91222382\n",
            "Iteration 57, loss = 43742260669.07720184\n",
            "Iteration 58, loss = 43741911390.12989044\n",
            "Iteration 59, loss = 43741558907.31185150\n",
            "Iteration 60, loss = 43741201612.73487091\n",
            "Iteration 61, loss = 43740840417.72406006\n",
            "Iteration 62, loss = 43740475559.41787720\n",
            "Iteration 63, loss = 43740107117.20472717\n",
            "Iteration 64, loss = 43739735400.74382019\n",
            "Iteration 65, loss = 43739360165.39285278\n",
            "Iteration 66, loss = 43738980018.32678986\n",
            "Iteration 67, loss = 43738596180.75582123\n",
            "Iteration 68, loss = 43738208768.74510193\n",
            "Iteration 69, loss = 43737817491.63335419\n",
            "Iteration 70, loss = 43737421884.22560120\n",
            "Iteration 71, loss = 43737021346.50152588\n",
            "Iteration 72, loss = 43736616385.30048370\n",
            "Iteration 73, loss = 43736207144.94828033\n",
            "Iteration 74, loss = 43735793347.70995331\n",
            "Iteration 75, loss = 43735374455.23299408\n",
            "Iteration 76, loss = 43734950621.04329681\n",
            "Iteration 77, loss = 43734521612.79777527\n",
            "Iteration 78, loss = 43734087480.18097687\n",
            "Iteration 79, loss = 43733648433.88541412\n",
            "Iteration 80, loss = 43733204001.60964203\n",
            "Iteration 81, loss = 43732754445.39961243\n",
            "Iteration 82, loss = 43732299635.84915161\n",
            "Iteration 83, loss = 43731838692.69712067\n",
            "Iteration 84, loss = 43731372083.61840820\n",
            "Iteration 85, loss = 43730900057.06171417\n",
            "Iteration 86, loss = 43730421977.25368500\n",
            "Iteration 87, loss = 43729936795.69805145\n",
            "Iteration 88, loss = 43729446211.69676208\n",
            "Iteration 89, loss = 43728950279.87617493\n",
            "Iteration 90, loss = 43728448821.22306061\n",
            "Iteration 91, loss = 43727941910.66133118\n",
            "Iteration 92, loss = 43727433718.73149872\n",
            "Iteration 93, loss = 43726924767.09661102\n",
            "Iteration 94, loss = 43726415710.75549316\n",
            "Iteration 95, loss = 43725909042.12833405\n",
            "Iteration 96, loss = 43725411952.76815796\n",
            "Iteration 97, loss = 43724925901.63210297\n",
            "Iteration 98, loss = 43724451197.49642181\n",
            "Iteration 99, loss = 43723986421.05533600\n",
            "Iteration 100, loss = 43723528503.72566986\n",
            "Iteration 101, loss = 43723075986.63561249\n",
            "Iteration 102, loss = 43722626118.68225098\n",
            "Iteration 103, loss = 43722179609.00805664\n",
            "Iteration 104, loss = 43721734233.44270325\n",
            "Iteration 105, loss = 43721290742.93630219\n",
            "Iteration 106, loss = 43720846422.50646973\n",
            "Iteration 107, loss = 43720399643.25226593\n",
            "Iteration 108, loss = 43719950542.67785645\n",
            "Iteration 109, loss = 43719499434.85807037\n",
            "Iteration 110, loss = 43719047151.42803192\n",
            "Iteration 111, loss = 43718592816.79570007\n",
            "Iteration 112, loss = 43718136313.39566803\n",
            "Iteration 113, loss = 43717678023.02313995\n",
            "Iteration 114, loss = 43717217779.29656219\n",
            "Iteration 115, loss = 43716755743.36678314\n",
            "Iteration 116, loss = 43716291947.59861755\n",
            "Iteration 117, loss = 43715826295.37052155\n",
            "Iteration 118, loss = 43715358616.23212433\n",
            "Iteration 119, loss = 43714888890.69425201\n",
            "Iteration 120, loss = 43714417089.51997375\n",
            "Iteration 121, loss = 43713943183.76957703\n",
            "Iteration 122, loss = 43713467392.44024658\n",
            "Iteration 123, loss = 43712989793.16791534\n",
            "Iteration 124, loss = 43712510485.65540314\n",
            "Iteration 125, loss = 43712029724.35000610\n",
            "Iteration 126, loss = 43711547433.38336182\n",
            "Iteration 127, loss = 43711063415.31168365\n",
            "Iteration 128, loss = 43710577823.02937317\n",
            "Iteration 129, loss = 43710091142.49718475\n",
            "Iteration 130, loss = 43709602539.51547241\n",
            "Iteration 131, loss = 43709111886.03302002\n",
            "Iteration 132, loss = 43708619593.83434296\n",
            "Iteration 133, loss = 43708125660.24694061\n",
            "Iteration 134, loss = 43707630022.27585602\n",
            "Iteration 135, loss = 43707133209.31799316\n",
            "Iteration 136, loss = 43706634679.41979218\n",
            "Iteration 137, loss = 43706134175.62366486\n",
            "Iteration 138, loss = 43705631105.06716156\n",
            "Iteration 139, loss = 43705125415.99311829\n",
            "Iteration 140, loss = 43704617433.47891998\n",
            "Iteration 141, loss = 43704107200.81241608\n",
            "Iteration 142, loss = 43703595562.50058746\n",
            "Iteration 143, loss = 43703081990.97501373\n",
            "Iteration 144, loss = 43702565984.54605103\n",
            "Iteration 145, loss = 43702047637.63551331\n",
            "Iteration 146, loss = 43701527125.12734222\n",
            "Iteration 147, loss = 43701003529.56585693\n",
            "Iteration 148, loss = 43700477212.74167633\n",
            "Iteration 149, loss = 43699948482.80078125\n",
            "Iteration 150, loss = 43699416531.74972534\n",
            "Iteration 151, loss = 43698881406.33807373\n",
            "Iteration 152, loss = 43698343443.36790466\n",
            "Iteration 153, loss = 43697802461.06517029\n",
            "Iteration 154, loss = 43697258161.12233734\n",
            "Iteration 155, loss = 43696710722.43208313\n",
            "Iteration 156, loss = 43696159642.16175079\n",
            "Iteration 157, loss = 43695605131.58937836\n",
            "Iteration 158, loss = 43695047445.75364685\n",
            "Iteration 159, loss = 43694486200.05273438\n",
            "Iteration 160, loss = 43693921234.79766083\n",
            "Iteration 161, loss = 43693352466.06964874\n",
            "Iteration 162, loss = 43692779906.81262970\n",
            "Iteration 163, loss = 43692203367.34735107\n",
            "Iteration 164, loss = 43691622863.64583588\n",
            "Iteration 165, loss = 43691038267.93601990\n",
            "Iteration 166, loss = 43690449486.97946167\n",
            "Iteration 167, loss = 43689856618.39339447\n",
            "Iteration 168, loss = 43689259777.00978088\n",
            "Iteration 169, loss = 43688658799.88231659\n",
            "Iteration 170, loss = 43688053624.41349030\n",
            "Iteration 171, loss = 43687444262.69602966\n",
            "Iteration 172, loss = 43686830651.32661438\n",
            "Iteration 173, loss = 43686212683.72910309\n",
            "Iteration 174, loss = 43685590280.86547852\n",
            "Iteration 175, loss = 43684963436.03866577\n",
            "Iteration 176, loss = 43684332040.09655762\n",
            "Iteration 177, loss = 43683695926.47652435\n",
            "Iteration 178, loss = 43683055171.58770752\n",
            "Iteration 179, loss = 43682409732.27830505\n",
            "Iteration 180, loss = 43681759534.56766510\n",
            "Iteration 181, loss = 43681104524.09440613\n",
            "Iteration 182, loss = 43680444708.90888214\n",
            "Iteration 183, loss = 43679780012.34617615\n",
            "Iteration 184, loss = 43679110381.76509094\n",
            "Iteration 185, loss = 43678435776.76039124\n",
            "Iteration 186, loss = 43677756157.26425171\n",
            "Iteration 187, loss = 43677071502.05288696\n",
            "Iteration 188, loss = 43676381729.28622437\n",
            "Iteration 189, loss = 43675686840.08713531\n",
            "Iteration 190, loss = 43674986777.15102386\n",
            "Iteration 191, loss = 43674281511.34007263\n",
            "Iteration 192, loss = 43673571079.86487579\n",
            "Iteration 193, loss = 43672855446.89173126\n",
            "Iteration 194, loss = 43672134524.61886597\n",
            "Iteration 195, loss = 43671408243.93065643\n",
            "Iteration 196, loss = 43670676566.52534485\n",
            "Iteration 197, loss = 43669939454.22870636\n",
            "Iteration 198, loss = 43669196868.97814941\n",
            "Iteration 199, loss = 43668448772.80778503\n",
            "Iteration 200, loss = 43667695127.83476257\n",
            "Iteration 201, loss = 43666935896.24659729\n",
            "Iteration 202, loss = 43666171148.67643738\n",
            "Iteration 203, loss = 43665400591.42950439\n",
            "Iteration 204, loss = 43664624417.63187408\n",
            "Iteration 205, loss = 43663842506.14675140\n",
            "Iteration 206, loss = 43663054819.46092987\n",
            "Iteration 207, loss = 43662261320.06031036\n",
            "Iteration 208, loss = 43661461970.42488861\n",
            "Iteration 209, loss = 43660656733.02380371\n",
            "Iteration 210, loss = 43659845570.31121063\n",
            "Iteration 211, loss = 43659028444.72223663\n",
            "Iteration 212, loss = 43658205318.66973114\n",
            "Iteration 213, loss = 43657376154.54101562\n",
            "Iteration 214, loss = 43656540914.69542694\n",
            "Iteration 215, loss = 43655699561.46186066\n",
            "Iteration 216, loss = 43654852057.13701630\n",
            "Iteration 217, loss = 43653998363.98383331\n",
            "Iteration 218, loss = 43653138444.23028564\n",
            "Iteration 219, loss = 43652272260.06855011\n",
            "Iteration 220, loss = 43651399773.65448761\n",
            "Iteration 221, loss = 43650520962.52890015\n",
            "Iteration 222, loss = 43649635806.14894104\n",
            "Iteration 223, loss = 43648744236.33281708\n",
            "Iteration 224, loss = 43647846240.21298218\n",
            "Iteration 225, loss = 43646941708.28730011\n",
            "Iteration 226, loss = 43646030672.43413544\n",
            "Iteration 227, loss = 43645113069.28421783\n",
            "Iteration 228, loss = 43644188860.73513031\n",
            "Iteration 229, loss = 43643258008.65131378\n",
            "Iteration 230, loss = 43642320474.86669159\n",
            "Iteration 231, loss = 43641376234.46125031\n",
            "Iteration 232, loss = 43640425246.29539490\n",
            "Iteration 233, loss = 43639467462.66613770\n",
            "Iteration 234, loss = 43638502845.25919342\n",
            "Iteration 235, loss = 43637531355.75117493\n",
            "Iteration 236, loss = 43636552955.81231689\n",
            "Iteration 237, loss = 43635567607.10939026\n",
            "Iteration 238, loss = 43634575271.30872345\n",
            "Iteration 239, loss = 43633575910.07914734\n",
            "Iteration 240, loss = 43632569485.09533691\n",
            "Iteration 241, loss = 43631555958.04094696\n",
            "Iteration 242, loss = 43630535290.61198425\n",
            "Iteration 243, loss = 43629507444.52014923\n",
            "Iteration 244, loss = 43628472381.49624634\n",
            "Iteration 245, loss = 43627430063.29367065\n",
            "Iteration 246, loss = 43626380451.69190216\n",
            "Iteration 247, loss = 43625323508.49993134\n",
            "Iteration 248, loss = 43624259195.55983734\n",
            "Iteration 249, loss = 43623187474.75024414\n",
            "Iteration 250, loss = 43622108307.98992920\n",
            "Iteration 251, loss = 43621021657.24108124\n",
            "Iteration 252, loss = 43619927484.51302338\n",
            "Iteration 253, loss = 43618825751.86542511\n",
            "Iteration 254, loss = 43617716421.41179657\n",
            "Iteration 255, loss = 43616599455.32274628\n",
            "Iteration 256, loss = 43615474815.82939911\n",
            "Iteration 257, loss = 43614342465.22641754\n",
            "Iteration 258, loss = 43613202365.87535095\n",
            "Iteration 259, loss = 43612054480.20761108\n",
            "Iteration 260, loss = 43610898770.72755432\n",
            "Iteration 261, loss = 43609735200.01535034\n",
            "Iteration 262, loss = 43608563730.72993469\n",
            "Iteration 263, loss = 43607384325.61175537\n",
            "Iteration 264, loss = 43606196947.48536682\n",
            "Iteration 265, loss = 43605001559.26222992\n",
            "Iteration 266, loss = 43603798123.94303131\n",
            "Iteration 267, loss = 43602586604.62016296\n",
            "Iteration 268, loss = 43601366964.48015594\n",
            "Iteration 269, loss = 43600139166.80574036\n",
            "Iteration 270, loss = 43598903174.97808838\n",
            "Iteration 271, loss = 43597658952.47886658\n",
            "Iteration 272, loss = 43596406462.89208221\n",
            "Iteration 273, loss = 43595145669.90608978\n",
            "Iteration 274, loss = 43593876537.31513214\n",
            "Iteration 275, loss = 43592599029.02126312\n",
            "Iteration 276, loss = 43591313109.03569031\n",
            "Iteration 277, loss = 43590018741.48034668\n",
            "Iteration 278, loss = 43588715890.58933258\n",
            "Iteration 279, loss = 43587404520.71009064\n",
            "Iteration 280, loss = 43586084596.30474091\n",
            "Iteration 281, loss = 43584756081.95110321\n",
            "Iteration 282, loss = 43583418942.34375000\n",
            "Iteration 283, loss = 43582073142.29505157\n",
            "Iteration 284, loss = 43580718646.73596954\n",
            "Iteration 285, loss = 43579355420.71684265\n",
            "Iteration 286, loss = 43577983429.40812683\n",
            "Iteration 287, loss = 43576602638.10112000\n",
            "Iteration 288, loss = 43575213012.20836639\n",
            "Iteration 289, loss = 43573814517.26434326\n",
            "Iteration 290, loss = 43572407118.92578125\n",
            "Iteration 291, loss = 43570990782.97200012\n",
            "Iteration 292, loss = 43569565475.30535889\n",
            "Iteration 293, loss = 43568131161.95133209\n",
            "Iteration 294, loss = 43566687809.05879211\n",
            "Iteration 295, loss = 43565235382.90013123\n",
            "Iteration 296, loss = 43563773849.87124634\n",
            "Iteration 297, loss = 43562303176.49168396\n",
            "Iteration 298, loss = 43560823329.40445709\n",
            "Iteration 299, loss = 43559334275.37605286\n",
            "Iteration 300, loss = 43557835981.29630280\n",
            "Iteration 301, loss = 43556328414.17813110\n",
            "Iteration 302, loss = 43554811541.15739441\n",
            "Iteration 303, loss = 43553285329.49258423\n",
            "Iteration 304, loss = 43551749746.56452942\n",
            "Iteration 305, loss = 43550204759.87602997\n",
            "Iteration 306, loss = 43548650337.05153656\n",
            "Iteration 307, loss = 43547086445.83663940\n",
            "Iteration 308, loss = 43545513054.09769440\n",
            "Iteration 309, loss = 43543930129.82130432\n",
            "Iteration 310, loss = 43542337641.11383057\n",
            "Iteration 311, loss = 43540735556.20082092\n",
            "Iteration 312, loss = 43539123843.42642975\n",
            "Iteration 313, loss = 43537502471.25291443\n",
            "Iteration 314, loss = 43535871408.25988770\n",
            "Iteration 315, loss = 43534230623.14381409\n",
            "Iteration 316, loss = 43532580084.71719360\n",
            "Iteration 317, loss = 43530919761.90801239\n",
            "Iteration 318, loss = 43529249623.75898743\n",
            "Iteration 319, loss = 43527569639.42684937\n",
            "Iteration 320, loss = 43525879778.18155670\n",
            "Iteration 321, loss = 43524180009.40566254\n",
            "Iteration 322, loss = 43522470302.59344482\n",
            "Iteration 323, loss = 43520750627.35018921\n",
            "Iteration 324, loss = 43519020953.39132690\n",
            "Iteration 325, loss = 43517281250.54172516\n",
            "Iteration 326, loss = 43515531488.73480988\n",
            "Iteration 327, loss = 43513771638.01177216\n",
            "Iteration 328, loss = 43512001668.52078247\n",
            "Iteration 329, loss = 43510221550.51602936\n",
            "Iteration 330, loss = 43508431254.35701752\n",
            "Iteration 331, loss = 43506630750.50762939\n",
            "Iteration 332, loss = 43504820009.53532410\n",
            "Iteration 333, loss = 43502999002.11030579\n",
            "Iteration 334, loss = 43501167699.00457001\n",
            "Iteration 335, loss = 43499326071.09112549\n",
            "Iteration 336, loss = 43497474089.34310150\n",
            "Iteration 337, loss = 43495611724.83293915\n",
            "Iteration 338, loss = 43493738948.73144531\n",
            "Iteration 339, loss = 43491855732.30696869\n",
            "Iteration 340, loss = 43489962046.92460632\n",
            "Iteration 341, loss = 43488057864.04521942\n",
            "Iteration 342, loss = 43486143155.22466278\n",
            "Iteration 343, loss = 43484217892.11296082\n",
            "Iteration 344, loss = 43482282046.45335388\n",
            "Iteration 345, loss = 43480335590.08148956\n",
            "Iteration 346, loss = 43478378494.92473602\n",
            "Iteration 347, loss = 43476410733.00105286\n",
            "Iteration 348, loss = 43474432276.41841125\n",
            "Iteration 349, loss = 43472443097.37390900\n",
            "Iteration 350, loss = 43470443168.15282440\n",
            "Iteration 351, loss = 43468432461.12797546\n",
            "Iteration 352, loss = 43466410948.75883484\n",
            "Iteration 353, loss = 43464378603.59069824\n",
            "Iteration 354, loss = 43462335398.25395203\n",
            "Iteration 355, loss = 43460281305.46331787\n",
            "Iteration 356, loss = 43458216298.01692963\n",
            "Iteration 357, loss = 43456140348.79575348\n",
            "Iteration 358, loss = 43454053430.76270294\n",
            "Iteration 359, loss = 43451955516.96191406\n",
            "Iteration 360, loss = 43449846580.51802063\n",
            "Iteration 361, loss = 43447726594.63543701\n",
            "Iteration 362, loss = 43445595532.59757233\n",
            "Iteration 363, loss = 43443453367.76616669\n",
            "Iteration 364, loss = 43441300073.58059692\n",
            "Iteration 365, loss = 43439135623.55712128\n",
            "Iteration 366, loss = 43436959991.28824615\n",
            "Iteration 367, loss = 43434773150.44202423\n",
            "Iteration 368, loss = 43432575074.76140594\n",
            "Iteration 369, loss = 43430365738.06352997\n",
            "Iteration 370, loss = 43428145114.23920441\n",
            "Iteration 371, loss = 43425913177.25203705\n",
            "Iteration 372, loss = 43423669901.13809967\n",
            "Iteration 373, loss = 43421415260.00508881\n",
            "Iteration 374, loss = 43419149228.03176880\n",
            "Iteration 375, loss = 43416871779.46744537\n",
            "Iteration 376, loss = 43414582888.63128662\n",
            "Iteration 377, loss = 43412282529.91179657\n",
            "Iteration 378, loss = 43409970677.76627350\n",
            "Iteration 379, loss = 43407647306.72016144\n",
            "Iteration 380, loss = 43405312391.36660004\n",
            "Iteration 381, loss = 43402965906.36580658\n",
            "Iteration 382, loss = 43400607826.44460297\n",
            "Iteration 383, loss = 43398238126.39585876\n",
            "Iteration 384, loss = 43395856781.07799530\n",
            "Iteration 385, loss = 43393463765.41454315\n",
            "Iteration 386, loss = 43391059054.39348602\n",
            "Iteration 387, loss = 43388642623.06703186\n",
            "Iteration 388, loss = 43386214446.55089569\n",
            "Iteration 389, loss = 43383774500.02394867\n",
            "Iteration 390, loss = 43381322758.72784424\n",
            "Iteration 391, loss = 43378859197.96636963\n",
            "Iteration 392, loss = 43376383793.10522461\n",
            "Iteration 393, loss = 43373896519.57144928\n",
            "Iteration 394, loss = 43371397352.85308838\n",
            "Iteration 395, loss = 43368886268.49869537\n",
            "Iteration 396, loss = 43366363242.11703491\n",
            "Iteration 397, loss = 43363828249.37664032\n",
            "Iteration 398, loss = 43361281266.00543213\n",
            "Iteration 399, loss = 43358722267.79032135\n",
            "Iteration 400, loss = 43356151230.57686615\n",
            "Iteration 401, loss = 43353568130.26895905\n",
            "Iteration 402, loss = 43350972942.82838440\n",
            "Iteration 403, loss = 43348365644.27448273\n",
            "Iteration 404, loss = 43345746210.68393707\n",
            "Iteration 405, loss = 43343114618.19029999\n",
            "Iteration 406, loss = 43340470842.98372650\n",
            "Iteration 407, loss = 43337814861.31070709\n",
            "Iteration 408, loss = 43335146649.47366333\n",
            "Iteration 409, loss = 43332466183.83072662\n",
            "Iteration 410, loss = 43329773440.79544067\n",
            "Iteration 411, loss = 43327068396.83641052\n",
            "Iteration 412, loss = 43324351028.47713470\n",
            "Iteration 413, loss = 43321621312.29559326\n",
            "Iteration 414, loss = 43318879224.92408752\n",
            "Iteration 415, loss = 43316124743.04895782\n",
            "Iteration 416, loss = 43313357843.41032410\n",
            "Iteration 417, loss = 43310578502.80181122\n",
            "Iteration 418, loss = 43307786698.07032776\n",
            "Iteration 419, loss = 43304982406.11590576\n",
            "Iteration 420, loss = 43302165603.89127350\n",
            "Iteration 421, loss = 43299336268.40184021\n",
            "Iteration 422, loss = 43296494376.70537567\n",
            "Iteration 423, loss = 43293639905.91182709\n",
            "Iteration 424, loss = 43290772833.18309784\n",
            "Iteration 425, loss = 43287893135.73278809\n",
            "Iteration 426, loss = 43285000790.82615662\n",
            "Iteration 427, loss = 43282095775.77973175\n",
            "Iteration 428, loss = 43279178067.96129608\n",
            "Iteration 429, loss = 43276247644.78955841\n",
            "Iteration 430, loss = 43273304483.73406982\n",
            "Iteration 431, loss = 43270348562.31506348\n",
            "Iteration 432, loss = 43267379858.10317230\n",
            "Iteration 433, loss = 43264398348.71939850\n",
            "Iteration 434, loss = 43261404011.83486938\n",
            "Iteration 435, loss = 43258396825.17070770\n",
            "Iteration 436, loss = 43255376766.49787903\n",
            "Iteration 437, loss = 43252343813.63703918\n",
            "Iteration 438, loss = 43249297944.45837402\n",
            "Iteration 439, loss = 43246239136.88153076\n",
            "Iteration 440, loss = 43243167368.87538147\n",
            "Iteration 441, loss = 43240082618.45795441\n",
            "Iteration 442, loss = 43236984863.69627380\n",
            "Iteration 443, loss = 43233874082.70629120\n",
            "Iteration 444, loss = 43230750253.65267181\n",
            "Iteration 445, loss = 43227613354.74879456\n",
            "Iteration 446, loss = 43224463364.25646973\n",
            "Iteration 447, loss = 43221300260.48603058\n",
            "Iteration 448, loss = 43218124021.79605865\n",
            "Iteration 449, loss = 43214934626.59334564\n",
            "Iteration 450, loss = 43211732053.33278656\n",
            "Iteration 451, loss = 43208516280.51729584\n",
            "Iteration 452, loss = 43205287286.69768524\n",
            "Iteration 453, loss = 43202045050.47256470\n",
            "Iteration 454, loss = 43198789550.48826599\n",
            "Iteration 455, loss = 43195520765.43875885\n",
            "Iteration 456, loss = 43192238674.06557465\n",
            "Iteration 457, loss = 43188943255.15766144\n",
            "Iteration 458, loss = 43185634487.55137634\n",
            "Iteration 459, loss = 43182312350.13037872\n",
            "Iteration 460, loss = 43178976821.82556152\n",
            "Iteration 461, loss = 43175627881.61492920\n",
            "Iteration 462, loss = 43172265508.52362061\n",
            "Iteration 463, loss = 43168889681.62372589\n",
            "Iteration 464, loss = 43165500380.03430939\n",
            "Iteration 465, loss = 43162097582.92133331\n",
            "Iteration 466, loss = 43158681269.49754333\n",
            "Iteration 467, loss = 43155251419.02244568\n",
            "Iteration 468, loss = 43151808010.80221558\n",
            "Iteration 469, loss = 43148351024.18973541\n",
            "Iteration 470, loss = 43144880438.58438873\n",
            "Iteration 471, loss = 43141396233.43215942\n",
            "Iteration 472, loss = 43137898388.22543335\n",
            "Iteration 473, loss = 43134386882.50305939\n",
            "Iteration 474, loss = 43130861695.85028839\n",
            "Iteration 475, loss = 43127322807.89868164\n",
            "Iteration 476, loss = 43123770198.32604218\n",
            "Iteration 477, loss = 43120203846.85647583\n",
            "Iteration 478, loss = 43116623733.26027679\n",
            "Iteration 479, loss = 43113029837.35385895\n",
            "Iteration 480, loss = 43109422138.99980927\n",
            "Iteration 481, loss = 43105800651.09979248\n",
            "Iteration 482, loss = 43102165325.57223511\n",
            "Iteration 483, loss = 43098516139.31041718\n",
            "Iteration 484, loss = 43094853072.21353912\n",
            "Iteration 485, loss = 43091176104.24134064\n",
            "Iteration 486, loss = 43087485215.41260529\n",
            "Iteration 487, loss = 43083780385.80393219\n",
            "Iteration 488, loss = 43080061595.54840088\n",
            "Iteration 489, loss = 43076328824.83459473\n",
            "Iteration 490, loss = 43072582053.90561676\n",
            "Iteration 491, loss = 43068821263.05813599\n",
            "Iteration 492, loss = 43065046432.64164734\n",
            "Iteration 493, loss = 43061257543.05774689\n",
            "Iteration 494, loss = 43057454574.75943756\n",
            "Iteration 495, loss = 43053637508.25063324\n",
            "Iteration 496, loss = 43049806324.08554840\n",
            "Iteration 497, loss = 43045961002.86820984\n",
            "Iteration 498, loss = 43042101525.25209808\n",
            "Iteration 499, loss = 43038227871.93971252\n",
            "Iteration 500, loss = 43034340023.68217468\n",
            "Iteration 501, loss = 43030437961.27899933\n",
            "Iteration 502, loss = 43026521665.57778168\n",
            "Iteration 503, loss = 43022591117.47383118\n",
            "Iteration 504, loss = 43018646297.91008759\n",
            "Iteration 505, loss = 43014687187.87683868\n",
            "Iteration 506, loss = 43010713768.41146088\n",
            "Iteration 507, loss = 43006726020.59844208\n",
            "Iteration 508, loss = 43002723925.56896973\n",
            "Iteration 509, loss = 42998707464.50097656\n",
            "Iteration 510, loss = 42994676618.61891174\n",
            "Iteration 511, loss = 42990631369.19372559\n",
            "Iteration 512, loss = 42986571697.54264069\n",
            "Iteration 513, loss = 42982497585.02916718\n",
            "Iteration 514, loss = 42978409013.06293488\n",
            "Iteration 515, loss = 42974305963.09965515\n",
            "Iteration 516, loss = 42970188416.64104462\n",
            "Iteration 517, loss = 42966056355.23479462\n",
            "Iteration 518, loss = 42961909760.47447968\n",
            "Iteration 519, loss = 42957748613.99942780\n",
            "Iteration 520, loss = 42953572897.49488831\n",
            "Iteration 521, loss = 42949382592.69177246\n",
            "Iteration 522, loss = 42945177681.36676788\n",
            "Iteration 523, loss = 42940958145.34215546\n",
            "Iteration 524, loss = 42936723966.48594666\n",
            "Iteration 525, loss = 42932475126.71176147\n",
            "Iteration 526, loss = 42928211607.97881317\n",
            "Iteration 527, loss = 42923933392.29187775\n",
            "Iteration 528, loss = 42919640461.70131683\n",
            "Iteration 529, loss = 42915332798.30306244\n",
            "Iteration 530, loss = 42911010384.23854065\n",
            "Iteration 531, loss = 42906673201.69467926\n",
            "Iteration 532, loss = 42902321232.90401459\n",
            "Iteration 533, loss = 42897954460.14447784\n",
            "Iteration 534, loss = 42893572865.73955536\n",
            "Iteration 535, loss = 42889176432.05822754\n",
            "Iteration 536, loss = 42884765141.51490784\n",
            "Iteration 537, loss = 42880338976.56951904\n",
            "Iteration 538, loss = 42875897919.72748566\n",
            "Iteration 539, loss = 42871441953.53965759\n",
            "Iteration 540, loss = 42866971060.60242462\n",
            "Iteration 541, loss = 42862485223.55760193\n",
            "Iteration 542, loss = 42857984425.09249115\n",
            "Iteration 543, loss = 42853468647.93989563\n",
            "Iteration 544, loss = 42848937874.87805939\n",
            "Iteration 545, loss = 42844392088.73071289\n",
            "Iteration 546, loss = 42839831272.36709595\n",
            "Iteration 547, loss = 42835255408.70195007\n",
            "Iteration 548, loss = 42830664480.69544220\n",
            "Iteration 549, loss = 42826058471.35334778\n",
            "Iteration 550, loss = 42821437363.72682190\n",
            "Iteration 551, loss = 42816801140.91260529\n",
            "Iteration 552, loss = 42812149786.05295563\n",
            "Iteration 553, loss = 42807483282.33559418\n",
            "Iteration 554, loss = 42802801612.99383545\n",
            "Iteration 555, loss = 42798104761.30648041\n",
            "Iteration 556, loss = 42793392710.59791565\n",
            "Iteration 557, loss = 42788665444.23802185\n",
            "Iteration 558, loss = 42783922945.64229584\n",
            "Iteration 559, loss = 42779165198.27174377\n",
            "Iteration 560, loss = 42774392185.63300323\n",
            "Iteration 561, loss = 42769603891.27825165\n",
            "Iteration 562, loss = 42764800298.80525970\n",
            "Iteration 563, loss = 42759981391.85741425\n",
            "Iteration 564, loss = 42755147154.12372589\n",
            "Iteration 565, loss = 42750297569.33877563\n",
            "Iteration 566, loss = 42745432621.28280640\n",
            "Iteration 567, loss = 42740552293.78170776\n",
            "Iteration 568, loss = 42735656570.70697784\n",
            "Iteration 569, loss = 42730745435.97580719\n",
            "Iteration 570, loss = 42725818873.55104828\n",
            "Iteration 571, loss = 42720876867.44122314\n",
            "Iteration 572, loss = 42715919401.70054626\n",
            "Iteration 573, loss = 42710946460.42893219\n",
            "Iteration 574, loss = 42705958027.77198792\n",
            "Iteration 575, loss = 42700954087.92108154\n",
            "Iteration 576, loss = 42695934625.11327362\n",
            "Iteration 577, loss = 42690899623.63140106\n",
            "Iteration 578, loss = 42685849067.80400085\n",
            "Iteration 579, loss = 42680782942.00546265\n",
            "Iteration 580, loss = 42675701230.65586090\n",
            "Iteration 581, loss = 42670603918.22111511\n",
            "Iteration 582, loss = 42665490989.21292877\n",
            "Iteration 583, loss = 42660362428.18881226\n",
            "Iteration 584, loss = 42655218219.75211334\n",
            "Iteration 585, loss = 42650058348.55200958\n",
            "Iteration 586, loss = 42644882799.28349304\n",
            "Iteration 587, loss = 42639691556.68749237\n",
            "Iteration 588, loss = 42634484605.55070496\n",
            "Iteration 589, loss = 42629261930.70581818\n",
            "Iteration 590, loss = 42624023517.03132629\n",
            "Iteration 591, loss = 42618769349.45168304\n",
            "Iteration 592, loss = 42613499412.93724823\n",
            "Iteration 593, loss = 42608213692.50431061\n",
            "Iteration 594, loss = 42602912173.21509552\n",
            "Iteration 595, loss = 42597594840.17782593\n",
            "Iteration 596, loss = 42592261678.54663849\n",
            "Iteration 597, loss = 42586912673.52169037\n",
            "Iteration 598, loss = 42581547810.34912109\n",
            "Iteration 599, loss = 42576167074.32109833\n",
            "Iteration 600, loss = 42570770450.77577972\n",
            "Iteration 601, loss = 42565357925.09736633\n",
            "Iteration 602, loss = 42559929482.71611023\n",
            "Iteration 603, loss = 42554485109.10832977\n",
            "Iteration 604, loss = 42549024789.79640961\n",
            "Iteration 605, loss = 42543548510.34880829\n",
            "Iteration 606, loss = 42538056256.38008881\n",
            "Iteration 607, loss = 42532548013.55094910\n",
            "Iteration 608, loss = 42527023767.56818390\n",
            "Iteration 609, loss = 42521483504.18470764\n",
            "Iteration 610, loss = 42515927209.19961548\n",
            "Iteration 611, loss = 42510354868.45817566\n",
            "Iteration 612, loss = 42504766467.85181427\n",
            "Iteration 613, loss = 42499161993.31813812\n",
            "Iteration 614, loss = 42493541430.84097290\n",
            "Iteration 615, loss = 42487904766.45034790\n",
            "Iteration 616, loss = 42482251986.22252655\n",
            "Iteration 617, loss = 42476583076.28001404\n",
            "Iteration 618, loss = 42470898022.79158020\n",
            "Iteration 619, loss = 42465196811.97225952\n",
            "Iteration 620, loss = 42459479430.08333588\n",
            "Iteration 621, loss = 42453745863.43243408\n",
            "Iteration 622, loss = 42447996098.37346649\n",
            "Iteration 623, loss = 42442230121.30666351\n",
            "Iteration 624, loss = 42436447918.67860413\n",
            "Iteration 625, loss = 42430649476.98218536\n",
            "Iteration 626, loss = 42424834782.75670624\n",
            "Iteration 627, loss = 42419003822.58782196\n",
            "Iteration 628, loss = 42413156583.10753632\n",
            "Iteration 629, loss = 42407293050.99432373\n",
            "Iteration 630, loss = 42401413212.97305298\n",
            "Iteration 631, loss = 42395517055.81496429\n",
            "Iteration 632, loss = 42389604566.33779144\n",
            "Iteration 633, loss = 42383675731.40573883\n",
            "Iteration 634, loss = 42377730537.92941284\n",
            "Iteration 635, loss = 42371768972.86595154\n",
            "Iteration 636, loss = 42365791023.21897125\n",
            "Iteration 637, loss = 42359796676.03858948\n",
            "Iteration 638, loss = 42353785918.42145538\n",
            "Iteration 639, loss = 42347758737.51074219\n",
            "Iteration 640, loss = 42341715120.49616241\n",
            "Iteration 641, loss = 42335655054.61401367\n",
            "Iteration 642, loss = 42329578527.14712524\n",
            "Iteration 643, loss = 42323485525.42495728\n",
            "Iteration 644, loss = 42317376036.82352448\n",
            "Iteration 645, loss = 42311250048.76549530\n",
            "Iteration 646, loss = 42305107548.72013092\n",
            "Iteration 647, loss = 42298948524.20333099\n",
            "Iteration 648, loss = 42292772962.77767181\n",
            "Iteration 649, loss = 42286580852.05239105\n",
            "Iteration 650, loss = 42280372179.68335724\n",
            "Iteration 651, loss = 42274146933.37317657\n",
            "Iteration 652, loss = 42267905115.35179138\n",
            "Iteration 653, loss = 42261646718.74754333\n",
            "Iteration 654, loss = 42255371711.73474884\n",
            "Iteration 655, loss = 42249080082.20588684\n",
            "Iteration 656, loss = 42242771818.09993744\n",
            "Iteration 657, loss = 42236446907.40237427\n",
            "Iteration 658, loss = 42230105338.14517212\n",
            "Iteration 659, loss = 42223747098.40692139\n",
            "Iteration 660, loss = 42217372176.31284332\n",
            "Iteration 661, loss = 42210980560.03476715\n",
            "Iteration 662, loss = 42204572237.79125214\n",
            "Iteration 663, loss = 42198147197.84750366\n",
            "Iteration 664, loss = 42191705428.51551056\n",
            "Iteration 665, loss = 42185246918.15400696\n",
            "Iteration 666, loss = 42178771655.16847992\n",
            "Iteration 667, loss = 42172279628.01125336\n",
            "Iteration 668, loss = 42165770825.18148041\n",
            "Iteration 669, loss = 42159245235.22514343\n",
            "Iteration 670, loss = 42152702846.73509979\n",
            "Iteration 671, loss = 42146143648.35107422\n",
            "Iteration 672, loss = 42139567628.75976562\n",
            "Iteration 673, loss = 42132974776.69468689\n",
            "Iteration 674, loss = 42126365080.93637848\n",
            "Iteration 675, loss = 42119738530.31229401\n",
            "Iteration 676, loss = 42113095113.69688416\n",
            "Iteration 677, loss = 42106434820.01155853\n",
            "Iteration 678, loss = 42099757638.22476196\n",
            "Iteration 679, loss = 42093063557.35191345\n",
            "Iteration 680, loss = 42086352566.45550537\n",
            "Iteration 681, loss = 42079624654.64507294\n",
            "Iteration 682, loss = 42072879811.07719421\n",
            "Iteration 683, loss = 42066118024.95552063\n",
            "Iteration 684, loss = 42059339285.53080750\n",
            "Iteration 685, loss = 42052543582.10090637\n",
            "Iteration 686, loss = 42045730904.01078033\n",
            "Iteration 687, loss = 42038901240.65250397\n",
            "Iteration 688, loss = 42032054581.46534729\n",
            "Iteration 689, loss = 42025190915.93565369\n",
            "Iteration 690, loss = 42018310233.59700012\n",
            "Iteration 691, loss = 42011412524.03009796\n",
            "Iteration 692, loss = 42004497776.86289215\n",
            "Iteration 693, loss = 41997565981.77048492\n",
            "Iteration 694, loss = 41990617128.47522736\n",
            "Iteration 695, loss = 41983651206.74666595\n",
            "Iteration 696, loss = 41976668206.40161896\n",
            "Iteration 697, loss = 41969668117.30413055\n",
            "Iteration 698, loss = 41962650929.36553955\n",
            "Iteration 699, loss = 41955616632.54438782\n",
            "Iteration 700, loss = 41948565216.84658813\n",
            "Iteration 701, loss = 41941496672.32530975\n",
            "Iteration 702, loss = 41934410989.08101654\n",
            "Iteration 703, loss = 41927308157.26153564\n",
            "Iteration 704, loss = 41920188167.06196594\n",
            "Iteration 705, loss = 41913051008.72480774\n",
            "Iteration 706, loss = 41905896672.53987885\n",
            "Iteration 707, loss = 41898725148.84435272\n",
            "Iteration 708, loss = 41891536428.02281952\n",
            "Iteration 709, loss = 41884330500.50723267\n",
            "Iteration 710, loss = 41877107356.77693939\n",
            "Iteration 711, loss = 41869866987.35869598\n",
            "Iteration 712, loss = 41862609382.82667542\n",
            "Iteration 713, loss = 41855334533.80250549\n",
            "Iteration 714, loss = 41848042430.95521545\n",
            "Iteration 715, loss = 41840733065.00132751\n",
            "Iteration 716, loss = 41833406426.70477295\n",
            "Iteration 717, loss = 41826062506.87701416\n",
            "Iteration 718, loss = 41818701296.37696075\n",
            "Iteration 719, loss = 41811322786.11101532\n",
            "Iteration 720, loss = 41803926967.03310394\n",
            "Iteration 721, loss = 41796513830.14464569\n",
            "Iteration 722, loss = 41789083366.49459839\n",
            "Iteration 723, loss = 41781635567.17943573\n",
            "Iteration 724, loss = 41774170423.34320831\n",
            "Iteration 725, loss = 41766687926.17749023\n",
            "Iteration 726, loss = 41759188066.92143250\n",
            "Iteration 727, loss = 41751670836.86176300\n",
            "Iteration 728, loss = 41744136227.33278656\n",
            "Iteration 729, loss = 41736584229.71640015\n",
            "Iteration 730, loss = 41729014835.44210815\n",
            "Iteration 731, loss = 41721428035.98705292\n",
            "Iteration 732, loss = 41713823822.87596893\n",
            "Iteration 733, loss = 41706202187.68122864\n",
            "Iteration 734, loss = 41698563122.02285004\n",
            "Iteration 735, loss = 41690906617.56850433\n",
            "Iteration 736, loss = 41683232666.03353882\n",
            "Iteration 737, loss = 41675541259.18093872\n",
            "Iteration 738, loss = 41667832388.82141113\n",
            "Iteration 739, loss = 41660106046.81330872\n",
            "Iteration 740, loss = 41652362225.06272125\n",
            "Iteration 741, loss = 41644600915.52342987\n",
            "Iteration 742, loss = 41636822110.19692230\n",
            "Iteration 743, loss = 41629025801.13245392\n",
            "Iteration 744, loss = 41621211980.42694855\n",
            "Iteration 745, loss = 41613380640.22512054\n",
            "Iteration 746, loss = 41605531772.71945953\n",
            "Iteration 747, loss = 41597665370.15015411\n",
            "Iteration 748, loss = 41589781424.80519104\n",
            "Iteration 749, loss = 41581879929.02037048\n",
            "Iteration 750, loss = 41573960875.17923737\n",
            "Iteration 751, loss = 41566024255.71313477\n",
            "Iteration 752, loss = 41558070063.10124207\n",
            "Iteration 753, loss = 41550098289.87053680\n",
            "Iteration 754, loss = 41542108928.59578705\n",
            "Iteration 755, loss = 41534101971.89964294\n",
            "Iteration 756, loss = 41526077412.45258331\n",
            "Iteration 757, loss = 41518035242.97290039\n",
            "Iteration 758, loss = 41509975456.22676086\n",
            "Iteration 759, loss = 41501898045.02821350\n",
            "Iteration 760, loss = 41493803002.23915100\n",
            "Iteration 761, loss = 41485690320.76936340\n",
            "Iteration 762, loss = 41477559993.57651520\n",
            "Iteration 763, loss = 41469412013.66617584\n",
            "Iteration 764, loss = 41461246374.09180450\n",
            "Iteration 765, loss = 41453063067.95478821\n",
            "Iteration 766, loss = 41444862088.40441895\n",
            "Iteration 767, loss = 41436643428.63793182\n",
            "Iteration 768, loss = 41428407081.90047455\n",
            "Iteration 769, loss = 41420153041.48513794\n",
            "Iteration 770, loss = 41411881300.73297882\n",
            "Iteration 771, loss = 41403591853.03301239\n",
            "Iteration 772, loss = 41395284691.82217407\n",
            "Iteration 773, loss = 41386959810.58541870\n",
            "Iteration 774, loss = 41378617202.85566711\n",
            "Iteration 775, loss = 41370256862.21379852\n",
            "Iteration 776, loss = 41361878782.28870392\n",
            "Iteration 777, loss = 41353482956.75727844\n",
            "Iteration 778, loss = 41345069379.34442139\n",
            "Iteration 779, loss = 41336638043.82304382\n",
            "Iteration 780, loss = 41328188944.01405334\n",
            "Iteration 781, loss = 41319722073.78640747\n",
            "Iteration 782, loss = 41311237427.05709076\n",
            "Iteration 783, loss = 41302734997.79112244\n",
            "Iteration 784, loss = 41294214780.00158691\n",
            "Iteration 785, loss = 41285676767.74958038\n",
            "Iteration 786, loss = 41277120955.14430237\n",
            "Iteration 787, loss = 41268547336.34298706\n",
            "Iteration 788, loss = 41259955905.55096436\n",
            "Iteration 789, loss = 41251346657.02159119\n",
            "Iteration 790, loss = 41242719585.05638885\n",
            "Iteration 791, loss = 41234074684.00489044\n",
            "Iteration 792, loss = 41225411948.26477051\n",
            "Iteration 793, loss = 41216731372.28178406\n",
            "Iteration 794, loss = 41208032950.54980469\n",
            "Iteration 795, loss = 41199316677.61082458\n",
            "Iteration 796, loss = 41190582548.05491638\n",
            "Iteration 797, loss = 41181830556.52031708\n",
            "Iteration 798, loss = 41173060697.69339752\n",
            "Iteration 799, loss = 41164272966.30863190\n",
            "Iteration 800, loss = 41155467357.14865875\n",
            "Iteration 801, loss = 41146643865.04424286\n",
            "Iteration 802, loss = 41137802484.87432861\n",
            "Iteration 803, loss = 41128943211.56598663\n",
            "Iteration 804, loss = 41120066040.09448242\n",
            "Iteration 805, loss = 41111170965.48320770\n",
            "Iteration 806, loss = 41102257982.80376434\n",
            "Iteration 807, loss = 41093327087.17590332\n",
            "Iteration 808, loss = 41084378273.76758575\n",
            "Iteration 809, loss = 41075411537.79492188\n",
            "Iteration 810, loss = 41066426874.52225494\n",
            "Iteration 811, loss = 41057424279.26209259\n",
            "Iteration 812, loss = 41048403747.37515259\n",
            "Iteration 813, loss = 41039365274.27036285\n",
            "Iteration 814, loss = 41030308855.40486908\n",
            "Iteration 815, loss = 41021234486.28399658\n",
            "Iteration 816, loss = 41012142162.46131897\n",
            "Iteration 817, loss = 41003031879.53864288\n",
            "Iteration 818, loss = 40993903633.16594696\n",
            "Iteration 819, loss = 40984757419.04151917\n",
            "Iteration 820, loss = 40975593232.91181183\n",
            "Iteration 821, loss = 40966411070.57156372\n",
            "Iteration 822, loss = 40957210927.86373901\n",
            "Iteration 823, loss = 40947992800.67951965\n",
            "Iteration 824, loss = 40938756684.95838165\n",
            "Iteration 825, loss = 40929502576.68804169\n",
            "Iteration 826, loss = 40920230471.90446472\n",
            "Iteration 827, loss = 40910940366.69190216\n",
            "Iteration 828, loss = 40901632257.18280792\n",
            "Iteration 829, loss = 40892306139.55799866\n",
            "Iteration 830, loss = 40882962010.04646301\n",
            "Iteration 831, loss = 40873599864.92552185\n",
            "Iteration 832, loss = 40864219700.52079010\n",
            "Iteration 833, loss = 40854821513.20610809\n",
            "Iteration 834, loss = 40845405299.40364075\n",
            "Iteration 835, loss = 40835971055.58381653\n",
            "Iteration 836, loss = 40826518778.26535797\n",
            "Iteration 837, loss = 40817048464.01530457\n",
            "Iteration 838, loss = 40807560109.44893646\n",
            "Iteration 839, loss = 40798053711.22989655\n",
            "Iteration 840, loss = 40788529266.07007599\n",
            "Iteration 841, loss = 40778986770.72972107\n",
            "Iteration 842, loss = 40769426222.01730347\n",
            "Iteration 843, loss = 40759847616.78968048\n",
            "Iteration 844, loss = 40750250951.95198822\n",
            "Iteration 845, loss = 40740636224.45765686\n",
            "Iteration 846, loss = 40731003431.30845642\n",
            "Iteration 847, loss = 40721352569.55447388\n",
            "Iteration 848, loss = 40711683636.29409790\n",
            "Iteration 849, loss = 40701996628.67402649\n",
            "Iteration 850, loss = 40692291543.88932037\n",
            "Iteration 851, loss = 40682568379.18331909\n",
            "Iteration 852, loss = 40672827131.84771729\n",
            "Iteration 853, loss = 40663067799.22253418\n",
            "Iteration 854, loss = 40653290378.69607544\n",
            "Iteration 855, loss = 40643494867.70503235\n",
            "Iteration 856, loss = 40633681263.73440552\n",
            "Iteration 857, loss = 40623849564.31752014\n",
            "Iteration 858, loss = 40613999767.03604126\n",
            "Iteration 859, loss = 40604131869.51994324\n",
            "Iteration 860, loss = 40594245869.44759369\n",
            "Iteration 861, loss = 40584341764.54566193\n",
            "Iteration 862, loss = 40574419552.58911896\n",
            "Iteration 863, loss = 40564479231.40132904\n",
            "Iteration 864, loss = 40554520798.85398102\n",
            "Iteration 865, loss = 40544544252.86708832\n",
            "Iteration 866, loss = 40534549591.40900421\n",
            "Iteration 867, loss = 40524536812.49644470\n",
            "Iteration 868, loss = 40514505914.19444275\n",
            "Iteration 869, loss = 40504456894.61638641\n",
            "Iteration 870, loss = 40494389751.92399597\n",
            "Iteration 871, loss = 40484304484.32734680\n",
            "Iteration 872, loss = 40474201090.08483887\n",
            "Iteration 873, loss = 40464079567.50321960\n",
            "Iteration 874, loss = 40453939914.93759155\n",
            "Iteration 875, loss = 40443782130.79137421\n",
            "Iteration 876, loss = 40433606213.51632690\n",
            "Iteration 877, loss = 40423412161.61259460\n",
            "Iteration 878, loss = 40413199973.62862396\n",
            "Iteration 879, loss = 40402969648.16119385\n",
            "Iteration 880, loss = 40392721183.85545349\n",
            "Iteration 881, loss = 40382454579.40486145\n",
            "Iteration 882, loss = 40372169833.55124664\n",
            "Iteration 883, loss = 40361866945.08473969\n",
            "Iteration 884, loss = 40351545912.84384155\n",
            "Iteration 885, loss = 40341206735.71533203\n",
            "Iteration 886, loss = 40330849412.63442230\n",
            "Iteration 887, loss = 40320473942.58456421\n",
            "Iteration 888, loss = 40310080324.59759521\n",
            "Iteration 889, loss = 40299668557.75364685\n",
            "Iteration 890, loss = 40289238641.18122864\n",
            "Iteration 891, loss = 40278790574.05710602\n",
            "Iteration 892, loss = 40268324355.60644531\n",
            "Iteration 893, loss = 40257839985.10271454\n",
            "Iteration 894, loss = 40247337461.86766052\n",
            "Iteration 895, loss = 40236816785.27143097\n",
            "Iteration 896, loss = 40226277954.73242188\n",
            "Iteration 897, loss = 40215720969.71738434\n",
            "Iteration 898, loss = 40205145829.74137878\n",
            "Iteration 899, loss = 40194552534.36778259\n",
            "Iteration 900, loss = 40183941083.20827484\n",
            "Iteration 901, loss = 40173311475.92283630\n",
            "Iteration 902, loss = 40162663712.21977997\n",
            "Iteration 903, loss = 40151997791.85572052\n",
            "Iteration 904, loss = 40141313714.63554382\n",
            "Iteration 905, loss = 40130611480.41246796\n",
            "Iteration 906, loss = 40119891089.08799744\n",
            "Iteration 907, loss = 40109152540.61193085\n",
            "Iteration 908, loss = 40098395834.98235321\n",
            "Iteration 909, loss = 40087620972.24564362\n",
            "Iteration 910, loss = 40076827952.49646759\n",
            "Iteration 911, loss = 40066016775.87776947\n",
            "Iteration 912, loss = 40055187442.58078003\n",
            "Iteration 913, loss = 40044339952.84498596\n",
            "Iteration 914, loss = 40033474306.95816803\n",
            "Iteration 915, loss = 40022590505.25637054\n",
            "Iteration 916, loss = 40011688548.12389374\n",
            "Iteration 917, loss = 40000768435.99331665\n",
            "Iteration 918, loss = 39989830169.34547424\n",
            "Iteration 919, loss = 39978873748.70942688\n",
            "Iteration 920, loss = 39967899174.66252899\n",
            "Iteration 921, loss = 39956906447.83036041\n",
            "Iteration 922, loss = 39945895568.88674164\n",
            "Iteration 923, loss = 39934866538.55374146\n",
            "Iteration 924, loss = 39923819357.60164642\n",
            "Iteration 925, loss = 39912754026.84900665\n",
            "Iteration 926, loss = 39901670547.16254425\n",
            "Iteration 927, loss = 39890568919.45726776\n",
            "Iteration 928, loss = 39879449144.69637299\n",
            "Iteration 929, loss = 39868311223.89123535\n",
            "Iteration 930, loss = 39857155158.10150146\n",
            "Iteration 931, loss = 39845980948.43498230\n",
            "Iteration 932, loss = 39834788596.04768372\n",
            "Iteration 933, loss = 39823578102.14381409\n",
            "Iteration 934, loss = 39812349467.97580719\n",
            "Iteration 935, loss = 39801102694.84420013\n",
            "Iteration 936, loss = 39789837784.09777832\n",
            "Iteration 937, loss = 39778554737.13347626\n",
            "Iteration 938, loss = 39767253555.39637756\n",
            "Iteration 939, loss = 39755934240.37976074\n",
            "Iteration 940, loss = 39744596793.62504578\n",
            "Iteration 941, loss = 39733241216.72180176\n",
            "Iteration 942, loss = 39721867511.30774689\n",
            "Iteration 943, loss = 39710475679.06873322\n",
            "Iteration 944, loss = 39699065721.73873901\n",
            "Iteration 945, loss = 39687637641.09990692\n",
            "Iteration 946, loss = 39676191438.98245239\n",
            "Iteration 947, loss = 39664727117.26475525\n",
            "Iteration 948, loss = 39653244677.87324524\n",
            "Iteration 949, loss = 39641744122.78252411\n",
            "Iteration 950, loss = 39630225454.01523590\n",
            "Iteration 951, loss = 39618688673.64214325\n",
            "Iteration 952, loss = 39607133783.78207397\n",
            "Iteration 953, loss = 39595560786.60194397\n",
            "Iteration 954, loss = 39583969684.31674957\n",
            "Iteration 955, loss = 39572360479.18952179\n",
            "Iteration 956, loss = 39560733173.53137207\n",
            "Iteration 957, loss = 39549087769.70145416\n",
            "Iteration 958, loss = 39537424270.10697174\n",
            "Iteration 959, loss = 39525742677.20314026\n",
            "Iteration 960, loss = 39514042993.49324036\n",
            "Iteration 961, loss = 39502325221.52854156\n",
            "Iteration 962, loss = 39490589363.90831757\n",
            "Iteration 963, loss = 39478835423.27989197\n",
            "Iteration 964, loss = 39467063402.33856201\n",
            "Iteration 965, loss = 39455273303.82759857\n",
            "Iteration 966, loss = 39443465130.53828430\n",
            "Iteration 967, loss = 39431638885.30984497\n",
            "Iteration 968, loss = 39419794571.02952576\n",
            "Iteration 969, loss = 39407932190.63246155\n",
            "Iteration 970, loss = 39396051747.10179138\n",
            "Iteration 971, loss = 39384153243.46857452\n",
            "Iteration 972, loss = 39372236682.81179810\n",
            "Iteration 973, loss = 39360302068.25839233\n",
            "Iteration 974, loss = 39348349402.98319244\n",
            "Iteration 975, loss = 39336378690.20896149\n",
            "Iteration 976, loss = 39324389933.20632935\n",
            "Iteration 977, loss = 39312383135.29381561\n",
            "Iteration 978, loss = 39300358299.83789825\n",
            "Iteration 979, loss = 39288315430.25279999\n",
            "Iteration 980, loss = 39276254530.00074768\n",
            "Iteration 981, loss = 39264175602.59169769\n",
            "Iteration 982, loss = 39252078651.58354187\n",
            "Iteration 983, loss = 39239963680.58196259\n",
            "Iteration 984, loss = 39227830693.24048615\n",
            "Iteration 985, loss = 39215679693.26045227\n",
            "Iteration 986, loss = 39203510684.39101410\n",
            "Iteration 987, loss = 39191323670.42909241\n",
            "Iteration 988, loss = 39179118655.21946716\n",
            "Iteration 989, loss = 39166895642.65461731\n",
            "Iteration 990, loss = 39154654636.67483521\n",
            "Iteration 991, loss = 39142395641.26817322\n",
            "Iteration 992, loss = 39130118660.47042847\n",
            "Iteration 993, loss = 39117823698.36509705\n",
            "Iteration 994, loss = 39105510759.08346558\n",
            "Iteration 995, loss = 39093179846.80450439\n",
            "Iteration 996, loss = 39080830965.75492096\n",
            "Iteration 997, loss = 39068464120.20905304\n",
            "Iteration 998, loss = 39056079314.48899078\n",
            "Iteration 999, loss = 39043676552.96447754\n",
            "Iteration 1000, loss = 39031255840.05292511\n",
            "Iteration 1001, loss = 39018817180.21939850\n",
            "Iteration 1002, loss = 39006360577.97657013\n",
            "Iteration 1003, loss = 38993886037.88481903\n",
            "Iteration 1004, loss = 38981393564.55207825\n",
            "Iteration 1005, loss = 38968883162.63393402\n",
            "Iteration 1006, loss = 38956354836.83351898\n",
            "Iteration 1007, loss = 38943808591.90161896\n",
            "Iteration 1008, loss = 38931244432.63653564\n",
            "Iteration 1009, loss = 38918662363.88418579\n",
            "Iteration 1010, loss = 38906062390.53797913\n",
            "Iteration 1011, loss = 38893444517.53891754\n",
            "Iteration 1012, loss = 38880808749.87549591\n",
            "Iteration 1013, loss = 38868155092.58375549\n",
            "Iteration 1014, loss = 38855483550.74721527\n",
            "Iteration 1015, loss = 38842794129.49688721\n",
            "Iteration 1016, loss = 38830086834.01128387\n",
            "Iteration 1017, loss = 38817361669.51637268\n",
            "Iteration 1018, loss = 38804618641.28556824\n",
            "Iteration 1019, loss = 38791857754.63972473\n",
            "Iteration 1020, loss = 38779079014.94715881\n",
            "Iteration 1021, loss = 38766282427.62354279\n",
            "Iteration 1022, loss = 38753467998.13202667\n",
            "Iteration 1023, loss = 38740635731.98309326\n",
            "Iteration 1024, loss = 38727785634.73461914\n",
            "Iteration 1025, loss = 38714917711.99185181\n",
            "Iteration 1026, loss = 38702031969.40739441\n",
            "Iteration 1027, loss = 38689128412.68119812\n",
            "Iteration 1028, loss = 38676207047.56048584\n",
            "Iteration 1029, loss = 38663267879.83985901\n",
            "Iteration 1030, loss = 38650310915.36116028\n",
            "Iteration 1031, loss = 38637336160.01357269\n",
            "Iteration 1032, loss = 38624343619.73349762\n",
            "Iteration 1033, loss = 38611333300.50463104\n",
            "Iteration 1034, loss = 38598305208.35787201\n",
            "Iteration 1035, loss = 38585259349.37138367\n",
            "Iteration 1036, loss = 38572195729.67054749\n",
            "Iteration 1037, loss = 38559114355.42788696\n",
            "Iteration 1038, loss = 38546015232.86321259\n",
            "Iteration 1039, loss = 38532898368.24340057\n",
            "Iteration 1040, loss = 38519763767.88255310\n",
            "Iteration 1041, loss = 38506611438.14186859\n",
            "Iteration 1042, loss = 38493441385.42973328\n",
            "Iteration 1043, loss = 38480253616.20157623\n",
            "Iteration 1044, loss = 38467048136.95998383\n",
            "Iteration 1045, loss = 38453824954.25458527\n",
            "Iteration 1046, loss = 38440584074.68209839\n",
            "Iteration 1047, loss = 38427325504.88629150\n",
            "Iteration 1048, loss = 38414049251.55796051\n",
            "Iteration 1049, loss = 38400755321.43492889\n",
            "Iteration 1050, loss = 38387443721.30204773\n",
            "Iteration 1051, loss = 38374114457.99111176\n",
            "Iteration 1052, loss = 38360767538.38095093\n",
            "Iteration 1053, loss = 38347402969.39730835\n",
            "Iteration 1054, loss = 38334020758.01290131\n",
            "Iteration 1055, loss = 38320620911.24733734\n",
            "Iteration 1056, loss = 38307203436.16719818\n",
            "Iteration 1057, loss = 38293768339.88589478\n",
            "Iteration 1058, loss = 38280315629.56375885\n",
            "Iteration 1059, loss = 38266845312.40797424\n",
            "Iteration 1060, loss = 38253357395.67259216\n",
            "Iteration 1061, loss = 38239851886.65845490\n",
            "Iteration 1062, loss = 38226328792.71325684\n",
            "Iteration 1063, loss = 38212788121.23146057\n",
            "Iteration 1064, loss = 38199229879.65435791\n",
            "Iteration 1065, loss = 38185654075.46991730\n",
            "Iteration 1066, loss = 38172060716.21296692\n",
            "Iteration 1067, loss = 38158449809.46497345\n",
            "Iteration 1068, loss = 38144821362.85417175\n",
            "Iteration 1069, loss = 38131175384.05545044\n",
            "Iteration 1070, loss = 38117511880.79042816\n",
            "Iteration 1071, loss = 38103830860.82732391\n",
            "Iteration 1072, loss = 38090132331.98105621\n",
            "Iteration 1073, loss = 38076416302.11314392\n",
            "Iteration 1074, loss = 38062682779.13170624\n",
            "Iteration 1075, loss = 38048931770.99148560\n",
            "Iteration 1076, loss = 38035163285.69375610\n",
            "Iteration 1077, loss = 38021377331.28637695\n",
            "Iteration 1078, loss = 38007573915.86373901\n",
            "Iteration 1079, loss = 37993753047.56674194\n",
            "Iteration 1080, loss = 37979914734.58279419\n",
            "Iteration 1081, loss = 37966058985.14579010\n",
            "Iteration 1082, loss = 37952185807.53607941\n",
            "Iteration 1083, loss = 37938295210.08045959\n",
            "Iteration 1084, loss = 37924387201.15216827\n",
            "Iteration 1085, loss = 37910461789.17082214\n",
            "Iteration 1086, loss = 37896518982.60245514\n",
            "Iteration 1087, loss = 37882558789.95945740\n",
            "Iteration 1088, loss = 37868581219.80056763\n",
            "Iteration 1089, loss = 37854586280.73088074\n",
            "Iteration 1090, loss = 37840573981.40177917\n",
            "Iteration 1091, loss = 37826544330.51093292\n",
            "Iteration 1092, loss = 37812497336.80232239\n",
            "Iteration 1093, loss = 37798433009.06615448\n",
            "Iteration 1094, loss = 37784351356.13887024\n",
            "Iteration 1095, loss = 37770252386.90314484\n",
            "Iteration 1096, loss = 37756136110.28782654\n",
            "Iteration 1097, loss = 37742002535.26796722\n",
            "Iteration 1098, loss = 37727851670.86474609\n",
            "Iteration 1099, loss = 37713683526.14551544\n",
            "Iteration 1100, loss = 37699498110.22370911\n",
            "Iteration 1101, loss = 37685295432.25885010\n",
            "Iteration 1102, loss = 37671075501.45658875\n",
            "Iteration 1103, loss = 37656838327.06857300\n",
            "Iteration 1104, loss = 37642583918.39250946\n",
            "Iteration 1105, loss = 37628312284.77213287\n",
            "Iteration 1106, loss = 37614023435.59714508\n",
            "Iteration 1107, loss = 37599717380.30322266\n",
            "Iteration 1108, loss = 37585394128.37203217\n",
            "Iteration 1109, loss = 37571053689.33111572\n",
            "Iteration 1110, loss = 37556696072.75396729\n",
            "Iteration 1111, loss = 37542321288.25993347\n",
            "Iteration 1112, loss = 37527929345.51425934\n",
            "Iteration 1113, loss = 37513520254.22801971\n",
            "Iteration 1114, loss = 37499094024.15811157\n",
            "Iteration 1115, loss = 37484650665.10725403\n",
            "Iteration 1116, loss = 37470190186.92391205\n",
            "Iteration 1117, loss = 37455712599.50233459\n",
            "Iteration 1118, loss = 37441217912.78250885\n",
            "Iteration 1119, loss = 37426706136.75012970\n",
            "Iteration 1120, loss = 37412177281.43658447\n",
            "Iteration 1121, loss = 37397631356.91892242\n",
            "Iteration 1122, loss = 37383068373.31985474\n",
            "Iteration 1123, loss = 37368488340.80772400\n",
            "Iteration 1124, loss = 37353891269.59648132\n",
            "Iteration 1125, loss = 37339277169.94561768\n",
            "Iteration 1126, loss = 37324646052.16024017\n",
            "Iteration 1127, loss = 37309997926.59094238\n",
            "Iteration 1128, loss = 37295332803.63385010\n",
            "Iteration 1129, loss = 37280650693.73059845\n",
            "Iteration 1130, loss = 37265951607.36827850\n",
            "Iteration 1131, loss = 37251235555.07939148\n",
            "Iteration 1132, loss = 37236502547.44190216\n",
            "Iteration 1133, loss = 37221752595.07916260\n",
            "Iteration 1134, loss = 37206985708.65990448\n",
            "Iteration 1135, loss = 37192201898.89817047\n",
            "Iteration 1136, loss = 37177401176.55338287\n",
            "Iteration 1137, loss = 37162583552.43024445\n",
            "Iteration 1138, loss = 37147749037.37873077\n",
            "Iteration 1139, loss = 37132897642.29409027\n",
            "Iteration 1140, loss = 37118029378.11676788\n",
            "Iteration 1141, loss = 37103144255.83248901\n",
            "Iteration 1142, loss = 37088242286.47206879\n",
            "Iteration 1143, loss = 37073323481.11154938\n",
            "Iteration 1144, loss = 37058387850.87207794\n",
            "Iteration 1145, loss = 37043435406.91993713\n",
            "Iteration 1146, loss = 37028466160.46645355\n",
            "Iteration 1147, loss = 37013480122.76805878\n",
            "Iteration 1148, loss = 36998477305.12619019\n",
            "Iteration 1149, loss = 36983457718.88732910\n",
            "Iteration 1150, loss = 36968421375.44290161\n",
            "Iteration 1151, loss = 36953368286.22932434\n",
            "Iteration 1152, loss = 36938298462.72793579\n",
            "Iteration 1153, loss = 36923211916.46500397\n",
            "Iteration 1154, loss = 36908108659.01165771\n",
            "Iteration 1155, loss = 36892988701.98390961\n",
            "Iteration 1156, loss = 36877852057.04260254\n",
            "Iteration 1157, loss = 36862698735.89335632\n",
            "Iteration 1158, loss = 36847528750.28662872\n",
            "Iteration 1159, loss = 36832342112.01760101\n",
            "Iteration 1160, loss = 36817138832.92617798\n",
            "Iteration 1161, loss = 36801918924.89698792\n",
            "Iteration 1162, loss = 36786682399.85935211\n",
            "Iteration 1163, loss = 36771429269.78721619\n",
            "Iteration 1164, loss = 36756159546.69915771\n",
            "Iteration 1165, loss = 36740873242.65838623\n",
            "Iteration 1166, loss = 36725570369.77263641\n",
            "Iteration 1167, loss = 36710250940.19422913\n",
            "Iteration 1168, loss = 36694914966.11997986\n",
            "Iteration 1169, loss = 36679562459.79121399\n",
            "Iteration 1170, loss = 36664193433.49373627\n",
            "Iteration 1171, loss = 36648807899.55774689\n",
            "Iteration 1172, loss = 36633405870.35791779\n",
            "Iteration 1173, loss = 36617987358.31327057\n",
            "Iteration 1174, loss = 36602552375.88717651\n",
            "Iteration 1175, loss = 36587100935.58735657\n",
            "Iteration 1176, loss = 36571633049.96584320\n",
            "Iteration 1177, loss = 36556148731.61893463\n",
            "Iteration 1178, loss = 36540647993.18715668\n",
            "Iteration 1179, loss = 36525130847.35530090\n",
            "Iteration 1180, loss = 36509597306.85231781\n",
            "Iteration 1181, loss = 36494047384.45130920\n",
            "Iteration 1182, loss = 36478481092.96956635\n",
            "Iteration 1183, loss = 36462898445.26845551\n",
            "Iteration 1184, loss = 36447299454.25341034\n",
            "Iteration 1185, loss = 36431684132.87394714\n",
            "Iteration 1186, loss = 36416052494.12357330\n",
            "Iteration 1187, loss = 36400404551.03984070\n",
            "Iteration 1188, loss = 36384740316.70420837\n",
            "Iteration 1189, loss = 36369059804.24211121\n",
            "Iteration 1190, loss = 36353363026.82288361\n",
            "Iteration 1191, loss = 36337649997.65972900\n",
            "Iteration 1192, loss = 36321920730.00971985\n",
            "Iteration 1193, loss = 36306175237.17375183\n",
            "Iteration 1194, loss = 36290413532.49647522\n",
            "Iteration 1195, loss = 36274635629.36634827\n",
            "Iteration 1196, loss = 36258841541.21554565\n",
            "Iteration 1197, loss = 36243031281.51994324\n",
            "Iteration 1198, loss = 36227204863.79908752\n",
            "Iteration 1199, loss = 36211362301.61618805\n",
            "Iteration 1200, loss = 36195503608.57805634\n",
            "Iteration 1201, loss = 36179628798.33506775\n",
            "Iteration 1202, loss = 36163737884.58120728\n",
            "Iteration 1203, loss = 36147830881.05392456\n",
            "Iteration 1204, loss = 36131907801.53420258\n",
            "Iteration 1205, loss = 36115968659.84646606\n",
            "Iteration 1206, loss = 36100013469.85861206\n",
            "Iteration 1207, loss = 36084042245.48189545\n",
            "Iteration 1208, loss = 36068055000.67096710\n",
            "Iteration 1209, loss = 36052051749.42379761\n",
            "Iteration 1210, loss = 36036032505.78170776\n",
            "Iteration 1211, loss = 36019997283.82927704\n",
            "Iteration 1212, loss = 36003946097.69431305\n",
            "Iteration 1213, loss = 35987878961.54788971\n",
            "Iteration 1214, loss = 35971795889.60421753\n",
            "Iteration 1215, loss = 35955696896.12070465\n",
            "Iteration 1216, loss = 35939581995.39785004\n",
            "Iteration 1217, loss = 35923451201.77927399\n",
            "Iteration 1218, loss = 35907304529.65164185\n",
            "Iteration 1219, loss = 35891141993.44464111\n",
            "Iteration 1220, loss = 35874963607.63098907\n",
            "Iteration 1221, loss = 35858769386.72634125\n",
            "Iteration 1222, loss = 35842559345.28926849\n",
            "Iteration 1223, loss = 35826333497.92128754\n",
            "Iteration 1224, loss = 35810091859.26676941\n",
            "Iteration 1225, loss = 35793834444.01290894\n",
            "Iteration 1226, loss = 35777561266.88973999\n",
            "Iteration 1227, loss = 35761272342.67001343\n",
            "Iteration 1228, loss = 35744967686.16925812\n",
            "Iteration 1229, loss = 35728647312.24570465\n",
            "Iteration 1230, loss = 35712311235.80028534\n",
            "Iteration 1231, loss = 35695959471.77650452\n",
            "Iteration 1232, loss = 35679592035.16053772\n",
            "Iteration 1233, loss = 35663208940.98112488\n",
            "Iteration 1234, loss = 35646810204.30952454\n",
            "Iteration 1235, loss = 35630395840.25949097\n",
            "Iteration 1236, loss = 35613965863.98735046\n",
            "Iteration 1237, loss = 35597520290.69174957\n",
            "Iteration 1238, loss = 35581059135.61380768\n",
            "Iteration 1239, loss = 35564582414.03702545\n",
            "Iteration 1240, loss = 35548090141.28720856\n",
            "Iteration 1241, loss = 35531582332.73249817\n",
            "Iteration 1242, loss = 35515059003.78330231\n",
            "Iteration 1243, loss = 35498520169.89226532\n",
            "Iteration 1244, loss = 35481965846.55424500\n",
            "Iteration 1245, loss = 35465396049.30626678\n",
            "Iteration 1246, loss = 35448810793.72747803\n",
            "Iteration 1247, loss = 35432210095.43914795\n",
            "Iteration 1248, loss = 35415593970.10462952\n",
            "Iteration 1249, loss = 35398962433.42924500\n",
            "Iteration 1250, loss = 35382315501.16039276\n",
            "Iteration 1251, loss = 35365653189.08736420\n",
            "Iteration 1252, loss = 35348975513.04145050\n",
            "Iteration 1253, loss = 35332282488.89578247\n",
            "Iteration 1254, loss = 35315574132.56537628\n",
            "Iteration 1255, loss = 35298850460.00704956\n",
            "Iteration 1256, loss = 35282111487.21944427\n",
            "Iteration 1257, loss = 35265357230.24289703\n",
            "Iteration 1258, loss = 35248587705.15953064\n",
            "Iteration 1259, loss = 35231802928.09310150\n",
            "Iteration 1260, loss = 35215002915.20901489\n",
            "Iteration 1261, loss = 35198187682.71432495\n",
            "Iteration 1262, loss = 35181357246.85760498\n",
            "Iteration 1263, loss = 35164511623.92900848\n",
            "Iteration 1264, loss = 35147650830.26017761\n",
            "Iteration 1265, loss = 35130774882.22419739\n",
            "Iteration 1266, loss = 35113883796.23563385\n",
            "Iteration 1267, loss = 35096977588.75039673\n",
            "Iteration 1268, loss = 35080056276.26576996\n",
            "Iteration 1269, loss = 35063119875.32037354\n",
            "Iteration 1270, loss = 35046168402.49409485\n",
            "Iteration 1271, loss = 35029201874.40802765\n",
            "Iteration 1272, loss = 35012220307.72457123\n",
            "Iteration 1273, loss = 34995223719.14722443\n",
            "Iteration 1274, loss = 34978212125.42062378\n",
            "Iteration 1275, loss = 34961185543.33053589\n",
            "Iteration 1276, loss = 34944143989.70377350\n",
            "Iteration 1277, loss = 34927087481.40814972\n",
            "Iteration 1278, loss = 34910016035.35250854\n",
            "Iteration 1279, loss = 34892929668.48661041\n",
            "Iteration 1280, loss = 34875828397.80113983\n",
            "Iteration 1281, loss = 34858712240.32763672\n",
            "Iteration 1282, loss = 34841581213.13851166\n",
            "Iteration 1283, loss = 34824435333.34693909\n",
            "Iteration 1284, loss = 34807274618.10685730\n",
            "Iteration 1285, loss = 34790099084.61293793\n",
            "Iteration 1286, loss = 34772908750.10053253\n",
            "Iteration 1287, loss = 34755703631.84562683\n",
            "Iteration 1288, loss = 34738483747.16482544\n",
            "Iteration 1289, loss = 34721249113.41527557\n",
            "Iteration 1290, loss = 34703999747.99468994\n",
            "Iteration 1291, loss = 34686735668.34125519\n",
            "Iteration 1292, loss = 34669456891.93357849\n",
            "Iteration 1293, loss = 34652163436.29074860\n",
            "Iteration 1294, loss = 34634855318.97213745\n",
            "Iteration 1295, loss = 34617532557.57753754\n",
            "Iteration 1296, loss = 34600195169.74697113\n",
            "Iteration 1297, loss = 34582843173.14395142\n",
            "Iteration 1298, loss = 34565474119.80764771\n",
            "Iteration 1299, loss = 34548086563.48725891\n",
            "Iteration 1300, loss = 34530676673.88695526\n",
            "Iteration 1301, loss = 34513242087.98027802\n",
            "Iteration 1302, loss = 34495780780.51057434\n",
            "Iteration 1303, loss = 34478291008.49377441\n",
            "Iteration 1304, loss = 34460771281.77980042\n",
            "Iteration 1305, loss = 34443220338.14110565\n",
            "Iteration 1306, loss = 34425637119.75790405\n",
            "Iteration 1307, loss = 34408020751.24949646\n",
            "Iteration 1308, loss = 34390370519.48530579\n",
            "Iteration 1309, loss = 34372685855.22838593\n",
            "Iteration 1310, loss = 34354966316.55017090\n",
            "Iteration 1311, loss = 34337211573.90336227\n",
            "Iteration 1312, loss = 34319421396.71984482\n",
            "Iteration 1313, loss = 34301595641.39843369\n",
            "Iteration 1314, loss = 34283734240.55245972\n",
            "Iteration 1315, loss = 34265837193.39479828\n",
            "Iteration 1316, loss = 34247904557.14854813\n",
            "Iteration 1317, loss = 34229936439.38052368\n",
            "Iteration 1318, loss = 34211932991.16477966\n",
            "Iteration 1319, loss = 34193894400.99163818\n",
            "Iteration 1320, loss = 34175820889.34635162\n",
            "Iteration 1321, loss = 34157712703.88860703\n",
            "Iteration 1322, loss = 34139570115.17110062\n",
            "Iteration 1323, loss = 34121393412.84163666\n",
            "Iteration 1324, loss = 34103182902.27811813\n",
            "Iteration 1325, loss = 34084938901.61218262\n",
            "Iteration 1326, loss = 34066661739.10010147\n",
            "Iteration 1327, loss = 34048351750.80505371\n",
            "Iteration 1328, loss = 34030009278.55766296\n",
            "Iteration 1329, loss = 34011634668.16563034\n",
            "Iteration 1330, loss = 33993228267.84571838\n",
            "Iteration 1331, loss = 33974790426.85453033\n",
            "Iteration 1332, loss = 33956321494.29672623\n",
            "Iteration 1333, loss = 33937821818.09126282\n",
            "Iteration 1334, loss = 33919291744.07879639\n",
            "Iteration 1335, loss = 33900731615.25462341\n",
            "Iteration 1336, loss = 33882141771.11316681\n",
            "Iteration 1337, loss = 33863522547.09197998\n",
            "Iteration 1338, loss = 33844874274.10364532\n",
            "Iteration 1339, loss = 33826197278.14593124\n",
            "Iteration 1340, loss = 33807491879.98114014\n",
            "Iteration 1341, loss = 33788758394.87650299\n",
            "Iteration 1342, loss = 33769997132.39873505\n",
            "Iteration 1343, loss = 33751208396.25597000\n",
            "Iteration 1344, loss = 33732392484.18159485\n",
            "Iteration 1345, loss = 33713549687.85481644\n",
            "Iteration 1346, loss = 33694680292.85313797\n",
            "Iteration 1347, loss = 33675784578.63301086\n",
            "Iteration 1348, loss = 33656862818.53462219\n",
            "Iteration 1349, loss = 33637915279.80794907\n",
            "Iteration 1350, loss = 33618942223.65672302\n",
            "Iteration 1351, loss = 33599943905.29822159\n",
            "Iteration 1352, loss = 33580920574.03612518\n",
            "Iteration 1353, loss = 33561872473.34466553\n",
            "Iteration 1354, loss = 33542799840.96230316\n",
            "Iteration 1355, loss = 33523702908.99298096\n",
            "Iteration 1356, loss = 33504581904.01400375\n",
            "Iteration 1357, loss = 33485437047.18888855\n",
            "Iteration 1358, loss = 33466268554.38430405\n",
            "Iteration 1359, loss = 33447076636.29009628\n",
            "Iteration 1360, loss = 33427861498.54139328\n",
            "Iteration 1361, loss = 33408623341.84238052\n",
            "Iteration 1362, loss = 33389362362.09058380\n",
            "Iteration 1363, loss = 33370078750.50166702\n",
            "Iteration 1364, loss = 33350772693.73373795\n",
            "Iteration 1365, loss = 33331444374.01111984\n",
            "Iteration 1366, loss = 33312093969.24695587\n",
            "Iteration 1367, loss = 33292721653.16452408\n",
            "Iteration 1368, loss = 33273327595.41688156\n",
            "Iteration 1369, loss = 33253911961.70464325\n",
            "Iteration 1370, loss = 33234474913.89171219\n",
            "Iteration 1371, loss = 33215016610.11881638\n",
            "Iteration 1372, loss = 33195537204.91476822\n",
            "Iteration 1373, loss = 33176036849.30518341\n",
            "Iteration 1374, loss = 33156515690.91884995\n",
            "Iteration 1375, loss = 33136973874.09140015\n",
            "Iteration 1376, loss = 33117411539.96652985\n",
            "Iteration 1377, loss = 33097828826.59445953\n",
            "Iteration 1378, loss = 33078225869.02787781\n",
            "Iteration 1379, loss = 33058602799.41520309\n",
            "Iteration 1380, loss = 33038959747.09123230\n",
            "Iteration 1381, loss = 33019296838.66523743\n",
            "Iteration 1382, loss = 32999614198.10644913\n",
            "Iteration 1383, loss = 32979911946.82699966\n",
            "Iteration 1384, loss = 32960190203.76244736\n",
            "Iteration 1385, loss = 32940449085.44972992\n",
            "Iteration 1386, loss = 32920688706.10282516\n",
            "Iteration 1387, loss = 32900909177.68594360\n",
            "Iteration 1388, loss = 32881110609.98455048\n",
            "Iteration 1389, loss = 32861293110.67401886\n",
            "Iteration 1390, loss = 32841456785.38616562\n",
            "Iteration 1391, loss = 32821601737.77353287\n",
            "Iteration 1392, loss = 32801728069.57179642\n",
            "Iteration 1393, loss = 32781835880.65990829\n",
            "Iteration 1394, loss = 32761925269.11848831\n",
            "Iteration 1395, loss = 32741996331.28606796\n",
            "Iteration 1396, loss = 32722049161.81374359\n",
            "Iteration 1397, loss = 32702083853.71776962\n",
            "Iteration 1398, loss = 32682100498.43069839\n",
            "Iteration 1399, loss = 32662099185.85051346\n",
            "Iteration 1400, loss = 32642080004.38833618\n",
            "Iteration 1401, loss = 32622043041.01451874\n",
            "Iteration 1402, loss = 32601988381.30315018\n",
            "Iteration 1403, loss = 32581916109.47512436\n",
            "Iteration 1404, loss = 32561826308.43974304\n",
            "Iteration 1405, loss = 32541719059.83496094\n",
            "Iteration 1406, loss = 32521594444.06628799\n",
            "Iteration 1407, loss = 32501452540.34434891\n",
            "Iteration 1408, loss = 32481293426.72130203\n",
            "Iteration 1409, loss = 32461117180.12591171\n",
            "Iteration 1410, loss = 32440923876.39757919\n",
            "Iteration 1411, loss = 32420713590.31915665\n",
            "Iteration 1412, loss = 32400486395.64877701\n",
            "Iteration 1413, loss = 32380242365.15045166\n",
            "Iteration 1414, loss = 32359981570.62389374\n",
            "Iteration 1415, loss = 32339704082.93319702\n",
            "Iteration 1416, loss = 32319409972.03458786\n",
            "Iteration 1417, loss = 32299099307.00337219\n",
            "Iteration 1418, loss = 32278772156.05986786\n",
            "Iteration 1419, loss = 32258428586.59457397\n",
            "Iteration 1420, loss = 32238068665.19250488\n",
            "Iteration 1421, loss = 32217692457.65673828\n",
            "Iteration 1422, loss = 32197300029.03118896\n",
            "Iteration 1423, loss = 32176891443.62261963\n",
            "Iteration 1424, loss = 32156466765.02203751\n",
            "Iteration 1425, loss = 32136026056.12533951\n",
            "Iteration 1426, loss = 32115569379.15325546\n",
            "Iteration 1427, loss = 32095096795.67074585\n",
            "Iteration 1428, loss = 32074608366.60573578\n",
            "Iteration 1429, loss = 32054104152.26726913\n",
            "Iteration 1430, loss = 32033584212.36304855\n",
            "Iteration 1431, loss = 32013048606.01654053\n",
            "Iteration 1432, loss = 31992497391.78336716\n",
            "Iteration 1433, loss = 31971930627.66735077\n",
            "Iteration 1434, loss = 31951348371.13595963\n",
            "Iteration 1435, loss = 31930750679.13533401\n",
            "Iteration 1436, loss = 31910137608.10478973\n",
            "Iteration 1437, loss = 31889509213.99094009\n",
            "Iteration 1438, loss = 31868865552.26132202\n",
            "Iteration 1439, loss = 31848206677.91762924\n",
            "Iteration 1440, loss = 31827532645.50862503\n",
            "Iteration 1441, loss = 31806843509.14249420\n",
            "Iteration 1442, loss = 31786139322.49894714\n",
            "Iteration 1443, loss = 31765420138.84095383\n",
            "Iteration 1444, loss = 31744686011.02607727\n",
            "Iteration 1445, loss = 31723936991.51748657\n",
            "Iteration 1446, loss = 31703173132.39468765\n",
            "Iteration 1447, loss = 31682394485.36381149\n",
            "Iteration 1448, loss = 31661601101.76778793\n",
            "Iteration 1449, loss = 31640793032.59601974\n",
            "Iteration 1450, loss = 31619970328.49396133\n",
            "Iteration 1451, loss = 31599133039.77223969\n",
            "Iteration 1452, loss = 31578281216.41564941\n",
            "Iteration 1453, loss = 31557414908.09183121\n",
            "Iteration 1454, loss = 31536534164.15967560\n",
            "Iteration 1455, loss = 31515639033.67752075\n",
            "Iteration 1456, loss = 31494729565.41114807\n",
            "Iteration 1457, loss = 31473805807.84144592\n",
            "Iteration 1458, loss = 31452867809.17195892\n",
            "Iteration 1459, loss = 31431915617.33621597\n",
            "Iteration 1460, loss = 31410949280.00471878\n",
            "Iteration 1461, loss = 31389968844.59193420\n",
            "Iteration 1462, loss = 31368974358.26296997\n",
            "Iteration 1463, loss = 31347965867.94004440\n",
            "Iteration 1464, loss = 31326943420.30887222\n",
            "Iteration 1465, loss = 31305907061.82478714\n",
            "Iteration 1466, loss = 31284856838.71875381\n",
            "Iteration 1467, loss = 31263792797.00317764\n",
            "Iteration 1468, loss = 31242714982.47756577\n",
            "Iteration 1469, loss = 31221623440.73405075\n",
            "Iteration 1470, loss = 31200518217.16276169\n",
            "Iteration 1471, loss = 31179399356.95699692\n",
            "Iteration 1472, loss = 31158266905.11833954\n",
            "Iteration 1473, loss = 31137120906.46158981\n",
            "Iteration 1474, loss = 31115961405.61958694\n",
            "Iteration 1475, loss = 31094788447.04783249\n",
            "Iteration 1476, loss = 31073602075.02913284\n",
            "Iteration 1477, loss = 31052402333.67796707\n",
            "Iteration 1478, loss = 31031189266.94481659\n",
            "Iteration 1479, loss = 31009962918.62042999\n",
            "Iteration 1480, loss = 30988723332.33983612\n",
            "Iteration 1481, loss = 30967470551.58636475\n",
            "Iteration 1482, loss = 30946204619.69557953\n",
            "Iteration 1483, loss = 30924925579.85898972\n",
            "Iteration 1484, loss = 30903633475.12779617\n",
            "Iteration 1485, loss = 30882328348.41645813\n",
            "Iteration 1486, loss = 30861010242.50618362\n",
            "Iteration 1487, loss = 30839679200.04836273\n",
            "Iteration 1488, loss = 30818335263.56791687\n",
            "Iteration 1489, loss = 30796978475.46648788\n",
            "Iteration 1490, loss = 30775608878.02563858\n",
            "Iteration 1491, loss = 30754226513.40990448\n",
            "Iteration 1492, loss = 30732831423.66981125\n",
            "Iteration 1493, loss = 30711423650.74483109\n",
            "Iteration 1494, loss = 30690003236.46617889\n",
            "Iteration 1495, loss = 30668570222.55966187\n",
            "Iteration 1496, loss = 30647124650.64834595\n",
            "Iteration 1497, loss = 30625666562.25522232\n",
            "Iteration 1498, loss = 30604195998.80579376\n",
            "Iteration 1499, loss = 30582713001.63061142\n",
            "Iteration 1500, loss = 30561217611.96768188\n",
            "Iteration 1501, loss = 30539709870.96495438\n",
            "Iteration 1502, loss = 30518189819.68255997\n",
            "Iteration 1503, loss = 30496657499.09518051\n",
            "Iteration 1504, loss = 30475112950.09423065\n",
            "Iteration 1505, loss = 30453556213.49003601\n",
            "Iteration 1506, loss = 30431987330.01399612\n",
            "Iteration 1507, loss = 30410406340.32061768\n",
            "Iteration 1508, loss = 30388813284.98954773\n",
            "Iteration 1509, loss = 30367208204.52754593\n",
            "Iteration 1510, loss = 30345591139.37044907\n",
            "Iteration 1511, loss = 30323962129.88497543\n",
            "Iteration 1512, loss = 30302321216.37065125\n",
            "Iteration 1513, loss = 30280668439.06156921\n",
            "Iteration 1514, loss = 30259003838.12813187\n",
            "Iteration 1515, loss = 30237327453.67875671\n",
            "Iteration 1516, loss = 30215639325.76158142\n",
            "Iteration 1517, loss = 30193939494.36610031\n",
            "Iteration 1518, loss = 30172227999.42468643\n",
            "Iteration 1519, loss = 30150504880.81425858\n",
            "Iteration 1520, loss = 30128770178.35774612\n",
            "Iteration 1521, loss = 30107023931.77510452\n",
            "Iteration 1522, loss = 30085242625.13784790\n",
            "Iteration 1523, loss = 30063445115.47478485\n",
            "Iteration 1524, loss = 30041620061.10245514\n",
            "Iteration 1525, loss = 30019766983.26517487\n",
            "Iteration 1526, loss = 29997884767.70531082\n",
            "Iteration 1527, loss = 29975972258.99426270\n",
            "Iteration 1528, loss = 29954028415.04046249\n",
            "Iteration 1529, loss = 29932052350.52709579\n",
            "Iteration 1530, loss = 29910043342.12839508\n",
            "Iteration 1531, loss = 29888000819.45928955\n",
            "Iteration 1532, loss = 29865924351.05633163\n",
            "Iteration 1533, loss = 29843813629.25472260\n",
            "Iteration 1534, loss = 29821668455.57345963\n",
            "Iteration 1535, loss = 29799488727.23194885\n",
            "Iteration 1536, loss = 29777274424.97958755\n",
            "Iteration 1537, loss = 29755025602.22646332\n",
            "Iteration 1538, loss = 29732742375.38464355\n",
            "Iteration 1539, loss = 29710424915.30405045\n",
            "Iteration 1540, loss = 29688073439.68506622\n",
            "Iteration 1541, loss = 29665688206.35757828\n",
            "Iteration 1542, loss = 29643269507.32793045\n",
            "Iteration 1543, loss = 29620817663.50602341\n",
            "Iteration 1544, loss = 29598333020.03618622\n",
            "Iteration 1545, loss = 29575815942.16438675\n",
            "Iteration 1546, loss = 29553266811.58267593\n",
            "Iteration 1547, loss = 29530686023.19894409\n",
            "Iteration 1548, loss = 29508073982.28610611\n",
            "Iteration 1549, loss = 29485431101.96964645\n",
            "Iteration 1550, loss = 29462757801.01779938\n",
            "Iteration 1551, loss = 29440054501.90156555\n",
            "Iteration 1552, loss = 29417321629.09626389\n",
            "Iteration 1553, loss = 29394559607.59833908\n",
            "Iteration 1554, loss = 29371768861.63488770\n",
            "Iteration 1555, loss = 29348949813.54469299\n",
            "Iteration 1556, loss = 29326102882.81267929\n",
            "Iteration 1557, loss = 29303228485.24065781\n",
            "Iteration 1558, loss = 29280327032.23989487\n",
            "Iteration 1559, loss = 29257398930.23177719\n",
            "Iteration 1560, loss = 29234444580.14453888\n",
            "Iteration 1561, loss = 29211464376.99542618\n",
            "Iteration 1562, loss = 29188458709.54833984\n",
            "Iteration 1563, loss = 29165427960.03849792\n",
            "Iteration 1564, loss = 29142372503.95613098\n",
            "Iteration 1565, loss = 29119292709.88226700\n",
            "Iteration 1566, loss = 29096188939.37037659\n",
            "Iteration 1567, loss = 29073061546.86821747\n",
            "Iteration 1568, loss = 29049910879.67488098\n",
            "Iteration 1569, loss = 29026737277.92847443\n",
            "Iteration 1570, loss = 29003541074.62052536\n",
            "Iteration 1571, loss = 28980322595.63360596\n",
            "Iteration 1572, loss = 28957082159.79855728\n",
            "Iteration 1573, loss = 28933820078.96915817\n",
            "Iteration 1574, loss = 28910536658.11093140\n",
            "Iteration 1575, loss = 28887232195.40253830\n",
            "Iteration 1576, loss = 28863906982.34723282\n",
            "Iteration 1577, loss = 28840561303.89291763\n",
            "Iteration 1578, loss = 28817195438.55902481\n",
            "Iteration 1579, loss = 28793809658.56891251\n",
            "Iteration 1580, loss = 28770392389.42162704\n",
            "Iteration 1581, loss = 28746933519.52397156\n",
            "Iteration 1582, loss = 28723412117.47620773\n",
            "Iteration 1583, loss = 28699814644.40009689\n",
            "Iteration 1584, loss = 28676129467.83722687\n",
            "Iteration 1585, loss = 28652346560.44384003\n",
            "Iteration 1586, loss = 28628457346.51605988\n",
            "Iteration 1587, loss = 28604454562.51910782\n",
            "Iteration 1588, loss = 28580332122.28099823\n",
            "Iteration 1589, loss = 28556084990.41396332\n",
            "Iteration 1590, loss = 28531709065.95453262\n",
            "Iteration 1591, loss = 28507201076.63914490\n",
            "Iteration 1592, loss = 28482558483.45501328\n",
            "Iteration 1593, loss = 28457779394.78417206\n",
            "Iteration 1594, loss = 28432862489.35190201\n",
            "Iteration 1595, loss = 28407806947.18320847\n",
            "Iteration 1596, loss = 28382612387.80617523\n",
            "Iteration 1597, loss = 28357278814.99409485\n",
            "Iteration 1598, loss = 28331803808.38004684\n",
            "Iteration 1599, loss = 28306186116.62822723\n",
            "Iteration 1600, loss = 28280422098.54221344\n",
            "Iteration 1601, loss = 28254509982.68135452\n",
            "Iteration 1602, loss = 28228448569.43820953\n",
            "Iteration 1603, loss = 28202237139.82229233\n",
            "Iteration 1604, loss = 28175875398.83391190\n",
            "Iteration 1605, loss = 28149363426.01613998\n",
            "Iteration 1606, loss = 28122701629.70219421\n",
            "Iteration 1607, loss = 28095890705.09143066\n",
            "Iteration 1608, loss = 28068931596.27054977\n",
            "Iteration 1609, loss = 28041825462.06141281\n",
            "Iteration 1610, loss = 28014573645.44989014\n",
            "Iteration 1611, loss = 27987177646.30330276\n",
            "Iteration 1612, loss = 27959639097.07633209\n",
            "Iteration 1613, loss = 27931959741.21789169\n",
            "Iteration 1614, loss = 27904141414.00977325\n",
            "Iteration 1615, loss = 27876186025.59080124\n",
            "Iteration 1616, loss = 27848095545.94152069\n",
            "Iteration 1617, loss = 27819871991.62666702\n",
            "Iteration 1618, loss = 27791517414.11120987\n",
            "Iteration 1619, loss = 27763033889.48516083\n",
            "Iteration 1620, loss = 27734423509.44771957\n",
            "Iteration 1621, loss = 27705688373.41739655\n",
            "Iteration 1622, loss = 27676830581.64748001\n",
            "Iteration 1623, loss = 27647852229.23891830\n",
            "Iteration 1624, loss = 27618755400.95362091\n",
            "Iteration 1625, loss = 27589542166.74108124\n",
            "Iteration 1626, loss = 27560214577.90010452\n",
            "Iteration 1627, loss = 27530774663.80566025\n",
            "Iteration 1628, loss = 27501224429.13790512\n",
            "Iteration 1629, loss = 27471565851.55708694\n",
            "Iteration 1630, loss = 27441800879.77362823\n",
            "Iteration 1631, loss = 27411931431.96841049\n",
            "Iteration 1632, loss = 27381959394.52246094\n",
            "Iteration 1633, loss = 27351886621.01984024\n",
            "Iteration 1634, loss = 27321714931.49129486\n",
            "Iteration 1635, loss = 27291446111.86951065\n",
            "Iteration 1636, loss = 27261081913.63003159\n",
            "Iteration 1637, loss = 27230624053.59463501\n",
            "Iteration 1638, loss = 27200074213.87648010\n",
            "Iteration 1639, loss = 27169434041.94829559\n",
            "Iteration 1640, loss = 27138705150.81744003\n",
            "Iteration 1641, loss = 27107889119.29284668\n",
            "Iteration 1642, loss = 27076987492.33086014\n",
            "Iteration 1643, loss = 27046001781.44840240\n",
            "Iteration 1644, loss = 27014933465.19287109\n",
            "Iteration 1645, loss = 26983783989.65988541\n",
            "Iteration 1646, loss = 26952554769.05047226\n",
            "Iteration 1647, loss = 26921247186.26070023\n",
            "Iteration 1648, loss = 26889862593.49718857\n",
            "Iteration 1649, loss = 26858402312.91297531\n",
            "Iteration 1650, loss = 26826867637.25885010\n",
            "Iteration 1651, loss = 26795259830.54565048\n",
            "Iteration 1652, loss = 26763580128.71380615\n",
            "Iteration 1653, loss = 26731829740.30679703\n",
            "Iteration 1654, loss = 26700009847.14558411\n",
            "Iteration 1655, loss = 26668121605.00144577\n",
            "Iteration 1656, loss = 26636166144.26526642\n",
            "Iteration 1657, loss = 26604144570.61098099\n",
            "Iteration 1658, loss = 26572057965.65203857\n",
            "Iteration 1659, loss = 26539907387.58910751\n",
            "Iteration 1660, loss = 26507693871.84818268\n",
            "Iteration 1661, loss = 26475418431.70792770\n",
            "Iteration 1662, loss = 26443082058.91556168\n",
            "Iteration 1663, loss = 26410685724.29061127\n",
            "Iteration 1664, loss = 26378230378.31595230\n",
            "Iteration 1665, loss = 26345716951.71578598\n",
            "Iteration 1666, loss = 26313146356.02042389\n",
            "Iteration 1667, loss = 26280519484.11726761\n",
            "Iteration 1668, loss = 26247837210.78825760\n",
            "Iteration 1669, loss = 26215100393.23350143\n",
            "Iteration 1670, loss = 26182309871.58117294\n",
            "Iteration 1671, loss = 26149466469.38356781\n",
            "Iteration 1672, loss = 26116570994.09970093\n",
            "Iteration 1673, loss = 26083624237.56431961\n",
            "Iteration 1674, loss = 26050626976.44359207\n",
            "Iteration 1675, loss = 26017579972.67762375\n",
            "Iteration 1676, loss = 25984483973.91010284\n",
            "Iteration 1677, loss = 25951339713.90516281\n",
            "Iteration 1678, loss = 25918147912.95191193\n",
            "Iteration 1679, loss = 25884909278.25663757\n",
            "Iteration 1680, loss = 25851624504.32320404\n",
            "Iteration 1681, loss = 25818294273.32173538\n",
            "Iteration 1682, loss = 25784919255.44598389\n",
            "Iteration 1683, loss = 25751500109.25960159\n",
            "Iteration 1684, loss = 25718037482.03166199\n",
            "Iteration 1685, loss = 25684532010.06165314\n",
            "Iteration 1686, loss = 25650984318.99431610\n",
            "Iteration 1687, loss = 25617395024.12459564\n",
            "Iteration 1688, loss = 25583764730.69282532\n",
            "Iteration 1689, loss = 25550094034.17077637\n",
            "Iteration 1690, loss = 25516383520.53849030\n",
            "Iteration 1691, loss = 25482633766.55240631\n",
            "Iteration 1692, loss = 25448845340.00494766\n",
            "Iteration 1693, loss = 25415018799.97581482\n",
            "Iteration 1694, loss = 25381154697.07541275\n",
            "Iteration 1695, loss = 25347253573.68035889\n",
            "Iteration 1696, loss = 25313315964.16168594\n",
            "Iteration 1697, loss = 25279342395.10564041\n",
            "Iteration 1698, loss = 25245333385.52759171\n",
            "Iteration 1699, loss = 25211289447.07898712\n",
            "Iteration 1700, loss = 25177211084.24802017\n",
            "Iteration 1701, loss = 25143098794.55360031\n",
            "Iteration 1702, loss = 25108953068.73353958\n",
            "Iteration 1703, loss = 25074774390.92649078\n",
            "Iteration 1704, loss = 25040563238.84836578\n",
            "Iteration 1705, loss = 25006320083.96313858\n",
            "Iteration 1706, loss = 24972045391.64825821\n",
            "Iteration 1707, loss = 24937739621.35493469\n",
            "Iteration 1708, loss = 24903403226.76334763\n",
            "Iteration 1709, loss = 24869036655.93313980\n",
            "Iteration 1710, loss = 24834640351.44906998\n",
            "Iteration 1711, loss = 24800214750.56232834\n",
            "Iteration 1712, loss = 24765760285.32731247\n",
            "Iteration 1713, loss = 24731277382.73427582\n",
            "Iteration 1714, loss = 24696766464.83800125\n",
            "Iteration 1715, loss = 24662227948.88220596\n",
            "Iteration 1716, loss = 24627662247.42057419\n",
            "Iteration 1717, loss = 24593069768.43377686\n",
            "Iteration 1718, loss = 24558450915.44300079\n",
            "Iteration 1719, loss = 24523806087.62025452\n",
            "Iteration 1720, loss = 24489135679.89496231\n",
            "Iteration 1721, loss = 24454440083.05775070\n",
            "Iteration 1722, loss = 24419719683.86085892\n",
            "Iteration 1723, loss = 24384974865.11564636\n",
            "Iteration 1724, loss = 24350206005.78722000\n",
            "Iteration 1725, loss = 24315413481.08611298\n",
            "Iteration 1726, loss = 24280597662.55753326\n",
            "Iteration 1727, loss = 24245758918.16765213\n",
            "Iteration 1728, loss = 24210897612.38765335\n",
            "Iteration 1729, loss = 24176014106.27506638\n",
            "Iteration 1730, loss = 24141108757.55291748\n",
            "Iteration 1731, loss = 24106181920.68654633\n",
            "Iteration 1732, loss = 24071233946.95811844\n",
            "Iteration 1733, loss = 24036265184.53906250\n",
            "Iteration 1734, loss = 24001275978.56044769\n",
            "Iteration 1735, loss = 23966266671.18122864\n",
            "Iteration 1736, loss = 23931237601.65468597\n",
            "Iteration 1737, loss = 23896189106.39289474\n",
            "Iteration 1738, loss = 23861121519.02943420\n",
            "Iteration 1739, loss = 23826035170.48021698\n",
            "Iteration 1740, loss = 23790930389.00271606\n",
            "Iteration 1741, loss = 23755807500.25349426\n",
            "Iteration 1742, loss = 23720666827.34414291\n",
            "Iteration 1743, loss = 23685508690.89562607\n",
            "Iteration 1744, loss = 23650333409.09116745\n",
            "Iteration 1745, loss = 23615141297.72768021\n",
            "Iteration 1746, loss = 23579932670.26570892\n",
            "Iteration 1747, loss = 23544707837.87812042\n",
            "Iteration 1748, loss = 23509467109.49733734\n",
            "Iteration 1749, loss = 23474210791.86140060\n",
            "Iteration 1750, loss = 23438939189.55871582\n",
            "Iteration 1751, loss = 23403652605.07166290\n",
            "Iteration 1752, loss = 23368351338.81885147\n",
            "Iteration 1753, loss = 23333035689.19653702\n",
            "Iteration 1754, loss = 23297705952.61866760\n",
            "Iteration 1755, loss = 23262362423.55596924\n",
            "Iteration 1756, loss = 23227005394.57402802\n",
            "Iteration 1757, loss = 23191635156.37031174\n",
            "Iteration 1758, loss = 23156251997.81021118\n",
            "Iteration 1759, loss = 23120856205.96215057\n",
            "Iteration 1760, loss = 23085448066.13186264\n",
            "Iteration 1761, loss = 23050027861.89558411\n",
            "Iteration 1762, loss = 23014595875.13257599\n",
            "Iteration 1763, loss = 22979152386.05665588\n",
            "Iteration 1764, loss = 22943697673.24703217\n",
            "Iteration 1765, loss = 22908232013.67828369\n",
            "Iteration 1766, loss = 22872755682.74957275\n",
            "Iteration 1767, loss = 22837268954.31308746\n",
            "Iteration 1768, loss = 22801772100.70182419\n",
            "Iteration 1769, loss = 22766265392.75665283\n",
            "Iteration 1770, loss = 22730749099.85258484\n",
            "Iteration 1771, loss = 22695223489.92460251\n",
            "Iteration 1772, loss = 22659688829.49252701\n",
            "Iteration 1773, loss = 22624145383.68556976\n",
            "Iteration 1774, loss = 22588593416.26609421\n",
            "Iteration 1775, loss = 22553033189.65280533\n",
            "Iteration 1776, loss = 22517464964.94339371\n",
            "Iteration 1777, loss = 22481889001.93662262\n",
            "Iteration 1778, loss = 22446305559.15379333\n",
            "Iteration 1779, loss = 22410714893.85981750\n",
            "Iteration 1780, loss = 22375117262.08360672\n",
            "Iteration 1781, loss = 22339512918.63809967\n",
            "Iteration 1782, loss = 22303902117.13974762\n",
            "Iteration 1783, loss = 22268285110.02746582\n",
            "Iteration 1784, loss = 22232662148.58123398\n",
            "Iteration 1785, loss = 22197033482.94015503\n",
            "Iteration 1786, loss = 22161399362.12009430\n",
            "Iteration 1787, loss = 22125760034.03097153\n",
            "Iteration 1788, loss = 22090115745.49348831\n",
            "Iteration 1789, loss = 22054466742.25559235\n",
            "Iteration 1790, loss = 22018813269.00843048\n",
            "Iteration 1791, loss = 21983155569.40205765\n",
            "Iteration 1792, loss = 21947493886.06060028\n",
            "Iteration 1793, loss = 21911828460.59722519\n",
            "Iteration 1794, loss = 21876159533.62858200\n",
            "Iteration 1795, loss = 21840487344.78909683\n",
            "Iteration 1796, loss = 21804812132.74473953\n",
            "Iteration 1797, loss = 21769134135.20656586\n",
            "Iteration 1798, loss = 21733453588.94396210\n",
            "Iteration 1799, loss = 21697770729.79748154\n",
            "Iteration 1800, loss = 21662085792.69146347\n",
            "Iteration 1801, loss = 21626399011.64632034\n",
            "Iteration 1802, loss = 21590710619.79051971\n",
            "Iteration 1803, loss = 21555020849.37233734\n",
            "Iteration 1804, loss = 21519329931.77128601\n",
            "Iteration 1805, loss = 21483638097.50929260\n",
            "Iteration 1806, loss = 21447945576.26161575\n",
            "Iteration 1807, loss = 21412252596.86751175\n",
            "Iteration 1808, loss = 21376559387.34065628\n",
            "Iteration 1809, loss = 21340866174.87930679\n",
            "Iteration 1810, loss = 21305173185.87622452\n",
            "Iteration 1811, loss = 21269480645.92841721\n",
            "Iteration 1812, loss = 21233788779.84659958\n",
            "Iteration 1813, loss = 21198097811.66441345\n",
            "Iteration 1814, loss = 21162407964.64754105\n",
            "Iteration 1815, loss = 21126719461.30251694\n",
            "Iteration 1816, loss = 21091032523.38531876\n",
            "Iteration 1817, loss = 21055347371.90986252\n",
            "Iteration 1818, loss = 21019664227.15619659\n",
            "Iteration 1819, loss = 20983983308.67856216\n",
            "Iteration 1820, loss = 20948304835.31326675\n",
            "Iteration 1821, loss = 20912629025.18633652\n",
            "Iteration 1822, loss = 20876956095.72105789\n",
            "Iteration 1823, loss = 20841286263.64525604\n",
            "Iteration 1824, loss = 20805619744.99850464\n",
            "Iteration 1825, loss = 20769956755.13909912\n",
            "Iteration 1826, loss = 20734297508.75088501\n",
            "Iteration 1827, loss = 20698642219.84995270\n",
            "Iteration 1828, loss = 20662991101.79114151\n",
            "Iteration 1829, loss = 20627344367.27441788\n",
            "Iteration 1830, loss = 20591702228.35112000\n",
            "Iteration 1831, loss = 20556064896.42998886\n",
            "Iteration 1832, loss = 20520432582.28318024\n",
            "Iteration 1833, loss = 20484805496.05200577\n",
            "Iteration 1834, loss = 20449183847.25261307\n",
            "Iteration 1835, loss = 20413567844.78157425\n",
            "Iteration 1836, loss = 20377957696.92121124\n",
            "Iteration 1837, loss = 20342353611.34495544\n",
            "Iteration 1838, loss = 20306755795.12245178\n",
            "Iteration 1839, loss = 20271164454.72464752\n",
            "Iteration 1840, loss = 20235579796.02865982\n",
            "Iteration 1841, loss = 20200002024.32265472\n",
            "Iteration 1842, loss = 20164431344.31046677\n",
            "Iteration 1843, loss = 20128867960.11623001\n",
            "Iteration 1844, loss = 20093312075.28887939\n",
            "Iteration 1845, loss = 20057763892.80642700\n",
            "Iteration 1846, loss = 20022223615.08035278\n",
            "Iteration 1847, loss = 19986691443.95969772\n",
            "Iteration 1848, loss = 19951167580.73514557\n",
            "Iteration 1849, loss = 19915652226.14301682\n",
            "Iteration 1850, loss = 19880145580.36912537\n",
            "Iteration 1851, loss = 19844647843.05258179\n",
            "Iteration 1852, loss = 19809159213.28948975\n",
            "Iteration 1853, loss = 19773679889.63652802\n",
            "Iteration 1854, loss = 19738210070.11452103\n",
            "Iteration 1855, loss = 19702749952.21181107\n",
            "Iteration 1856, loss = 19667299732.88767624\n",
            "Iteration 1857, loss = 19631859608.57555008\n",
            "Iteration 1858, loss = 19596429775.18625259\n",
            "Iteration 1859, loss = 19561010428.11108398\n",
            "Iteration 1860, loss = 19525601762.22484207\n",
            "Iteration 1861, loss = 19490203971.88881683\n",
            "Iteration 1862, loss = 19454817250.95369720\n",
            "Iteration 1863, loss = 19419441792.76231766\n",
            "Iteration 1864, loss = 19384077790.15248108\n",
            "Iteration 1865, loss = 19348725435.45958328\n",
            "Iteration 1866, loss = 19313384920.51925278\n",
            "Iteration 1867, loss = 19278056436.66988754\n",
            "Iteration 1868, loss = 19242740174.75511551\n",
            "Iteration 1869, loss = 19207436325.12625885\n",
            "Iteration 1870, loss = 19172145077.64461517\n",
            "Iteration 1871, loss = 19136866621.68381882\n",
            "Iteration 1872, loss = 19101601146.13203812\n",
            "Iteration 1873, loss = 19066348839.39416122\n",
            "Iteration 1874, loss = 19031109889.39389420\n",
            "Iteration 1875, loss = 18995884483.57584381\n",
            "Iteration 1876, loss = 18960672808.90751266\n",
            "Iteration 1877, loss = 18925475051.88124466\n",
            "Iteration 1878, loss = 18890291398.51615143\n",
            "Iteration 1879, loss = 18855122034.35992050\n",
            "Iteration 1880, loss = 18819967144.49061584\n",
            "Iteration 1881, loss = 18784826913.51845551\n",
            "Iteration 1882, loss = 18749701525.58748245\n",
            "Iteration 1883, loss = 18714591164.37720871\n",
            "Iteration 1884, loss = 18679496013.10423279\n",
            "Iteration 1885, loss = 18644416254.52377701\n",
            "Iteration 1886, loss = 18609352070.93120956\n",
            "Iteration 1887, loss = 18574303644.16351700\n",
            "Iteration 1888, loss = 18539271155.60070038\n",
            "Iteration 1889, loss = 18504254786.16718674\n",
            "Iteration 1890, loss = 18469254716.33314133\n",
            "Iteration 1891, loss = 18434271126.11576462\n",
            "Iteration 1892, loss = 18399304195.08056259\n",
            "Iteration 1893, loss = 18364354102.34255219\n",
            "Iteration 1894, loss = 18329421026.56746292\n",
            "Iteration 1895, loss = 18294505145.97281265\n",
            "Iteration 1896, loss = 18259606638.32909775\n",
            "Iteration 1897, loss = 18224725680.96080017\n",
            "Iteration 1898, loss = 18189862450.74740601\n",
            "Iteration 1899, loss = 18155017124.12447357\n",
            "Iteration 1900, loss = 18120189877.08449554\n",
            "Iteration 1901, loss = 18085380885.17791367\n",
            "Iteration 1902, loss = 18050590323.51395035\n",
            "Iteration 1903, loss = 18015818366.76150513\n",
            "Iteration 1904, loss = 17981065189.14995575\n",
            "Iteration 1905, loss = 17946330964.46998978\n",
            "Iteration 1906, loss = 17911615866.07434082\n",
            "Iteration 1907, loss = 17876920066.87849426\n",
            "Iteration 1908, loss = 17842243739.36151123\n",
            "Iteration 1909, loss = 17807587055.56656265\n",
            "Iteration 1910, loss = 17772950187.10166550\n",
            "Iteration 1911, loss = 17738333305.14028168\n",
            "Iteration 1912, loss = 17703736580.42191315\n",
            "Iteration 1913, loss = 17669160183.25265884\n",
            "Iteration 1914, loss = 17634604283.50575638\n",
            "Iteration 1915, loss = 17600069050.62210083\n",
            "Iteration 1916, loss = 17565554653.61074066\n",
            "Iteration 1917, loss = 17531061261.04932785\n",
            "Iteration 1918, loss = 17496589041.08454514\n",
            "Iteration 1919, loss = 17462138161.43255997\n",
            "Iteration 1920, loss = 17427708789.37937546\n",
            "Iteration 1921, loss = 17393301091.78122330\n",
            "Iteration 1922, loss = 17358915235.06488419\n",
            "Iteration 1923, loss = 17324551385.22803116\n",
            "Iteration 1924, loss = 17290209707.83953857\n",
            "Iteration 1925, loss = 17255890368.03972244\n",
            "Iteration 1926, loss = 17221593530.54064178\n",
            "Iteration 1927, loss = 17187319359.62630844\n",
            "Iteration 1928, loss = 17153068019.15290833\n",
            "Iteration 1929, loss = 17118839672.54901695\n",
            "Iteration 1930, loss = 17084634482.81572914\n",
            "Iteration 1931, loss = 17050452612.52689362\n",
            "Iteration 1932, loss = 17016294223.82918358\n",
            "Iteration 1933, loss = 16982159478.44223022\n",
            "Iteration 1934, loss = 16948048537.65876770\n",
            "Iteration 1935, loss = 16913961562.34466743\n",
            "Iteration 1936, loss = 16879898712.93902016\n",
            "Iteration 1937, loss = 16845860149.45421219\n",
            "Iteration 1938, loss = 16811846031.47591972\n",
            "Iteration 1939, loss = 16777856518.16315651\n",
            "Iteration 1940, loss = 16743891768.24826241\n",
            "Iteration 1941, loss = 16709951940.03686905\n",
            "Iteration 1942, loss = 16676037191.40789795\n",
            "Iteration 1943, loss = 16642147679.81350517\n",
            "Iteration 1944, loss = 16608283562.27902031\n",
            "Iteration 1945, loss = 16574444995.40286827\n",
            "Iteration 1946, loss = 16540632135.35647202\n",
            "Iteration 1947, loss = 16506845137.88416672\n",
            "Iteration 1948, loss = 16473084158.30305862\n",
            "Iteration 1949, loss = 16439349351.50292015\n",
            "Iteration 1950, loss = 16405640871.94600487\n",
            "Iteration 1951, loss = 16371958873.66693306\n",
            "Iteration 1952, loss = 16338303510.27249908\n",
            "Iteration 1953, loss = 16304674934.94147110\n",
            "Iteration 1954, loss = 16271073300.42443466\n",
            "Iteration 1955, loss = 16237498759.04355240\n",
            "Iteration 1956, loss = 16203951462.69235039\n",
            "Iteration 1957, loss = 16170431562.83548164\n",
            "Iteration 1958, loss = 16136939210.50851822\n",
            "Iteration 1959, loss = 16103474556.31764793\n",
            "Iteration 1960, loss = 16070037750.43943405\n",
            "Iteration 1961, loss = 16036628942.62052345\n",
            "Iteration 1962, loss = 16003248282.17739487\n",
            "Iteration 1963, loss = 15969895917.99603271\n",
            "Iteration 1964, loss = 15936571998.53160477\n",
            "Iteration 1965, loss = 15903276671.80819321\n",
            "Iteration 1966, loss = 15870010085.41843414\n",
            "Iteration 1967, loss = 15836772386.52317619\n",
            "Iteration 1968, loss = 15803563721.85116005\n",
            "Iteration 1969, loss = 15770384237.69865990\n",
            "Iteration 1970, loss = 15737234079.92908478\n",
            "Iteration 1971, loss = 15704113393.97265625\n",
            "Iteration 1972, loss = 15671022324.82599831\n",
            "Iteration 1973, loss = 15637961017.05175018\n",
            "Iteration 1974, loss = 15604929614.77819443\n",
            "Iteration 1975, loss = 15571928261.69880104\n",
            "Iteration 1976, loss = 15538957101.07186508\n",
            "Iteration 1977, loss = 15506016275.72005844\n",
            "Iteration 1978, loss = 15473105928.03002548\n",
            "Iteration 1979, loss = 15440226199.95190620\n",
            "Iteration 1980, loss = 15407377232.99893761\n",
            "Iteration 1981, loss = 15374559168.24698257\n",
            "Iteration 1982, loss = 15341772146.33407402\n",
            "Iteration 1983, loss = 15309016307.45994759\n",
            "Iteration 1984, loss = 15276291791.38560295\n",
            "Iteration 1985, loss = 15243598737.43277931\n",
            "Iteration 1986, loss = 15210937284.48351860\n",
            "Iteration 1987, loss = 15178307570.97965431\n",
            "Iteration 1988, loss = 15145709734.92229843\n",
            "Iteration 1989, loss = 15113143913.87140274\n",
            "Iteration 1990, loss = 15080610244.94517899\n",
            "Iteration 1991, loss = 15048108864.81965065\n",
            "Iteration 1992, loss = 15015639909.72810745\n",
            "Iteration 1993, loss = 14983203515.46055794\n",
            "Iteration 1994, loss = 14950799817.36328316\n",
            "Iteration 1995, loss = 14918428950.33821487\n",
            "Iteration 1996, loss = 14886091048.84245300\n",
            "Iteration 1997, loss = 14853786246.88772583\n",
            "Iteration 1998, loss = 14821514678.03979301\n",
            "Iteration 1999, loss = 14789276475.41797256\n",
            "Iteration 2000, loss = 14757071771.69454193\n",
            "Iteration 2001, loss = 14724900699.09415627\n",
            "Iteration 2002, loss = 14692763389.39335823\n",
            "Iteration 2003, loss = 14660659973.91994476\n",
            "Iteration 2004, loss = 14628590583.55241585\n",
            "Iteration 2005, loss = 14596555348.71943665\n",
            "Iteration 2006, loss = 14564554399.39920616\n",
            "Iteration 2007, loss = 14532587865.11891937\n",
            "Iteration 2008, loss = 14500655874.95414734\n",
            "Iteration 2009, loss = 14468758557.52830696\n",
            "Iteration 2010, loss = 14436896041.01197433\n",
            "Iteration 2011, loss = 14405068453.12242126\n",
            "Iteration 2012, loss = 14373275921.12288857\n",
            "Iteration 2013, loss = 14341518571.82208633\n",
            "Iteration 2014, loss = 14309796531.57354164\n",
            "Iteration 2015, loss = 14278109926.27500343\n",
            "Iteration 2016, loss = 14246458881.36785126\n",
            "Iteration 2017, loss = 14214843521.83645821\n",
            "Iteration 2018, loss = 14183263972.20762634\n",
            "Iteration 2019, loss = 14151720356.54990578\n",
            "Iteration 2020, loss = 14120212798.47304916\n",
            "Iteration 2021, loss = 14088741421.12734413\n",
            "Iteration 2022, loss = 14057306347.20304489\n",
            "Iteration 2023, loss = 14025907698.92967606\n",
            "Iteration 2024, loss = 13994545598.07547760\n",
            "Iteration 2025, loss = 13963220165.94676399\n",
            "Iteration 2026, loss = 13931931523.38728333\n",
            "Iteration 2027, loss = 13900679790.77759933\n",
            "Iteration 2028, loss = 13869465088.03446579\n",
            "Iteration 2029, loss = 13838287534.61018753\n",
            "Iteration 2030, loss = 13807147249.49201393\n",
            "Iteration 2031, loss = 13776044351.20147514\n",
            "Iteration 2032, loss = 13744978957.79376030\n",
            "Iteration 2033, loss = 13713951186.85711288\n",
            "Iteration 2034, loss = 13682961155.51214218\n",
            "Iteration 2035, loss = 13652008980.41125298\n",
            "Iteration 2036, loss = 13621094777.73793221\n",
            "Iteration 2037, loss = 13590218663.20619202\n",
            "Iteration 2038, loss = 13559380752.05988503\n",
            "Iteration 2039, loss = 13528581159.07208252\n",
            "Iteration 2040, loss = 13497819998.54442406\n",
            "Iteration 2041, loss = 13467097384.30651093\n",
            "Iteration 2042, loss = 13436413429.71523094\n",
            "Iteration 2043, loss = 13405768247.65415382\n",
            "Iteration 2044, loss = 13375161950.53286743\n",
            "Iteration 2045, loss = 13344594650.28634644\n",
            "Iteration 2046, loss = 13314066458.37433815\n",
            "Iteration 2047, loss = 13283577485.78070068\n",
            "Iteration 2048, loss = 13253127843.01276970\n",
            "Iteration 2049, loss = 13222717640.10072899\n",
            "Iteration 2050, loss = 13192346986.59696960\n",
            "Iteration 2051, loss = 13162015991.57546043\n",
            "Iteration 2052, loss = 13131724763.63111305\n",
            "Iteration 2053, loss = 13101473410.87913895\n",
            "Iteration 2054, loss = 13071262040.95443344\n",
            "Iteration 2055, loss = 13041090761.01091766\n",
            "Iteration 2056, loss = 13010959677.72093773\n",
            "Iteration 2057, loss = 12980868897.27460289\n",
            "Iteration 2058, loss = 12950818525.37919044\n",
            "Iteration 2059, loss = 12920808667.25848389\n",
            "Iteration 2060, loss = 12890839427.65217400\n",
            "Iteration 2061, loss = 12860910910.81520653\n",
            "Iteration 2062, loss = 12831023220.51719856\n",
            "Iteration 2063, loss = 12801176460.04174995\n",
            "Iteration 2064, loss = 12771370732.18590164\n",
            "Iteration 2065, loss = 12741606139.25945091\n",
            "Iteration 2066, loss = 12711882783.08435631\n",
            "Iteration 2067, loss = 12682200764.99413681\n",
            "Iteration 2068, loss = 12652560185.83321953\n",
            "Iteration 2069, loss = 12622961145.95636559\n",
            "Iteration 2070, loss = 12593403745.22802734\n",
            "Iteration 2071, loss = 12563888083.02176857\n",
            "Iteration 2072, loss = 12534414258.21962547\n",
            "Iteration 2073, loss = 12504982369.21152687\n",
            "Iteration 2074, loss = 12475592513.89465904\n",
            "Iteration 2075, loss = 12446244789.67290688\n",
            "Iteration 2076, loss = 12416939293.45623207\n",
            "Iteration 2077, loss = 12387676121.66004562\n",
            "Iteration 2078, loss = 12358455370.20468140\n",
            "Iteration 2079, loss = 12329277134.51473808\n",
            "Iteration 2080, loss = 12300141509.51853752\n",
            "Iteration 2081, loss = 12271048589.64749718\n",
            "Iteration 2082, loss = 12241998468.83557320\n",
            "Iteration 2083, loss = 12212991240.51867104\n",
            "Iteration 2084, loss = 12184026997.63406181\n",
            "Iteration 2085, loss = 12155105832.61979103\n",
            "Iteration 2086, loss = 12126227837.41414833\n",
            "Iteration 2087, loss = 12097393103.45505524\n",
            "Iteration 2088, loss = 12068601721.67949295\n",
            "Iteration 2089, loss = 12039853782.52297974\n",
            "Iteration 2090, loss = 12011149375.91896629\n",
            "Iteration 2091, loss = 11982488591.29827499\n",
            "Iteration 2092, loss = 11953871517.58859062\n",
            "Iteration 2093, loss = 11925298243.21386337\n",
            "Iteration 2094, loss = 11896768856.09375381\n",
            "Iteration 2095, loss = 11868283443.64312363\n",
            "Iteration 2096, loss = 11839842092.77146149\n",
            "Iteration 2097, loss = 11811444889.88234329\n",
            "Iteration 2098, loss = 11783091920.87291908\n",
            "Iteration 2099, loss = 11754783271.13335800\n",
            "Iteration 2100, loss = 11726519025.54631233\n",
            "Iteration 2101, loss = 11698299268.48641586\n",
            "Iteration 2102, loss = 11670124083.81974411\n",
            "Iteration 2103, loss = 11641993554.90328407\n",
            "Iteration 2104, loss = 11613907764.58446884\n",
            "Iteration 2105, loss = 11585866795.20058250\n",
            "Iteration 2106, loss = 11557870728.57832336\n",
            "Iteration 2107, loss = 11529919646.03329277\n",
            "Iteration 2108, loss = 11502013628.36944199\n",
            "Iteration 2109, loss = 11474152755.87862396\n",
            "Iteration 2110, loss = 11446337108.34009743\n",
            "Iteration 2111, loss = 11418566765.02001762\n",
            "Iteration 2112, loss = 11390841804.67096710\n",
            "Iteration 2113, loss = 11363162305.53148079\n",
            "Iteration 2114, loss = 11335528345.32552910\n",
            "Iteration 2115, loss = 11307940001.26211929\n",
            "Iteration 2116, loss = 11280397350.03475571\n",
            "Iteration 2117, loss = 11252900467.82102203\n",
            "Iteration 2118, loss = 11225449430.28208351\n",
            "Iteration 2119, loss = 11198044312.56230545\n",
            "Iteration 2120, loss = 11170685189.28869438\n",
            "Iteration 2121, loss = 11143372134.57055855\n",
            "Iteration 2122, loss = 11116105221.99899101\n",
            "Iteration 2123, loss = 11088884524.64646721\n",
            "Iteration 2124, loss = 11061710115.06641769\n",
            "Iteration 2125, loss = 11034582065.29278946\n",
            "Iteration 2126, loss = 11007500446.83961296\n",
            "Iteration 2127, loss = 10980465330.70060921\n",
            "Iteration 2128, loss = 10953476787.34876633\n",
            "Iteration 2129, loss = 10926534886.73589706\n",
            "Iteration 2130, loss = 10899639698.29231834\n",
            "Iteration 2131, loss = 10872791290.92637062\n",
            "Iteration 2132, loss = 10845989733.02404976\n",
            "Iteration 2133, loss = 10819235092.44864845\n",
            "Iteration 2134, loss = 10792527436.54032326\n",
            "Iteration 2135, loss = 10765866832.11576843\n",
            "Iteration 2136, loss = 10739253345.46780014\n",
            "Iteration 2137, loss = 10712687042.36500359\n",
            "Iteration 2138, loss = 10686167988.05137634\n",
            "Iteration 2139, loss = 10659696247.24596977\n",
            "Iteration 2140, loss = 10633271884.14252663\n",
            "Iteration 2141, loss = 10606894962.40914345\n",
            "Iteration 2142, loss = 10580565545.18792915\n",
            "Iteration 2143, loss = 10554283695.09465981\n",
            "Iteration 2144, loss = 10528049474.21845436\n",
            "Iteration 2145, loss = 10501862944.12145233\n",
            "Iteration 2146, loss = 10475724165.83848953\n",
            "Iteration 2147, loss = 10449633199.87678528\n",
            "Iteration 2148, loss = 10423590106.21563339\n",
            "Iteration 2149, loss = 10397594944.30609703\n",
            "Iteration 2150, loss = 10371647773.07071304\n",
            "Iteration 2151, loss = 10345748650.90322113\n",
            "Iteration 2152, loss = 10319897635.66822815\n",
            "Iteration 2153, loss = 10294094784.70097733\n",
            "Iteration 2154, loss = 10268340154.80704880\n",
            "Iteration 2155, loss = 10242633802.26210022\n",
            "Iteration 2156, loss = 10216975782.81160355\n",
            "Iteration 2157, loss = 10191366151.67057991\n",
            "Iteration 2158, loss = 10165804963.52335548\n",
            "Iteration 2159, loss = 10140292272.52333450\n",
            "Iteration 2160, loss = 10114828132.29272079\n",
            "Iteration 2161, loss = 10089412595.92232323\n",
            "Iteration 2162, loss = 10064045715.97130775\n",
            "Iteration 2163, loss = 10038727544.46699715\n",
            "Iteration 2164, loss = 10013458132.90461540\n",
            "Iteration 2165, loss = 9988237532.24713707\n",
            "Iteration 2166, loss = 9963065792.92504501\n",
            "Iteration 2167, loss = 9937942964.83614922\n",
            "Iteration 2168, loss = 9912869097.34539413\n",
            "Iteration 2169, loss = 9887844239.28468323\n",
            "Iteration 2170, loss = 9862868438.95269585\n",
            "Iteration 2171, loss = 9837941744.11471558\n",
            "Iteration 2172, loss = 9813064202.00247002\n",
            "Iteration 2173, loss = 9788235859.31398201\n",
            "Iteration 2174, loss = 9763456762.21340561\n",
            "Iteration 2175, loss = 9738726956.33089066\n",
            "Iteration 2176, loss = 9714046486.76244545\n",
            "Iteration 2177, loss = 9689415398.06980705\n",
            "Iteration 2178, loss = 9664833734.28030396\n",
            "Iteration 2179, loss = 9640301538.88675499\n",
            "Iteration 2180, loss = 9615818854.84735489\n",
            "Iteration 2181, loss = 9591385724.58557701\n",
            "Iteration 2182, loss = 9567002189.99004936\n",
            "Iteration 2183, loss = 9542668292.41449738\n",
            "Iteration 2184, loss = 9518384072.67764282\n",
            "Iteration 2185, loss = 9494149571.06313515\n",
            "Iteration 2186, loss = 9469964827.31946754\n",
            "Iteration 2187, loss = 9445829880.65993118\n",
            "Iteration 2188, loss = 9421744769.76255226\n",
            "Iteration 2189, loss = 9397709532.77004433\n",
            "Iteration 2190, loss = 9373724207.28976250\n",
            "Iteration 2191, loss = 9349788830.39367294\n",
            "Iteration 2192, loss = 9325903438.61832428\n",
            "Iteration 2193, loss = 9302068067.96482658\n",
            "Iteration 2194, loss = 9278282753.89883423\n",
            "Iteration 2195, loss = 9254547531.35056305\n",
            "Iteration 2196, loss = 9230862434.71473694\n",
            "Iteration 2197, loss = 9207227497.85065460\n",
            "Iteration 2198, loss = 9183642754.08218384\n",
            "Iteration 2199, loss = 9160108236.19776535\n",
            "Iteration 2200, loss = 9136623976.45046997\n",
            "Iteration 2201, loss = 9113190006.55802536\n",
            "Iteration 2202, loss = 9089806357.70284271\n",
            "Iteration 2203, loss = 9066473060.53210640\n",
            "Iteration 2204, loss = 9043190145.15779877\n",
            "Iteration 2205, loss = 9019957641.15678406\n",
            "Iteration 2206, loss = 8996775577.57087135\n",
            "Iteration 2207, loss = 8973643982.90691948\n",
            "Iteration 2208, loss = 8950562885.13690948\n",
            "Iteration 2209, loss = 8927532311.69801521\n",
            "Iteration 2210, loss = 8904552289.49276543\n",
            "Iteration 2211, loss = 8881622844.88910294\n",
            "Iteration 2212, loss = 8858744003.72054672\n",
            "Iteration 2213, loss = 8835915791.28626823\n",
            "Iteration 2214, loss = 8813138232.35127640\n",
            "Iteration 2215, loss = 8790411351.14653778\n",
            "Iteration 2216, loss = 8767735171.36911583\n",
            "Iteration 2217, loss = 8745109716.18235588\n",
            "Iteration 2218, loss = 8722535008.21602058\n",
            "Iteration 2219, loss = 8700011069.56648445\n",
            "Iteration 2220, loss = 8677537921.79690552\n",
            "Iteration 2221, loss = 8655115585.93741417\n",
            "Iteration 2222, loss = 8632744082.48531151\n",
            "Iteration 2223, loss = 8610423431.40528679\n",
            "Iteration 2224, loss = 8588153652.12959480\n",
            "Iteration 2225, loss = 8565934763.55831528\n",
            "Iteration 2226, loss = 8543766784.05955029\n",
            "Iteration 2227, loss = 8521649731.46968937\n",
            "Iteration 2228, loss = 8499583623.09362125\n",
            "Iteration 2229, loss = 8477568475.70501804\n",
            "Iteration 2230, loss = 8455604305.54656410\n",
            "Iteration 2231, loss = 8433691128.33025360\n",
            "Iteration 2232, loss = 8411828959.23763752\n",
            "Iteration 2233, loss = 8390017812.92013073\n",
            "Iteration 2234, loss = 8368257703.49929714\n",
            "Iteration 2235, loss = 8346548644.56714249\n",
            "Iteration 2236, loss = 8324890649.18643093\n",
            "Iteration 2237, loss = 8303283729.89099312\n",
            "Iteration 2238, loss = 8281727898.68607235\n",
            "Iteration 2239, loss = 8260223167.04862309\n",
            "Iteration 2240, loss = 8238769545.92767906\n",
            "Iteration 2241, loss = 8217367045.74468613\n",
            "Iteration 2242, loss = 8196015676.39387321\n",
            "Iteration 2243, loss = 8174715447.24261379\n",
            "Iteration 2244, loss = 8153466367.13179493\n",
            "Iteration 2245, loss = 8132268444.37618160\n",
            "Iteration 2246, loss = 8111121686.76485348\n",
            "Iteration 2247, loss = 8090026101.56156921\n",
            "Iteration 2248, loss = 8068981695.50516987\n",
            "Iteration 2249, loss = 8047988474.81001854\n",
            "Iteration 2250, loss = 8027046445.16639996\n",
            "Iteration 2251, loss = 8006155611.74095535\n",
            "Iteration 2252, loss = 7985315979.17714977\n",
            "Iteration 2253, loss = 7964527551.59569263\n",
            "Iteration 2254, loss = 7943790332.59499073\n",
            "Iteration 2255, loss = 7923104325.25163460\n",
            "Iteration 2256, loss = 7902469532.12086964\n",
            "Iteration 2257, loss = 7881885955.23705673\n",
            "Iteration 2258, loss = 7861353596.11418533\n",
            "Iteration 2259, loss = 7840872455.74636745\n",
            "Iteration 2260, loss = 7820442534.60833359\n",
            "Iteration 2261, loss = 7800063832.65596771\n",
            "Iteration 2262, loss = 7779736349.32681751\n",
            "Iteration 2263, loss = 7759460083.54063320\n",
            "Iteration 2264, loss = 7739235033.69989586\n",
            "Iteration 2265, loss = 7719061197.69039631\n",
            "Iteration 2266, loss = 7698938572.88176441\n",
            "Iteration 2267, loss = 7678867156.12805367\n",
            "Iteration 2268, loss = 7658846943.76830864\n",
            "Iteration 2269, loss = 7638877931.62714767\n",
            "Iteration 2270, loss = 7618960115.01537037\n",
            "Iteration 2271, loss = 7599093488.73053646\n",
            "Iteration 2272, loss = 7579278047.05759811\n",
            "Iteration 2273, loss = 7559513783.76949692\n",
            "Iteration 2274, loss = 7539800692.12780094\n",
            "Iteration 2275, loss = 7520138764.88335419\n",
            "Iteration 2276, loss = 7500527994.27689934\n",
            "Iteration 2277, loss = 7480968372.03973198\n",
            "Iteration 2278, loss = 7461459889.39438438\n",
            "Iteration 2279, loss = 7442002537.05526352\n",
            "Iteration 2280, loss = 7422596305.22936344\n",
            "Iteration 2281, loss = 7403241183.61691570\n",
            "Iteration 2282, loss = 7383937161.41212845\n",
            "Iteration 2283, loss = 7364684227.30385303\n",
            "Iteration 2284, loss = 7345482369.47631359\n",
            "Iteration 2285, loss = 7326331575.60983467\n",
            "Iteration 2286, loss = 7307231832.88155937\n",
            "Iteration 2287, loss = 7288183127.96619320\n",
            "Iteration 2288, loss = 7269185447.03675938\n",
            "Iteration 2289, loss = 7250238775.76534653\n",
            "Iteration 2290, loss = 7231343099.32387161\n",
            "Iteration 2291, loss = 7212498402.38486767\n",
            "Iteration 2292, loss = 7193704669.12225628\n",
            "Iteration 2293, loss = 7174961883.21214199\n",
            "Iteration 2294, loss = 7156270027.83359528\n",
            "Iteration 2295, loss = 7137629085.66950226\n",
            "Iteration 2296, loss = 7119039038.90733719\n",
            "Iteration 2297, loss = 7100499869.24002075\n",
            "Iteration 2298, loss = 7082011557.86673164\n",
            "Iteration 2299, loss = 7063574085.49376869\n",
            "Iteration 2300, loss = 7045187432.33538914\n",
            "Iteration 2301, loss = 7026851578.11467838\n",
            "Iteration 2302, loss = 7008566502.06441593\n",
            "Iteration 2303, loss = 6990332182.92795563\n",
            "Iteration 2304, loss = 6972148598.96010590\n",
            "Iteration 2305, loss = 6954015727.92802906\n",
            "Iteration 2306, loss = 6935933547.11215782\n",
            "Iteration 2307, loss = 6917902033.30708313\n",
            "Iteration 2308, loss = 6899921162.82249165\n",
            "Iteration 2309, loss = 6881990911.48409843\n",
            "Iteration 2310, loss = 6864111254.63457584\n",
            "Iteration 2311, loss = 6846282167.13450527\n",
            "Iteration 2312, loss = 6828503623.36334324\n",
            "Iteration 2313, loss = 6810775597.22035980\n",
            "Iteration 2314, loss = 6793098062.12563419\n",
            "Iteration 2315, loss = 6775470991.02104187\n",
            "Iteration 2316, loss = 6757894356.37122250\n",
            "Iteration 2317, loss = 6740368130.16458797\n",
            "Iteration 2318, loss = 6722892283.91434383\n",
            "Iteration 2319, loss = 6705466788.65948105\n",
            "Iteration 2320, loss = 6688091614.96582222\n",
            "Iteration 2321, loss = 6670766732.92705536\n",
            "Iteration 2322, loss = 6653492112.16575241\n",
            "Iteration 2323, loss = 6636267721.83443737\n",
            "Iteration 2324, loss = 6619093530.61664581\n",
            "Iteration 2325, loss = 6601969506.72799492\n",
            "Iteration 2326, loss = 6584895617.91725445\n",
            "Iteration 2327, loss = 6567871831.46741772\n",
            "Iteration 2328, loss = 6550898114.19681835\n",
            "Iteration 2329, loss = 6533974432.46022511\n",
            "Iteration 2330, loss = 6517100752.14994621\n",
            "Iteration 2331, loss = 6500277038.69695282\n",
            "Iteration 2332, loss = 6483503257.07199383\n",
            "Iteration 2333, loss = 6466779371.78675938\n",
            "Iteration 2334, loss = 6450105346.89499378\n",
            "Iteration 2335, loss = 6433481145.99366856\n",
            "Iteration 2336, loss = 6416906732.22413158\n",
            "Iteration 2337, loss = 6400382068.27328300\n",
            "Iteration 2338, loss = 6383907116.37475109\n",
            "Iteration 2339, loss = 6367481838.31008244\n",
            "Iteration 2340, loss = 6351106195.40992069\n",
            "Iteration 2341, loss = 6334780148.55522823\n",
            "Iteration 2342, loss = 6318503658.17848301\n",
            "Iteration 2343, loss = 6302276684.26491070\n",
            "Iteration 2344, loss = 6286099186.35370541\n",
            "Iteration 2345, loss = 6269971123.53925323\n",
            "Iteration 2346, loss = 6253892454.47240543\n",
            "Iteration 2347, loss = 6237863137.36169529\n",
            "Iteration 2348, loss = 6221883129.97463226\n",
            "Iteration 2349, loss = 6205952389.63894558\n",
            "Iteration 2350, loss = 6190070873.24387169\n",
            "Iteration 2351, loss = 6174238537.24144363\n",
            "Iteration 2352, loss = 6158455337.64776897\n",
            "Iteration 2353, loss = 6142721230.04434586\n",
            "Iteration 2354, loss = 6127036169.57936668\n",
            "Iteration 2355, loss = 6111400110.96902847\n",
            "Iteration 2356, loss = 6095813008.49887848\n",
            "Iteration 2357, loss = 6080274816.02512550\n",
            "Iteration 2358, loss = 6064785486.97598457\n",
            "Iteration 2359, loss = 6049344974.35303116\n",
            "Iteration 2360, loss = 6033953230.73257637\n",
            "Iteration 2361, loss = 6018610208.26699829\n",
            "Iteration 2362, loss = 6003315858.68613434\n",
            "Iteration 2363, loss = 5988070133.29866028\n",
            "Iteration 2364, loss = 5972872982.99347305\n",
            "Iteration 2365, loss = 5957724358.24110031\n",
            "Iteration 2366, loss = 5942624209.09509754\n",
            "Iteration 2367, loss = 5927572485.19344902\n",
            "Iteration 2368, loss = 5912569135.76000404\n",
            "Iteration 2369, loss = 5897614109.60590172\n",
            "Iteration 2370, loss = 5882707355.13099098\n",
            "Iteration 2371, loss = 5867848820.32530785\n",
            "Iteration 2372, loss = 5853038452.77048683\n",
            "Iteration 2373, loss = 5838276199.64124489\n",
            "Iteration 2374, loss = 5823562007.70682716\n",
            "Iteration 2375, loss = 5808895823.33250999\n",
            "Iteration 2376, loss = 5794277592.48105526\n",
            "Iteration 2377, loss = 5779707260.71420097\n",
            "Iteration 2378, loss = 5765184773.19417095\n",
            "Iteration 2379, loss = 5750710074.68518257\n",
            "Iteration 2380, loss = 5736283109.55492783\n",
            "Iteration 2381, loss = 5721903821.77611446\n",
            "Iteration 2382, loss = 5707572154.92799187\n",
            "Iteration 2383, loss = 5693288052.19787979\n",
            "Iteration 2384, loss = 5679051456.38269234\n",
            "Iteration 2385, loss = 5664862309.89052296\n",
            "Iteration 2386, loss = 5650720554.74215508\n",
            "Iteration 2387, loss = 5636626132.57265568\n",
            "Iteration 2388, loss = 5622578984.63293266\n",
            "Iteration 2389, loss = 5608579051.79131317\n",
            "Iteration 2390, loss = 5594626274.53511333\n",
            "Iteration 2391, loss = 5580720592.97225285\n",
            "Iteration 2392, loss = 5566861946.83282661\n",
            "Iteration 2393, loss = 5553050275.47073078\n",
            "Iteration 2394, loss = 5539285517.86525726\n",
            "Iteration 2395, loss = 5525567612.62272167\n",
            "Iteration 2396, loss = 5511896497.97807312\n",
            "Iteration 2397, loss = 5498272111.79655647\n",
            "Iteration 2398, loss = 5484694391.57530594\n",
            "Iteration 2399, loss = 5471163274.44502831\n",
            "Iteration 2400, loss = 5457678697.17164612\n",
            "Iteration 2401, loss = 5444240596.15793419\n",
            "Iteration 2402, loss = 5430848907.44521046\n",
            "Iteration 2403, loss = 5417503566.71499348\n",
            "Iteration 2404, loss = 5404204509.29069328\n",
            "Iteration 2405, loss = 5390951670.13926888\n",
            "Iteration 2406, loss = 5377744983.87296200\n",
            "Iteration 2407, loss = 5364584384.75094318\n",
            "Iteration 2408, loss = 5351469806.68105602\n",
            "Iteration 2409, loss = 5338401183.22151852\n",
            "Iteration 2410, loss = 5325378447.58261681\n",
            "Iteration 2411, loss = 5312401532.62845802\n",
            "Iteration 2412, loss = 5299470370.87868500\n",
            "Iteration 2413, loss = 5286584894.51020908\n",
            "Iteration 2414, loss = 5273745035.35894871\n",
            "Iteration 2415, loss = 5260950724.92158794\n",
            "Iteration 2416, loss = 5248201894.35732460\n",
            "Iteration 2417, loss = 5235498474.48962021\n",
            "Iteration 2418, loss = 5222840395.80798244\n",
            "Iteration 2419, loss = 5210227588.46971416\n",
            "Iteration 2420, loss = 5197659982.30171490\n",
            "Iteration 2421, loss = 5185137506.80224419\n",
            "Iteration 2422, loss = 5172660091.14271641\n",
            "Iteration 2423, loss = 5160227664.16949368\n",
            "Iteration 2424, loss = 5147840154.40568924\n",
            "Iteration 2425, loss = 5135497490.05296516\n",
            "Iteration 2426, loss = 5123199598.99335194\n",
            "Iteration 2427, loss = 5110946408.79106045\n",
            "Iteration 2428, loss = 5098737846.69429588\n",
            "Iteration 2429, loss = 5086573839.63710594\n",
            "Iteration 2430, loss = 5074454314.24118328\n",
            "Iteration 2431, loss = 5062379196.81773186\n",
            "Iteration 2432, loss = 5050348413.36929226\n",
            "Iteration 2433, loss = 5038361889.59159851\n",
            "Iteration 2434, loss = 5026419550.87542820\n",
            "Iteration 2435, loss = 5014521322.30845261\n",
            "Iteration 2436, loss = 5002667128.67711926\n",
            "Iteration 2437, loss = 4990856894.46850395\n",
            "Iteration 2438, loss = 4979090543.87219429\n",
            "Iteration 2439, loss = 4967368000.78215694\n",
            "Iteration 2440, loss = 4955689188.79863167\n",
            "Iteration 2441, loss = 4944054031.23001099\n",
            "Iteration 2442, loss = 4932462451.09474564\n",
            "Iteration 2443, loss = 4920914371.12322235\n",
            "Iteration 2444, loss = 4909409713.75968456\n",
            "Iteration 2445, loss = 4897948401.16412354\n",
            "Iteration 2446, loss = 4886530355.21420383\n",
            "Iteration 2447, loss = 4875155497.50716496\n",
            "Iteration 2448, loss = 4863823749.36174583\n",
            "Iteration 2449, loss = 4852535031.82012749\n",
            "Iteration 2450, loss = 4841289265.64982891\n",
            "Iteration 2451, loss = 4830086371.34565639\n",
            "Iteration 2452, loss = 4818926269.13164902\n",
            "Iteration 2453, loss = 4807808878.96300507\n",
            "Iteration 2454, loss = 4796734120.52803040\n",
            "Iteration 2455, loss = 4785701913.25009251\n",
            "Iteration 2456, loss = 4774712176.28957558\n",
            "Iteration 2457, loss = 4763764828.54582310\n",
            "Iteration 2458, loss = 4752859788.65911579\n",
            "Iteration 2459, loss = 4741996975.01262188\n",
            "Iteration 2460, loss = 4731176305.73437595\n",
            "Iteration 2461, loss = 4720397698.69924831\n",
            "Iteration 2462, loss = 4709661071.53091526\n",
            "Iteration 2463, loss = 4698966341.60383987\n",
            "Iteration 2464, loss = 4688313426.04526234\n",
            "Iteration 2465, loss = 4677702241.73717213\n",
            "Iteration 2466, loss = 4667132705.31831360\n",
            "Iteration 2467, loss = 4656604733.18616009\n",
            "Iteration 2468, loss = 4646118241.49892616\n",
            "Iteration 2469, loss = 4635673146.17755032\n",
            "Iteration 2470, loss = 4625269362.90771770\n",
            "Iteration 2471, loss = 4614906807.14184666\n",
            "Iteration 2472, loss = 4604585394.10109997\n",
            "Iteration 2473, loss = 4594305038.77740574\n",
            "Iteration 2474, loss = 4584065655.93546677\n",
            "Iteration 2475, loss = 4573867160.11476707\n",
            "Iteration 2476, loss = 4563709465.63159561\n",
            "Iteration 2477, loss = 4553592486.58108330\n",
            "Iteration 2478, loss = 4543516136.83921432\n",
            "Iteration 2479, loss = 4533480330.06484509\n",
            "Iteration 2480, loss = 4523484979.70175076\n",
            "Iteration 2481, loss = 4513529998.98064423\n",
            "Iteration 2482, loss = 4503615300.92122173\n",
            "Iteration 2483, loss = 4493740798.33419800\n",
            "Iteration 2484, loss = 4483906403.82332325\n",
            "Iteration 2485, loss = 4474112029.78746033\n",
            "Iteration 2486, loss = 4464357588.42259693\n",
            "Iteration 2487, loss = 4454642991.72390747\n",
            "Iteration 2488, loss = 4444968151.48779202\n",
            "Iteration 2489, loss = 4435332979.31392860\n",
            "Iteration 2490, loss = 4425737386.60732841\n",
            "Iteration 2491, loss = 4416181284.58038044\n",
            "Iteration 2492, loss = 4406664584.25490856\n",
            "Iteration 2493, loss = 4397187196.46422386\n",
            "Iteration 2494, loss = 4387749031.85518360\n",
            "Iteration 2495, loss = 4378350000.89026642\n",
            "Iteration 2496, loss = 4368990013.84959984\n",
            "Iteration 2497, loss = 4359668980.83305168\n",
            "Iteration 2498, loss = 4350386811.76227188\n",
            "Iteration 2499, loss = 4341143416.38277531\n",
            "Iteration 2500, loss = 4331938704.26598930\n",
            "Iteration 2501, loss = 4322772584.81133366\n",
            "Iteration 2502, loss = 4313644967.24827671\n",
            "Iteration 2503, loss = 4304555760.63841820\n",
            "Iteration 2504, loss = 4295504873.87754345\n",
            "Iteration 2505, loss = 4286492215.69769335\n",
            "Iteration 2506, loss = 4277517694.66925383\n",
            "Iteration 2507, loss = 4268581219.20300627\n",
            "Iteration 2508, loss = 4259682697.55221176\n",
            "Iteration 2509, loss = 4250822037.81467438\n",
            "Iteration 2510, loss = 4241999147.93482399\n",
            "Iteration 2511, loss = 4233213935.70578384\n",
            "Iteration 2512, loss = 4224466308.77144527\n",
            "Iteration 2513, loss = 4215756174.62854433\n",
            "Iteration 2514, loss = 4207083440.62872553\n",
            "Iteration 2515, loss = 4198448013.98063183\n",
            "Iteration 2516, loss = 4189849801.75197363\n",
            "Iteration 2517, loss = 4181288710.87159681\n",
            "Iteration 2518, loss = 4172764648.13155842\n",
            "Iteration 2519, loss = 4164277520.18920898\n",
            "Iteration 2520, loss = 4155827233.56925631\n",
            "Iteration 2521, loss = 4147413694.66584778\n",
            "Iteration 2522, loss = 4139036809.74463463\n",
            "Iteration 2523, loss = 4130696484.94485998\n",
            "Iteration 2524, loss = 4122392626.28140688\n",
            "Iteration 2525, loss = 4114125139.64689684\n",
            "Iteration 2526, loss = 4105893930.81374216\n",
            "Iteration 2527, loss = 4097698905.43622160\n",
            "Iteration 2528, loss = 4089539969.05255556\n",
            "Iteration 2529, loss = 4081417027.08696461\n",
            "Iteration 2530, loss = 4073329984.85175133\n",
            "Iteration 2531, loss = 4065278747.54934645\n",
            "Iteration 2532, loss = 4057263220.27439976\n",
            "Iteration 2533, loss = 4049283308.01582766\n",
            "Iteration 2534, loss = 4041338915.65888166\n",
            "Iteration 2535, loss = 4033429947.98720169\n",
            "Iteration 2536, loss = 4025556309.68490219\n",
            "Iteration 2537, loss = 4017717905.33860159\n",
            "Iteration 2538, loss = 4009914639.43949795\n",
            "Iteration 2539, loss = 4002146416.38543034\n",
            "Iteration 2540, loss = 3994413140.48290586\n",
            "Iteration 2541, loss = 3986714715.94918776\n",
            "Iteration 2542, loss = 3979051046.91432524\n",
            "Iteration 2543, loss = 3971422037.42320967\n",
            "Iteration 2544, loss = 3963827591.43761873\n",
            "Iteration 2545, loss = 3956267612.83826828\n",
            "Iteration 2546, loss = 3948742005.42685223\n",
            "Iteration 2547, loss = 3941250672.92808199\n",
            "Iteration 2548, loss = 3933793518.99173594\n",
            "Iteration 2549, loss = 3926370447.19467592\n",
            "Iteration 2550, loss = 3918981361.04291105\n",
            "Iteration 2551, loss = 3911626163.97360373\n",
            "Iteration 2552, loss = 3904304759.35711956\n",
            "Iteration 2553, loss = 3897017050.49903584\n",
            "Iteration 2554, loss = 3889762940.64218807\n",
            "Iteration 2555, loss = 3882542332.96867609\n",
            "Iteration 2556, loss = 3875355130.60188627\n",
            "Iteration 2557, loss = 3868201236.60852003\n",
            "Iteration 2558, loss = 3861080554.00058746\n",
            "Iteration 2559, loss = 3853992985.73743868\n",
            "Iteration 2560, loss = 3846938434.72776461\n",
            "Iteration 2561, loss = 3839916803.83158779\n",
            "Iteration 2562, loss = 3832927995.86229658\n",
            "Iteration 2563, loss = 3825971913.58860779\n",
            "Iteration 2564, loss = 3819048459.73658752\n",
            "Iteration 2565, loss = 3812157536.99163580\n",
            "Iteration 2566, loss = 3805299048.00046444\n",
            "Iteration 2567, loss = 3798472895.37310457\n",
            "Iteration 2568, loss = 3791678981.68486404\n",
            "Iteration 2569, loss = 3784917209.47833204\n",
            "Iteration 2570, loss = 3778187481.26532269\n",
            "Iteration 2571, loss = 3771489699.52887535\n",
            "Iteration 2572, loss = 3764823766.72520351\n",
            "Iteration 2573, loss = 3758189585.28565931\n",
            "Iteration 2574, loss = 3751587057.61870289\n",
            "Iteration 2575, loss = 3745016086.11184978\n",
            "Iteration 2576, loss = 3738476573.13361740\n",
            "Iteration 2577, loss = 3731968421.03548574\n",
            "Iteration 2578, loss = 3725491532.15382719\n",
            "Iteration 2579, loss = 3719045808.81185389\n",
            "Iteration 2580, loss = 3712631153.32154560\n",
            "Iteration 2581, loss = 3706247467.98558521\n",
            "Iteration 2582, loss = 3699894655.09927988\n",
            "Iteration 2583, loss = 3693572616.95248508\n",
            "Iteration 2584, loss = 3687281255.83152008\n",
            "Iteration 2585, loss = 3681020474.02107191\n",
            "Iteration 2586, loss = 3674790173.80612373\n",
            "Iteration 2587, loss = 3668590257.47382879\n",
            "Iteration 2588, loss = 3662420627.31543446\n",
            "Iteration 2589, loss = 3656281185.62815094\n",
            "Iteration 2590, loss = 3650171834.71705866\n",
            "Iteration 2591, loss = 3644092476.89698315\n",
            "Iteration 2592, loss = 3638043014.49436474\n",
            "Iteration 2593, loss = 3632023349.84914827\n",
            "Iteration 2594, loss = 3626033385.31663179\n",
            "Iteration 2595, loss = 3620073023.26934528\n",
            "Iteration 2596, loss = 3614142166.09889126\n",
            "Iteration 2597, loss = 3608240716.21781445\n",
            "Iteration 2598, loss = 3602368576.06142330\n",
            "Iteration 2599, loss = 3596525648.08965969\n",
            "Iteration 2600, loss = 3590711834.78890800\n",
            "Iteration 2601, loss = 3584927038.67383623\n",
            "Iteration 2602, loss = 3579171162.28922796\n",
            "Iteration 2603, loss = 3573444108.21177912\n",
            "Iteration 2604, loss = 3567745779.05192709\n",
            "Iteration 2605, loss = 3562076077.45564604\n",
            "Iteration 2606, loss = 3556434906.10625744\n",
            "Iteration 2607, loss = 3550822167.72622061\n",
            "Iteration 2608, loss = 3545237765.07891130\n",
            "Iteration 2609, loss = 3539681600.97042561\n",
            "Iteration 2610, loss = 3534153578.25132990\n",
            "Iteration 2611, loss = 3528653599.81845379\n",
            "Iteration 2612, loss = 3523181568.61664009\n",
            "Iteration 2613, loss = 3517737387.64050627\n",
            "Iteration 2614, loss = 3512320959.93619537\n",
            "Iteration 2615, loss = 3506932188.60312080\n",
            "Iteration 2616, loss = 3501570976.79570150\n",
            "Iteration 2617, loss = 3496237227.72510242\n",
            "Iteration 2618, loss = 3490930844.66095495\n",
            "Iteration 2619, loss = 3485651730.93306923\n",
            "Iteration 2620, loss = 3480399789.93315411\n",
            "Iteration 2621, loss = 3475174925.11651945\n",
            "Iteration 2622, loss = 3469977040.00377464\n",
            "Iteration 2623, loss = 3464806038.18251991\n",
            "Iteration 2624, loss = 3459661823.30903816\n",
            "Iteration 2625, loss = 3454544299.10995579\n",
            "Iteration 2626, loss = 3449453369.38392830\n",
            "Iteration 2627, loss = 3444388938.00330544\n",
            "Iteration 2628, loss = 3439350908.91577244\n",
            "Iteration 2629, loss = 3434339186.14601898\n",
            "Iteration 2630, loss = 3429353673.79737091\n",
            "Iteration 2631, loss = 3424394276.05341959\n",
            "Iteration 2632, loss = 3419460897.17966509\n",
            "Iteration 2633, loss = 3414553441.52513027\n",
            "Iteration 2634, loss = 3409671813.52396822\n",
            "Iteration 2635, loss = 3404815917.69707584\n",
            "Iteration 2636, loss = 3399985658.65368891\n",
            "Iteration 2637, loss = 3395180941.09297705\n",
            "Iteration 2638, loss = 3390401669.80562353\n",
            "Iteration 2639, loss = 3385647749.67539644\n",
            "Iteration 2640, loss = 3380919085.68073416\n",
            "Iteration 2641, loss = 3376215582.89627934\n",
            "Iteration 2642, loss = 3371537146.49446440\n",
            "Iteration 2643, loss = 3366883681.74702787\n",
            "Iteration 2644, loss = 3362255094.02656651\n",
            "Iteration 2645, loss = 3357651288.80806303\n",
            "Iteration 2646, loss = 3353072171.67040825\n",
            "Iteration 2647, loss = 3348517648.29790831\n",
            "Iteration 2648, loss = 3343987624.48180389\n",
            "Iteration 2649, loss = 3339482006.12175083\n",
            "Iteration 2650, loss = 3335000699.22732496\n",
            "Iteration 2651, loss = 3330543609.91949797\n",
            "Iteration 2652, loss = 3326110644.43211031\n",
            "Iteration 2653, loss = 3321701709.11333942\n",
            "Iteration 2654, loss = 3317316710.42715168\n",
            "Iteration 2655, loss = 3312955554.95475531\n",
            "Iteration 2656, loss = 3308618149.39604807\n",
            "Iteration 2657, loss = 3304304400.57103491\n",
            "Iteration 2658, loss = 3300014215.42126894\n",
            "Iteration 2659, loss = 3295747501.01124954\n",
            "Iteration 2660, loss = 3291504164.52984285\n",
            "Iteration 2661, loss = 3287284113.29168367\n",
            "Iteration 2662, loss = 3283087254.73854733\n",
            "Iteration 2663, loss = 3278913496.44075537\n",
            "Iteration 2664, loss = 3274762746.09853029\n",
            "Iteration 2665, loss = 3270634911.54337311\n",
            "Iteration 2666, loss = 3266529900.73941612\n",
            "Iteration 2667, loss = 3262447621.78476048\n",
            "Iteration 2668, loss = 3258387982.91283751\n",
            "Iteration 2669, loss = 3254350892.49371433\n",
            "Iteration 2670, loss = 3250336259.03543854\n",
            "Iteration 2671, loss = 3246343991.18532991\n",
            "Iteration 2672, loss = 3242373997.73130131\n",
            "Iteration 2673, loss = 3238426187.60314941\n",
            "Iteration 2674, loss = 3234500469.87383604\n",
            "Iteration 2675, loss = 3230596753.76076984\n",
            "Iteration 2676, loss = 3226714948.62708330\n",
            "Iteration 2677, loss = 3222854963.98287439\n",
            "Iteration 2678, loss = 3219016709.48647404\n",
            "Iteration 2679, loss = 3215200094.94568348\n",
            "Iteration 2680, loss = 3211405030.31900311\n",
            "Iteration 2681, loss = 3207631425.71686316\n",
            "Iteration 2682, loss = 3203879191.40283632\n",
            "Iteration 2683, loss = 3200148237.79484558\n",
            "Iteration 2684, loss = 3196438475.46635246\n",
            "Iteration 2685, loss = 3192749815.14755917\n",
            "Iteration 2686, loss = 3189082167.72657776\n",
            "Iteration 2687, loss = 3185435444.25060701\n",
            "Iteration 2688, loss = 3181809555.92708158\n",
            "Iteration 2689, loss = 3178204414.12483311\n",
            "Iteration 2690, loss = 3174619930.37523746\n",
            "Iteration 2691, loss = 3171056016.37333345\n",
            "Iteration 2692, loss = 3167512583.97895575\n",
            "Iteration 2693, loss = 3163989545.21784973\n",
            "Iteration 2694, loss = 3160486812.28277016\n",
            "Iteration 2695, loss = 3157004297.53458834\n",
            "Iteration 2696, loss = 3153541913.50337315\n",
            "Iteration 2697, loss = 3150099572.88946486\n",
            "Iteration 2698, loss = 3146677188.56454897\n",
            "Iteration 2699, loss = 3143274673.57271528\n",
            "Iteration 2700, loss = 3139891941.13150311\n",
            "Iteration 2701, loss = 3136528904.63294506\n",
            "Iteration 2702, loss = 3133185477.64459944\n",
            "Iteration 2703, loss = 3129861573.91056728\n",
            "Iteration 2704, loss = 3126557107.35250664\n",
            "Iteration 2705, loss = 3123271992.07064295\n",
            "Iteration 2706, loss = 3120006142.34474134\n",
            "Iteration 2707, loss = 3116759472.63511515\n",
            "Iteration 2708, loss = 3113531897.58358908\n",
            "Iteration 2709, loss = 3110323332.01446247\n",
            "Iteration 2710, loss = 3107133690.93546820\n",
            "Iteration 2711, loss = 3103962889.53872108\n",
            "Iteration 2712, loss = 3100810843.20164824\n",
            "Iteration 2713, loss = 3097677467.48792315\n",
            "Iteration 2714, loss = 3094562678.14838123\n",
            "Iteration 2715, loss = 3091466391.12192869\n",
            "Iteration 2716, loss = 3088388522.53643465\n",
            "Iteration 2717, loss = 3085328988.70963621\n",
            "Iteration 2718, loss = 3082287706.14999819\n",
            "Iteration 2719, loss = 3079264591.55760765\n",
            "Iteration 2720, loss = 3076259561.82500887\n",
            "Iteration 2721, loss = 3073272534.03807831\n",
            "Iteration 2722, loss = 3070303425.47684908\n",
            "Iteration 2723, loss = 3067352153.61635351\n",
            "Iteration 2724, loss = 3064418636.12744570\n",
            "Iteration 2725, loss = 3061502790.87761307\n",
            "Iteration 2726, loss = 3058604535.93177462\n",
            "Iteration 2727, loss = 3055723789.55308771\n",
            "Iteration 2728, loss = 3052860470.20372725\n",
            "Iteration 2729, loss = 3050014496.54565525\n",
            "Iteration 2730, loss = 3047185787.44140291\n",
            "Iteration 2731, loss = 3044374261.95480490\n",
            "Iteration 2732, loss = 3041579839.35177088\n",
            "Iteration 2733, loss = 3038802439.10100508\n",
            "Iteration 2734, loss = 3036041980.87474537\n",
            "Iteration 2735, loss = 3033298384.54947233\n",
            "Iteration 2736, loss = 3030571570.20663309\n",
            "Iteration 2737, loss = 3027861458.13332844\n",
            "Iteration 2738, loss = 3025167968.82300329\n",
            "Iteration 2739, loss = 3022491022.97613955\n",
            "Iteration 2740, loss = 3019830541.50092125\n",
            "Iteration 2741, loss = 3017186445.51388836\n",
            "Iteration 2742, loss = 3014558656.34060383\n",
            "Iteration 2743, loss = 3011947095.51629066\n",
            "Iteration 2744, loss = 3009351684.78646660\n",
            "Iteration 2745, loss = 3006772346.10756588\n",
            "Iteration 2746, loss = 3004209001.64756250\n",
            "Iteration 2747, loss = 3001661573.78656578\n",
            "Iteration 2748, loss = 2999129985.11742353\n",
            "Iteration 2749, loss = 2996614158.44631624\n",
            "Iteration 2750, loss = 2994114016.79331875\n",
            "Iteration 2751, loss = 2991629483.39298058\n",
            "Iteration 2752, loss = 2989160481.69488430\n",
            "Iteration 2753, loss = 2986706935.36419106\n",
            "Iteration 2754, loss = 2984268768.28218842\n",
            "Iteration 2755, loss = 2981845904.54681969\n",
            "Iteration 2756, loss = 2979438268.47319746\n",
            "Iteration 2757, loss = 2977045784.59413481\n",
            "Iteration 2758, loss = 2974668377.66063070\n",
            "Iteration 2759, loss = 2972305972.64237881\n",
            "Iteration 2760, loss = 2969958494.72825003\n",
            "Iteration 2761, loss = 2967625869.32675838\n",
            "Iteration 2762, loss = 2965308022.06654692\n",
            "Iteration 2763, loss = 2963004878.79683304\n",
            "Iteration 2764, loss = 2960716365.58785725\n",
            "Iteration 2765, loss = 2958442408.73133993\n",
            "Iteration 2766, loss = 2956182934.74088097\n",
            "Iteration 2767, loss = 2953937870.35242128\n",
            "Iteration 2768, loss = 2951707142.52462435\n",
            "Iteration 2769, loss = 2949490678.43929720\n",
            "Iteration 2770, loss = 2947288405.50178146\n",
            "Iteration 2771, loss = 2945100251.34133148\n",
            "Iteration 2772, loss = 2942926143.81150866\n",
            "Iteration 2773, loss = 2940766010.99053669\n",
            "Iteration 2774, loss = 2938619781.18166542\n",
            "Iteration 2775, loss = 2936487382.91352463\n",
            "Iteration 2776, loss = 2934368744.94045496\n",
            "Iteration 2777, loss = 2932263796.24286175\n",
            "Iteration 2778, loss = 2930172466.02751637\n",
            "Iteration 2779, loss = 2928094683.72789001\n",
            "Iteration 2780, loss = 2926030379.00444794\n",
            "Iteration 2781, loss = 2923979481.74495554\n",
            "Iteration 2782, loss = 2921941922.06476784\n",
            "Iteration 2783, loss = 2919917630.30710936\n",
            "Iteration 2784, loss = 2917906537.04334068\n",
            "Iteration 2785, loss = 2915908573.07323217\n",
            "Iteration 2786, loss = 2913923669.42521048\n",
            "Iteration 2787, loss = 2911951757.35661459\n",
            "Iteration 2788, loss = 2909992768.35392618\n",
            "Iteration 2789, loss = 2908046634.13300323\n",
            "Iteration 2790, loss = 2906113286.63930178\n",
            "Iteration 2791, loss = 2904192658.04808378\n",
            "Iteration 2792, loss = 2902284680.76463079\n",
            "Iteration 2793, loss = 2900389287.42443180\n",
            "Iteration 2794, loss = 2898506410.89337730\n",
            "Iteration 2795, loss = 2896635984.26793480\n",
            "Iteration 2796, loss = 2894777940.87532234\n",
            "Iteration 2797, loss = 2892932214.27367258\n",
            "Iteration 2798, loss = 2891098738.25218582\n",
            "Iteration 2799, loss = 2889277446.83127832\n",
            "Iteration 2800, loss = 2887468274.26271820\n",
            "Iteration 2801, loss = 2885671155.02976656\n",
            "Iteration 2802, loss = 2883886023.84728336\n",
            "Iteration 2803, loss = 2882112815.66185379\n",
            "Iteration 2804, loss = 2880351465.65189791\n",
            "Iteration 2805, loss = 2878601909.22775555\n",
            "Iteration 2806, loss = 2876864082.03179121\n",
            "Iteration 2807, loss = 2875137919.93847084\n",
            "Iteration 2808, loss = 2873423359.05443621\n",
            "Iteration 2809, loss = 2871720335.71857023\n",
            "Iteration 2810, loss = 2870028786.50206995\n",
            "Iteration 2811, loss = 2868348648.20847750\n",
            "Iteration 2812, loss = 2866679857.87374353\n",
            "Iteration 2813, loss = 2865022352.76625013\n",
            "Iteration 2814, loss = 2863376070.38684893\n",
            "Iteration 2815, loss = 2861740948.46887255\n",
            "Iteration 2816, loss = 2860116924.97816324\n",
            "Iteration 2817, loss = 2858503938.11306381\n",
            "Iteration 2818, loss = 2856901926.30442190\n",
            "Iteration 2819, loss = 2855310828.21559095\n",
            "Iteration 2820, loss = 2853730582.74239779\n",
            "Iteration 2821, loss = 2852161129.01313019\n",
            "Iteration 2822, loss = 2850602406.38850260\n",
            "Iteration 2823, loss = 2849054354.46161842\n",
            "Iteration 2824, loss = 2847516913.05792952\n",
            "Iteration 2825, loss = 2845990022.23517275\n",
            "Iteration 2826, loss = 2844473622.28332615\n",
            "Iteration 2827, loss = 2842967653.72452545\n",
            "Iteration 2828, loss = 2841472057.31300354\n",
            "Iteration 2829, loss = 2839986774.03500319\n",
            "Iteration 2830, loss = 2838511745.10869217\n",
            "Iteration 2831, loss = 2837046911.98406887\n",
            "Iteration 2832, loss = 2835592216.34285736\n",
            "Iteration 2833, loss = 2834147600.09840012\n",
            "Iteration 2834, loss = 2832713005.39554739\n",
            "Iteration 2835, loss = 2831288374.61053133\n",
            "Iteration 2836, loss = 2829873650.35083342\n",
            "Iteration 2837, loss = 2828468775.45505953\n",
            "Iteration 2838, loss = 2827073692.99278641\n",
            "Iteration 2839, loss = 2825688346.26442480\n",
            "Iteration 2840, loss = 2824312678.80105066\n",
            "Iteration 2841, loss = 2822946634.36425495\n",
            "Iteration 2842, loss = 2821590156.94597340\n",
            "Iteration 2843, loss = 2820243190.76830244\n",
            "Iteration 2844, loss = 2818905680.28332996\n",
            "Iteration 2845, loss = 2817577570.17294264\n",
            "Iteration 2846, loss = 2816258805.34863472\n",
            "Iteration 2847, loss = 2814949330.95130301\n",
            "Iteration 2848, loss = 2813649092.35104465\n",
            "Iteration 2849, loss = 2812358035.14694738\n",
            "Iteration 2850, loss = 2811076105.16686201\n",
            "Iteration 2851, loss = 2809803248.46718597\n",
            "Iteration 2852, loss = 2808539411.33263636\n",
            "Iteration 2853, loss = 2807284540.27600002\n",
            "Iteration 2854, loss = 2806038582.03790092\n",
            "Iteration 2855, loss = 2804801483.58655024\n",
            "Iteration 2856, loss = 2803573192.11748838\n",
            "Iteration 2857, loss = 2802353655.05333328\n",
            "Iteration 2858, loss = 2801142820.04350328\n",
            "Iteration 2859, loss = 2799940634.96395016\n",
            "Iteration 2860, loss = 2798747047.91688967\n",
            "Iteration 2861, loss = 2797562007.23050928\n",
            "Iteration 2862, loss = 2796385461.45867872\n",
            "Iteration 2863, loss = 2795217359.38066339\n",
            "Iteration 2864, loss = 2794057650.00081873\n",
            "Iteration 2865, loss = 2792906282.54828882\n",
            "Iteration 2866, loss = 2791763206.47669649\n",
            "Iteration 2867, loss = 2790628371.46382475\n",
            "Iteration 2868, loss = 2789501727.41129160\n",
            "Iteration 2869, loss = 2788383224.44423866\n",
            "Iteration 2870, loss = 2787272812.91098166\n",
            "Iteration 2871, loss = 2786170443.38268805\n",
            "Iteration 2872, loss = 2785076066.65302658\n",
            "Iteration 2873, loss = 2783989633.73782158\n",
            "Iteration 2874, loss = 2782911095.87470627\n",
            "Iteration 2875, loss = 2781840404.52275896\n",
            "Iteration 2876, loss = 2780777511.36214685\n",
            "Iteration 2877, loss = 2779722368.29375172\n",
            "Iteration 2878, loss = 2778674927.43881130\n",
            "Iteration 2879, loss = 2777635141.13852930\n",
            "Iteration 2880, loss = 2776602961.95369959\n",
            "Iteration 2881, loss = 2775578342.66432428\n",
            "Iteration 2882, loss = 2774561236.26921463\n",
            "Iteration 2883, loss = 2773551595.98560476\n",
            "Iteration 2884, loss = 2772549375.24874687\n",
            "Iteration 2885, loss = 2771554527.71150732\n",
            "Iteration 2886, loss = 2770567007.24395847\n",
            "Iteration 2887, loss = 2769586767.93296337\n",
            "Iteration 2888, loss = 2768613764.08176422\n",
            "Iteration 2889, loss = 2767647950.20955515\n",
            "Iteration 2890, loss = 2766689281.05105448\n",
            "Iteration 2891, loss = 2765737711.55608368\n",
            "Iteration 2892, loss = 2764793196.88911819\n",
            "Iteration 2893, loss = 2763855692.42886162\n",
            "Iteration 2894, loss = 2762925153.76779556\n",
            "Iteration 2895, loss = 2762001536.71173859\n",
            "Iteration 2896, loss = 2761084797.27938461\n",
            "Iteration 2897, loss = 2760174891.70186043\n",
            "Iteration 2898, loss = 2759271776.42225790\n",
            "Iteration 2899, loss = 2758375408.09517527\n",
            "Iteration 2900, loss = 2757485743.58625031\n",
            "Iteration 2901, loss = 2756602739.97168684\n",
            "Iteration 2902, loss = 2755726354.53778553\n",
            "Iteration 2903, loss = 2754856544.78045940\n",
            "Iteration 2904, loss = 2753993268.40476036\n",
            "Iteration 2905, loss = 2753136483.32438469\n",
            "Iteration 2906, loss = 2752286147.66119432\n",
            "Iteration 2907, loss = 2751442219.74471664\n",
            "Iteration 2908, loss = 2750604658.11165190\n",
            "Iteration 2909, loss = 2749773421.50537443\n",
            "Iteration 2910, loss = 2748948468.87543058\n",
            "Iteration 2911, loss = 2748129759.37702942\n",
            "Iteration 2912, loss = 2747317252.37053871\n",
            "Iteration 2913, loss = 2746510907.42096519\n",
            "Iteration 2914, loss = 2745710684.29745054\n",
            "Iteration 2915, loss = 2744916542.97273874\n",
            "Iteration 2916, loss = 2744128443.62266397\n",
            "Iteration 2917, loss = 2743346346.62562275\n",
            "Iteration 2918, loss = 2742570212.56204510\n",
            "Iteration 2919, loss = 2741800002.21386290\n",
            "Iteration 2920, loss = 2741035676.56398106\n",
            "Iteration 2921, loss = 2740277196.79573393\n",
            "Iteration 2922, loss = 2739524524.29234695\n",
            "Iteration 2923, loss = 2738777620.63639975\n",
            "Iteration 2924, loss = 2738036447.60927486\n",
            "Iteration 2925, loss = 2737300967.19061184\n",
            "Iteration 2926, loss = 2736571141.55775690\n",
            "Iteration 2927, loss = 2735846933.08520746\n",
            "Iteration 2928, loss = 2735128304.34405947\n",
            "Iteration 2929, loss = 2734415218.10144949\n",
            "Iteration 2930, loss = 2733707637.31998730\n",
            "Iteration 2931, loss = 2733005525.15719938\n",
            "Iteration 2932, loss = 2732308844.96496010\n",
            "Iteration 2933, loss = 2731617560.28892183\n",
            "Iteration 2934, loss = 2730931634.86795378\n",
            "Iteration 2935, loss = 2730251032.63355255\n",
            "Iteration 2936, loss = 2729575717.70928001\n",
            "Iteration 2937, loss = 2728905654.41018343\n",
            "Iteration 2938, loss = 2728240807.24221420\n",
            "Iteration 2939, loss = 2727581140.90164328\n",
            "Iteration 2940, loss = 2726926620.27448750\n",
            "Iteration 2941, loss = 2726277210.43590879\n",
            "Iteration 2942, loss = 2725632876.64964104\n",
            "Iteration 2943, loss = 2724993584.36739063\n",
            "Iteration 2944, loss = 2724359299.22824955\n",
            "Iteration 2945, loss = 2723729987.05809975\n",
            "Iteration 2946, loss = 2723105613.86901903\n",
            "Iteration 2947, loss = 2722486145.85867882\n",
            "Iteration 2948, loss = 2721871549.40975618\n",
            "Iteration 2949, loss = 2721261791.08931971\n",
            "Iteration 2950, loss = 2720656837.64823818\n",
            "Iteration 2951, loss = 2720056656.02056694\n",
            "Iteration 2952, loss = 2719461213.32295322\n",
            "Iteration 2953, loss = 2718870476.85401583\n",
            "Iteration 2954, loss = 2718284414.09374952\n",
            "Iteration 2955, loss = 2717702992.70290327\n",
            "Iteration 2956, loss = 2717126180.52237558\n",
            "Iteration 2957, loss = 2716553945.57260036\n",
            "Iteration 2958, loss = 2715986256.05292988\n",
            "Iteration 2959, loss = 2715423080.34101963\n",
            "Iteration 2960, loss = 2714864386.99221230\n",
            "Iteration 2961, loss = 2714310144.73891878\n",
            "Iteration 2962, loss = 2713760322.48999786\n",
            "Iteration 2963, loss = 2713214889.33013582\n",
            "Iteration 2964, loss = 2712673814.51922417\n",
            "Iteration 2965, loss = 2712137067.49173594\n",
            "Iteration 2966, loss = 2711604617.85610437\n",
            "Iteration 2967, loss = 2711076435.39409208\n",
            "Iteration 2968, loss = 2710552490.06016874\n",
            "Iteration 2969, loss = 2710032751.98088217\n",
            "Iteration 2970, loss = 2709517191.45423269\n",
            "Iteration 2971, loss = 2709005778.94903898\n",
            "Iteration 2972, loss = 2708498485.10431194\n",
            "Iteration 2973, loss = 2707995280.72862387\n",
            "Iteration 2974, loss = 2707496136.79947233\n",
            "Iteration 2975, loss = 2707001024.46265364\n",
            "Iteration 2976, loss = 2706509915.03162766\n",
            "Iteration 2977, loss = 2706022779.98687935\n",
            "Iteration 2978, loss = 2705539590.97529221\n",
            "Iteration 2979, loss = 2705060319.80950356\n",
            "Iteration 2980, loss = 2704584938.46727848\n",
            "Iteration 2981, loss = 2704113419.09086704\n",
            "Iteration 2982, loss = 2703645733.98636913\n",
            "Iteration 2983, loss = 2703181855.62309647\n",
            "Iteration 2984, loss = 2702721756.63293648\n",
            "Iteration 2985, loss = 2702265409.80971098\n",
            "Iteration 2986, loss = 2701812788.10854006\n",
            "Iteration 2987, loss = 2701363864.64520264\n",
            "Iteration 2988, loss = 2700918612.69549513\n",
            "Iteration 2989, loss = 2700477005.69459438\n",
            "Iteration 2990, loss = 2700039017.23641348\n",
            "Iteration 2991, loss = 2699604621.07296801\n",
            "Iteration 2992, loss = 2699173791.11372709\n",
            "Iteration 2993, loss = 2698746501.42498016\n",
            "Iteration 2994, loss = 2698322726.22919273\n",
            "Iteration 2995, loss = 2697902439.90436316\n",
            "Iteration 2996, loss = 2697485616.98338795\n",
            "Iteration 2997, loss = 2697072232.15341520\n",
            "Iteration 2998, loss = 2696662260.25520039\n",
            "Iteration 2999, loss = 2696255676.28247786\n",
            "Iteration 3000, loss = 2695852455.38130379\n",
            "Iteration 3001, loss = 2695452572.84942722\n",
            "Iteration 3002, loss = 2695056004.13564396\n",
            "Iteration 3003, loss = 2694662724.83915186\n",
            "Iteration 3004, loss = 2694272710.70891905\n",
            "Iteration 3005, loss = 2693885937.64303684\n",
            "Iteration 3006, loss = 2693502381.68807650\n",
            "Iteration 3007, loss = 2693122019.03845692\n",
            "Iteration 3008, loss = 2692744826.03580093\n",
            "Iteration 3009, loss = 2692370779.16829157\n",
            "Iteration 3010, loss = 2691999855.07004166\n",
            "Iteration 3011, loss = 2691632030.52044249\n",
            "Iteration 3012, loss = 2691267282.44353724\n",
            "Iteration 3013, loss = 2690905587.90737152\n",
            "Iteration 3014, loss = 2690546924.12336636\n",
            "Iteration 3015, loss = 2690191268.44567060\n",
            "Iteration 3016, loss = 2689838598.37052727\n",
            "Iteration 3017, loss = 2689488891.53564119\n",
            "Iteration 3018, loss = 2689142125.71953392\n",
            "Iteration 3019, loss = 2688798278.84091711\n",
            "Iteration 3020, loss = 2688457328.95805216\n",
            "Iteration 3021, loss = 2688119254.26811457\n",
            "Iteration 3022, loss = 2687784033.10656404\n",
            "Iteration 3023, loss = 2687451643.94650555\n",
            "Iteration 3024, loss = 2687122065.39806557\n",
            "Iteration 3025, loss = 2686795276.20774984\n",
            "Iteration 3026, loss = 2686471255.25782013\n",
            "Iteration 3027, loss = 2686149981.56565428\n",
            "Iteration 3028, loss = 2685831434.28312492\n",
            "Iteration 3029, loss = 2685515592.69596720\n",
            "Iteration 3030, loss = 2685202436.22315121\n",
            "Iteration 3031, loss = 2684891944.41625166\n",
            "Iteration 3032, loss = 2684584096.95881987\n",
            "Iteration 3033, loss = 2684278873.66576481\n",
            "Iteration 3034, loss = 2683976254.48272038\n",
            "Iteration 3035, loss = 2683676219.48542643\n",
            "Iteration 3036, loss = 2683378748.87910223\n",
            "Iteration 3037, loss = 2683083822.99782419\n",
            "Iteration 3038, loss = 2682791422.30390835\n",
            "Iteration 3039, loss = 2682501527.38728189\n",
            "Iteration 3040, loss = 2682214118.96486759\n",
            "Iteration 3041, loss = 2681929177.87997246\n",
            "Iteration 3042, loss = 2681646685.10165834\n",
            "Iteration 3043, loss = 2681366621.72412920\n",
            "Iteration 3044, loss = 2681088968.96612310\n",
            "Iteration 3045, loss = 2680813708.17028475\n",
            "Iteration 3046, loss = 2680540820.80256271\n",
            "Iteration 3047, loss = 2680270288.45159197\n",
            "Iteration 3048, loss = 2680002092.82808685\n",
            "Iteration 3049, loss = 2679736215.76422453\n",
            "Iteration 3050, loss = 2679472639.21304417\n",
            "Iteration 3051, loss = 2679211345.24783230\n",
            "Iteration 3052, loss = 2678952316.06152439\n",
            "Iteration 3053, loss = 2678695533.96608829\n",
            "Iteration 3054, loss = 2678440981.39192963\n",
            "Iteration 3055, loss = 2678188640.88728952\n",
            "Iteration 3056, loss = 2677938495.11763430\n",
            "Iteration 3057, loss = 2677690526.86506510\n",
            "Iteration 3058, loss = 2677444719.02771091\n",
            "Iteration 3059, loss = 2677201054.61914015\n",
            "Iteration 3060, loss = 2676959516.76775312\n",
            "Iteration 3061, loss = 2676720088.71619701\n",
            "Iteration 3062, loss = 2676482753.82076645\n",
            "Iteration 3063, loss = 2676247495.55081463\n",
            "Iteration 3064, loss = 2676014297.48815966\n",
            "Iteration 3065, loss = 2675783143.32649755\n",
            "Iteration 3066, loss = 2675554016.87081528\n",
            "Iteration 3067, loss = 2675326902.03679657\n",
            "Iteration 3068, loss = 2675101782.85024738\n",
            "Iteration 3069, loss = 2674878643.44650459\n",
            "Iteration 3070, loss = 2674657468.06985903\n",
            "Iteration 3071, loss = 2674438241.07297039\n",
            "Iteration 3072, loss = 2674220946.91628933\n",
            "Iteration 3073, loss = 2674005570.16747856\n",
            "Iteration 3074, loss = 2673792095.50084162\n",
            "Iteration 3075, loss = 2673580507.69674397\n",
            "Iteration 3076, loss = 2673370791.64103842\n",
            "Iteration 3077, loss = 2673162932.32449675\n",
            "Iteration 3078, loss = 2672956914.84223843\n",
            "Iteration 3079, loss = 2672752724.39316320\n",
            "Iteration 3080, loss = 2672550346.27938080\n",
            "Iteration 3081, loss = 2672349765.90565157\n",
            "Iteration 3082, loss = 2672150968.77881527\n",
            "Iteration 3083, loss = 2671953940.50723696\n",
            "Iteration 3084, loss = 2671758666.80023909\n",
            "Iteration 3085, loss = 2671565133.46754885\n",
            "Iteration 3086, loss = 2671373326.41873598\n",
            "Iteration 3087, loss = 2671183231.66266203\n",
            "Iteration 3088, loss = 2670994835.30692339\n",
            "Iteration 3089, loss = 2670808123.55729675\n",
            "Iteration 3090, loss = 2670623082.71719694\n",
            "Iteration 3091, loss = 2670439699.18711901\n",
            "Iteration 3092, loss = 2670257959.46409941\n",
            "Iteration 3093, loss = 2670077850.14116001\n",
            "Iteration 3094, loss = 2669899357.90677547\n",
            "Iteration 3095, loss = 2669722469.54432631\n",
            "Iteration 3096, loss = 2669547171.93155670\n",
            "Iteration 3097, loss = 2669373452.04004192\n",
            "Iteration 3098, loss = 2669201296.93464422\n",
            "Iteration 3099, loss = 2669030693.77298594\n",
            "Iteration 3100, loss = 2668861629.80491018\n",
            "Iteration 3101, loss = 2668694092.37194967\n",
            "Iteration 3102, loss = 2668528068.90680408\n",
            "Iteration 3103, loss = 2668363546.93280220\n",
            "Iteration 3104, loss = 2668200514.06338501\n",
            "Iteration 3105, loss = 2668038958.00157499\n",
            "Iteration 3106, loss = 2667878866.53945827\n",
            "Iteration 3107, loss = 2667720227.55765915\n",
            "Iteration 3108, loss = 2667563029.02482796\n",
            "Iteration 3109, loss = 2667407258.99711800\n",
            "Iteration 3110, loss = 2667252905.61767387\n",
            "Iteration 3111, loss = 2667099957.11611748\n",
            "Iteration 3112, loss = 2666948401.80803728\n",
            "Iteration 3113, loss = 2666798228.09447575\n",
            "Iteration 3114, loss = 2666649424.46142673\n",
            "Iteration 3115, loss = 2666501979.47932434\n",
            "Iteration 3116, loss = 2666355881.80254459\n",
            "Iteration 3117, loss = 2666211120.16889811\n",
            "Iteration 3118, loss = 2666067683.39913368\n",
            "Iteration 3119, loss = 2665925560.39643526\n",
            "Iteration 3120, loss = 2665784740.14593458\n",
            "Iteration 3121, loss = 2665645211.71420527\n",
            "Iteration 3122, loss = 2665506964.24877882\n",
            "Iteration 3123, loss = 2665369986.97764874\n",
            "Iteration 3124, loss = 2665234269.20878458\n",
            "Iteration 3125, loss = 2665099800.32964611\n",
            "Iteration 3126, loss = 2664966569.80669308\n",
            "Iteration 3127, loss = 2664834567.18490791\n",
            "Iteration 3128, loss = 2664703782.08731174\n",
            "Iteration 3129, loss = 2664574204.21448231\n",
            "Iteration 3130, loss = 2664445823.34408379\n",
            "Iteration 3131, loss = 2664318629.33038473\n",
            "Iteration 3132, loss = 2664192612.10378599\n",
            "Iteration 3133, loss = 2664067761.67035484\n",
            "Iteration 3134, loss = 2663944068.11134624\n",
            "Iteration 3135, loss = 2663821521.58274078\n",
            "Iteration 3136, loss = 2663700112.31477642\n",
            "Iteration 3137, loss = 2663579830.61149073\n",
            "Iteration 3138, loss = 2663460666.85024691\n",
            "Iteration 3139, loss = 2663342611.48128557\n",
            "Iteration 3140, loss = 2663225655.02726316\n",
            "Iteration 3141, loss = 2663109788.08278942\n",
            "Iteration 3142, loss = 2662995001.31398582\n",
            "Iteration 3143, loss = 2662881285.45802021\n",
            "Iteration 3144, loss = 2662768631.32266521\n",
            "Iteration 3145, loss = 2662657029.78584671\n",
            "Iteration 3146, loss = 2662546471.79519892\n",
            "Iteration 3147, loss = 2662436948.36761856\n",
            "Iteration 3148, loss = 2662328450.58882332\n",
            "Iteration 3149, loss = 2662220969.61290789\n",
            "Iteration 3150, loss = 2662114496.66191435\n",
            "Iteration 3151, loss = 2662009023.02538586\n",
            "Iteration 3152, loss = 2661904540.05993462\n",
            "Iteration 3153, loss = 2661801039.18881512\n",
            "Iteration 3154, loss = 2661698511.90148354\n",
            "Iteration 3155, loss = 2661596949.75317812\n",
            "Iteration 3156, loss = 2661496344.36448622\n",
            "Iteration 3157, loss = 2661396687.42092228\n",
            "Iteration 3158, loss = 2661297970.67250252\n",
            "Iteration 3159, loss = 2661200185.93332815\n",
            "Iteration 3160, loss = 2661103325.08116102\n",
            "Iteration 3161, loss = 2661007380.05701113\n",
            "Iteration 3162, loss = 2660912342.86471844\n",
            "Iteration 3163, loss = 2660818205.57054090\n",
            "Iteration 3164, loss = 2660724960.30274343\n",
            "Iteration 3165, loss = 2660632599.25118732\n",
            "Iteration 3166, loss = 2660541114.66692400\n",
            "Iteration 3167, loss = 2660450498.86179018\n",
            "Iteration 3168, loss = 2660360744.20800352\n",
            "Iteration 3169, loss = 2660271843.13775730\n",
            "Iteration 3170, loss = 2660183788.14282894\n",
            "Iteration 3171, loss = 2660096571.77417660\n",
            "Iteration 3172, loss = 2660010186.64154434\n",
            "Iteration 3173, loss = 2659924625.41306686\n",
            "Iteration 3174, loss = 2659839880.81488371\n",
            "Iteration 3175, loss = 2659755945.63073826\n",
            "Iteration 3176, loss = 2659672812.70160341\n",
            "Iteration 3177, loss = 2659590474.92528296\n",
            "Iteration 3178, loss = 2659508925.25603580\n",
            "Iteration 3179, loss = 2659428156.70418882\n",
            "Iteration 3180, loss = 2659348162.33576059\n",
            "Iteration 3181, loss = 2659268935.27207708\n",
            "Iteration 3182, loss = 2659190468.68940163\n",
            "Iteration 3183, loss = 2659112755.81855488\n",
            "Iteration 3184, loss = 2659035789.94454622\n",
            "Iteration 3185, loss = 2658959564.40619993\n",
            "Iteration 3186, loss = 2658884072.59578800\n",
            "Iteration 3187, loss = 2658809307.95866299\n",
            "Iteration 3188, loss = 2658735263.99288940\n",
            "Iteration 3189, loss = 2658661934.24888563\n",
            "Iteration 3190, loss = 2658589312.32905912\n",
            "Iteration 3191, loss = 2658517391.88745070\n",
            "Iteration 3192, loss = 2658446166.62937021\n",
            "Iteration 3193, loss = 2658375630.31104565\n",
            "Iteration 3194, loss = 2658305776.73926878\n",
            "Iteration 3195, loss = 2658236599.77104330\n",
            "Iteration 3196, loss = 2658168093.31323242\n",
            "Iteration 3197, loss = 2658100251.32221365\n",
            "Iteration 3198, loss = 2658033067.80352879\n",
            "Iteration 3199, loss = 2657966536.81154156\n",
            "Iteration 3200, loss = 2657900652.44909620\n",
            "Iteration 3201, loss = 2657835408.86717367\n",
            "Iteration 3202, loss = 2657770800.26455307\n",
            "Iteration 3203, loss = 2657706820.88747597\n",
            "Iteration 3204, loss = 2657643465.02931070\n",
            "Iteration 3205, loss = 2657580727.03021526\n",
            "Iteration 3206, loss = 2657518601.27681208\n",
            "Iteration 3207, loss = 2657457082.20185328\n",
            "Iteration 3208, loss = 2657396164.28389215\n",
            "Iteration 3209, loss = 2657335842.04695940\n",
            "Iteration 3210, loss = 2657276110.06023693\n",
            "Iteration 3211, loss = 2657216962.93773794\n",
            "Iteration 3212, loss = 2657158395.33798122\n",
            "Iteration 3213, loss = 2657100401.96367598\n",
            "Iteration 3214, loss = 2657042977.56140232\n",
            "Iteration 3215, loss = 2656986116.92129755\n",
            "Iteration 3216, loss = 2656929814.87673998\n",
            "Iteration 3217, loss = 2656874066.30403852\n",
            "Iteration 3218, loss = 2656818866.12212229\n",
            "Iteration 3219, loss = 2656764209.29223251\n",
            "Iteration 3220, loss = 2656710090.81761503\n",
            "Iteration 3221, loss = 2656656505.74321556\n",
            "Iteration 3222, loss = 2656603449.15537405\n",
            "Iteration 3223, loss = 2656550916.18152952\n",
            "Iteration 3224, loss = 2656498901.98991251\n",
            "Iteration 3225, loss = 2656447401.78925419\n",
            "Iteration 3226, loss = 2656396410.82848310\n",
            "Iteration 3227, loss = 2656345924.39643669\n",
            "Iteration 3228, loss = 2656295937.82156658\n",
            "Iteration 3229, loss = 2656246446.47164345\n",
            "Iteration 3230, loss = 2656197445.75347328\n",
            "Iteration 3231, loss = 2656148931.11260653\n",
            "Iteration 3232, loss = 2656100898.03305387\n",
            "Iteration 3233, loss = 2656053342.03699780\n",
            "Iteration 3234, loss = 2656006258.68451452\n",
            "Iteration 3235, loss = 2655959643.57329130\n",
            "Iteration 3236, loss = 2655913492.33834743\n",
            "Iteration 3237, loss = 2655867800.65175438\n",
            "Iteration 3238, loss = 2655822564.22236347\n",
            "Iteration 3239, loss = 2655777778.79552650\n",
            "Iteration 3240, loss = 2655733440.15283060\n",
            "Iteration 3241, loss = 2655689544.11181831\n",
            "Iteration 3242, loss = 2655646086.52572536\n",
            "Iteration 3243, loss = 2655603063.28320646\n",
            "Iteration 3244, loss = 2655560470.30807686\n",
            "Iteration 3245, loss = 2655518303.55904150\n",
            "Iteration 3246, loss = 2655476559.02943277\n",
            "Iteration 3247, loss = 2655435232.74695015\n",
            "Iteration 3248, loss = 2655394320.77340603\n",
            "Iteration 3249, loss = 2655353819.20445633\n",
            "Iteration 3250, loss = 2655313724.16935158\n",
            "Iteration 3251, loss = 2655274031.83068085\n",
            "Iteration 3252, loss = 2655234738.38411808\n",
            "Iteration 3253, loss = 2655195840.05816889\n",
            "Iteration 3254, loss = 2655157333.11392260\n",
            "Iteration 3255, loss = 2655119213.84480190\n",
            "Iteration 3256, loss = 2655081478.57631445\n",
            "Iteration 3257, loss = 2655044123.66581202\n",
            "Iteration 3258, loss = 2655007145.50224066\n",
            "Iteration 3259, loss = 2654970540.50590181\n",
            "Iteration 3260, loss = 2654934305.12821245\n",
            "Iteration 3261, loss = 2654898435.85145855\n",
            "Iteration 3262, loss = 2654862929.18856621\n",
            "Iteration 3263, loss = 2654827781.68286037\n",
            "Iteration 3264, loss = 2654792989.90783024\n",
            "Iteration 3265, loss = 2654758550.46689844\n",
            "Iteration 3266, loss = 2654724459.99318027\n",
            "Iteration 3267, loss = 2654690715.14926767\n",
            "Iteration 3268, loss = 2654657312.62698841\n",
            "Iteration 3269, loss = 2654624249.14718342\n",
            "Iteration 3270, loss = 2654591521.45948076\n",
            "Iteration 3271, loss = 2654559126.34206629\n",
            "Iteration 3272, loss = 2654527060.60146999\n",
            "Iteration 3273, loss = 2654495321.07233667\n",
            "Iteration 3274, loss = 2654463904.61720610\n",
            "Iteration 3275, loss = 2654432808.12629795\n",
            "Iteration 3276, loss = 2654402028.51729107\n",
            "Iteration 3277, loss = 2654371562.73511124\n",
            "Iteration 3278, loss = 2654341407.75171041\n",
            "Iteration 3279, loss = 2654311560.56586075\n",
            "Iteration 3280, loss = 2654282018.20294046\n",
            "Iteration 3281, loss = 2654252777.71471786\n",
            "Iteration 3282, loss = 2654223836.17915249\n",
            "Iteration 3283, loss = 2654195190.70017910\n",
            "Iteration 3284, loss = 2654166838.40750456\n",
            "Iteration 3285, loss = 2654138776.45640707\n",
            "Iteration 3286, loss = 2654111002.02752495\n",
            "Iteration 3287, loss = 2654083512.32665968\n",
            "Iteration 3288, loss = 2654056304.58457375\n",
            "Iteration 3289, loss = 2654029376.05679464\n",
            "Iteration 3290, loss = 2654002724.02340841\n",
            "Iteration 3291, loss = 2653976345.78887272\n",
            "Iteration 3292, loss = 2653950238.68181467\n",
            "Iteration 3293, loss = 2653924400.05484152\n",
            "Iteration 3294, loss = 2653898827.28434324\n",
            "Iteration 3295, loss = 2653873517.77030611\n",
            "Iteration 3296, loss = 2653848468.93611574\n",
            "Iteration 3297, loss = 2653823678.22837877\n",
            "Iteration 3298, loss = 2653799143.11672354\n",
            "Iteration 3299, loss = 2653774861.09362125\n",
            "Iteration 3300, loss = 2653750829.67420149\n",
            "Iteration 3301, loss = 2653727046.39606285\n",
            "Iteration 3302, loss = 2653703508.81909657\n",
            "Iteration 3303, loss = 2653680214.52530003\n",
            "Iteration 3304, loss = 2653657161.11860228\n",
            "Iteration 3305, loss = 2653634346.22468042\n",
            "Iteration 3306, loss = 2653611767.49078512\n",
            "Iteration 3307, loss = 2653589422.58556414\n",
            "Iteration 3308, loss = 2653567309.19888592\n",
            "Iteration 3309, loss = 2653545425.04166746\n",
            "Iteration 3310, loss = 2653523767.84570312\n",
            "Iteration 3311, loss = 2653502335.36348486\n",
            "Iteration 3312, loss = 2653481125.36804485\n",
            "Iteration 3313, loss = 2653460135.65277767\n",
            "Iteration 3314, loss = 2653439364.03127623\n",
            "Iteration 3315, loss = 2653418808.33716202\n",
            "Iteration 3316, loss = 2653398466.42392397\n",
            "Iteration 3317, loss = 2653378336.16475058\n",
            "Iteration 3318, loss = 2653358415.45236969\n",
            "Iteration 3319, loss = 2653338702.19888496\n",
            "Iteration 3320, loss = 2653319194.33561277\n",
            "Iteration 3321, loss = 2653299889.81292915\n",
            "Iteration 3322, loss = 2653280786.60010481\n",
            "Iteration 3323, loss = 2653261882.68515205\n",
            "Iteration 3324, loss = 2653243176.07466698\n",
            "Iteration 3325, loss = 2653224664.79367304\n",
            "Iteration 3326, loss = 2653206346.88546944\n",
            "Iteration 3327, loss = 2653188220.41147852\n",
            "Iteration 3328, loss = 2653170283.45108795\n",
            "Iteration 3329, loss = 2653152534.10151339\n",
            "Iteration 3330, loss = 2653134970.47763205\n",
            "Iteration 3331, loss = 2653117590.71184731\n",
            "Iteration 3332, loss = 2653100392.95393515\n",
            "Iteration 3333, loss = 2653083375.37090111\n",
            "Iteration 3334, loss = 2653066536.14683151\n",
            "Iteration 3335, loss = 2653049873.48275089\n",
            "Iteration 3336, loss = 2653033385.59648037\n",
            "Iteration 3337, loss = 2653017070.72249413\n",
            "Iteration 3338, loss = 2653000927.11177683\n",
            "Iteration 3339, loss = 2652984953.03168774\n",
            "Iteration 3340, loss = 2652969146.76581621\n",
            "Iteration 3341, loss = 2652953506.61384964\n",
            "Iteration 3342, loss = 2652938030.89143133\n",
            "Iteration 3343, loss = 2652922717.93002939\n",
            "Iteration 3344, loss = 2652907566.07679796\n",
            "Iteration 3345, loss = 2652892573.69444275\n",
            "Iteration 3346, loss = 2652877739.16109419\n",
            "Iteration 3347, loss = 2652863060.87016726\n",
            "Iteration 3348, loss = 2652848537.23023748\n",
            "Iteration 3349, loss = 2652834166.66490650\n",
            "Iteration 3350, loss = 2652819947.61267567\n",
            "Iteration 3351, loss = 2652805878.52681589\n",
            "Iteration 3352, loss = 2652791957.87524319\n",
            "Iteration 3353, loss = 2652778184.14038992\n",
            "Iteration 3354, loss = 2652764555.81908321\n",
            "Iteration 3355, loss = 2652751071.42241430\n",
            "Iteration 3356, loss = 2652737729.47562170\n",
            "Iteration 3357, loss = 2652724528.51796579\n",
            "Iteration 3358, loss = 2652711467.10261059\n",
            "Iteration 3359, loss = 2652698543.79649687\n",
            "Iteration 3360, loss = 2652685757.18022871\n",
            "Iteration 3361, loss = 2652673105.84795046\n",
            "Iteration 3362, loss = 2652660588.40723562\n",
            "Iteration 3363, loss = 2652648203.47896051\n",
            "Iteration 3364, loss = 2652635949.69719458\n",
            "Iteration 3365, loss = 2652623825.70908689\n",
            "Iteration 3366, loss = 2652611830.17474318\n",
            "Iteration 3367, loss = 2652599961.76712370\n",
            "Iteration 3368, loss = 2652588219.17192411\n",
            "Iteration 3369, loss = 2652576601.08746386\n",
            "Iteration 3370, loss = 2652565106.22457504\n",
            "Iteration 3371, loss = 2652553733.30649996\n",
            "Iteration 3372, loss = 2652542481.06877089\n",
            "Iteration 3373, loss = 2652531348.25910950\n",
            "Iteration 3374, loss = 2652520333.63731766\n",
            "Iteration 3375, loss = 2652509435.97517014\n",
            "Iteration 3376, loss = 2652498654.05631113\n",
            "Iteration 3377, loss = 2652487986.67614412\n",
            "Iteration 3378, loss = 2652477432.64173555\n",
            "Iteration 3379, loss = 2652466990.77170467\n",
            "Iteration 3380, loss = 2652456659.89612579\n",
            "Iteration 3381, loss = 2652446438.85642290\n",
            "Iteration 3382, loss = 2652436326.50527287\n",
            "Iteration 3383, loss = 2652426321.70650291\n",
            "Iteration 3384, loss = 2652416423.33499050\n",
            "Iteration 3385, loss = 2652406630.27656603\n",
            "Iteration 3386, loss = 2652396941.42791843\n",
            "Iteration 3387, loss = 2652387355.69649363\n",
            "Iteration 3388, loss = 2652377872.00039864\n",
            "Iteration 3389, loss = 2652368489.26830816\n",
            "Iteration 3390, loss = 2652359206.43936968\n",
            "Iteration 3391, loss = 2652350022.46311045\n",
            "Iteration 3392, loss = 2652340936.29934072\n",
            "Iteration 3393, loss = 2652331946.91806555\n",
            "Iteration 3394, loss = 2652323053.29939222\n",
            "Iteration 3395, loss = 2652314254.43343592\n",
            "Iteration 3396, loss = 2652305549.32023430\n",
            "Iteration 3397, loss = 2652296936.96965551\n",
            "Iteration 3398, loss = 2652288416.40130949\n",
            "Iteration 3399, loss = 2652279986.64446068\n",
            "Iteration 3400, loss = 2652271646.73794031\n",
            "Iteration 3401, loss = 2652263395.73006058\n",
            "Iteration 3402, loss = 2652255232.67852640\n",
            "Iteration 3403, loss = 2652247156.65035391\n",
            "Iteration 3404, loss = 2652239166.72178316\n",
            "Iteration 3405, loss = 2652231261.97819233\n",
            "Iteration 3406, loss = 2652223441.51402187\n",
            "Iteration 3407, loss = 2652215704.43268299\n",
            "Iteration 3408, loss = 2652208049.84648514\n",
            "Iteration 3409, loss = 2652200476.87654352\n",
            "Iteration 3410, loss = 2652192984.65271187\n",
            "Iteration 3411, loss = 2652185572.31348991\n",
            "Iteration 3412, loss = 2652178239.00595474\n",
            "Iteration 3413, loss = 2652170983.88567352\n",
            "Iteration 3414, loss = 2652163806.11663294\n",
            "Iteration 3415, loss = 2652156704.87115717\n",
            "Iteration 3416, loss = 2652149679.32983255\n",
            "Iteration 3417, loss = 2652142728.68143320\n",
            "Iteration 3418, loss = 2652135852.12284279\n",
            "Iteration 3419, loss = 2652129048.85898209\n",
            "Iteration 3420, loss = 2652122318.10273504\n",
            "Iteration 3421, loss = 2652115659.07487297\n",
            "Iteration 3422, loss = 2652109071.00398397\n",
            "Iteration 3423, loss = 2652102553.12639713\n",
            "Iteration 3424, loss = 2652096104.68611860\n",
            "Iteration 3425, loss = 2652089724.93475008\n",
            "Iteration 3426, loss = 2652083413.13142776\n",
            "Iteration 3427, loss = 2652077168.54274273\n",
            "Iteration 3428, loss = 2652070990.44268513\n",
            "Iteration 3429, loss = 2652064878.11255932\n",
            "Iteration 3430, loss = 2652058830.84092951\n",
            "Iteration 3431, loss = 2652052847.92354441\n",
            "Iteration 3432, loss = 2652046928.66327000\n",
            "Iteration 3433, loss = 2652041072.37002945\n",
            "Iteration 3434, loss = 2652035278.36073065\n",
            "Iteration 3435, loss = 2652029545.95920277\n",
            "Iteration 3436, loss = 2652023874.49613428\n",
            "Iteration 3437, loss = 2652018263.30900478\n",
            "Iteration 3438, loss = 2652012711.74202156\n",
            "Iteration 3439, loss = 2652007219.14606047\n",
            "Iteration 3440, loss = 2652001784.87859869\n",
            "Iteration 3441, loss = 2651996408.30365467\n",
            "Iteration 3442, loss = 2651991088.79172659\n",
            "Iteration 3443, loss = 2651985825.71973181\n",
            "Iteration 3444, loss = 2651980618.47094393\n",
            "Iteration 3445, loss = 2651975466.43493509\n",
            "Iteration 3446, loss = 2651970369.00751686\n",
            "Iteration 3447, loss = 2651965325.59067774\n",
            "Iteration 3448, loss = 2651960335.59253025\n",
            "Iteration 3449, loss = 2651955398.42724562\n",
            "Iteration 3450, loss = 2651950513.51500463\n",
            "Iteration 3451, loss = 2651945680.28193331\n",
            "Iteration 3452, loss = 2651940898.16004944\n",
            "Iteration 3453, loss = 2651936166.58721066\n",
            "Iteration 3454, loss = 2651931485.00704861\n",
            "Iteration 3455, loss = 2651926852.86892605\n",
            "Iteration 3456, loss = 2651922269.62787008\n",
            "Iteration 3457, loss = 2651917734.74453211\n",
            "Iteration 3458, loss = 2651913247.68511820\n",
            "Iteration 3459, loss = 2651908807.92134762\n",
            "Iteration 3460, loss = 2651904414.93039799\n",
            "Iteration 3461, loss = 2651900068.19484854\n",
            "Iteration 3462, loss = 2651895767.20263338\n",
            "Iteration 3463, loss = 2651891511.44698620\n",
            "Iteration 3464, loss = 2651887300.42639351\n",
            "Iteration 3465, loss = 2651883133.64453888\n",
            "Iteration 3466, loss = 2651879010.61025667\n",
            "Iteration 3467, loss = 2651874930.83748436\n",
            "Iteration 3468, loss = 2651870893.84520626\n",
            "Iteration 3469, loss = 2651866899.15741253\n",
            "Iteration 3470, loss = 2651862946.30304623\n",
            "Iteration 3471, loss = 2651859034.81595516\n",
            "Iteration 3472, loss = 2651855164.23484945\n",
            "Iteration 3473, loss = 2651851334.10324621\n",
            "Iteration 3474, loss = 2651847543.96943235\n",
            "Iteration 3475, loss = 2651843793.38641167\n",
            "Iteration 3476, loss = 2651840081.91185808\n",
            "Iteration 3477, loss = 2651836409.10807991\n",
            "Iteration 3478, loss = 2651832774.54196310\n",
            "Iteration 3479, loss = 2651829177.78493071\n",
            "Iteration 3480, loss = 2651825618.41290426\n",
            "Iteration 3481, loss = 2651822096.00625181\n",
            "Iteration 3482, loss = 2651818610.14975071\n",
            "Iteration 3483, loss = 2651815160.43253756\n",
            "Iteration 3484, loss = 2651811746.44807529\n",
            "Iteration 3485, loss = 2651808367.79410076\n",
            "Iteration 3486, loss = 2651805024.07258940\n",
            "Iteration 3487, loss = 2651801714.88971472\n",
            "Iteration 3488, loss = 2651798439.85579872\n",
            "Iteration 3489, loss = 2651795198.58528137\n",
            "Iteration 3490, loss = 2651791990.69667244\n",
            "Iteration 3491, loss = 2651788815.81251717\n",
            "Iteration 3492, loss = 2651785673.55935049\n",
            "Iteration 3493, loss = 2651782563.56766462\n",
            "Iteration 3494, loss = 2651779485.47186565\n",
            "Iteration 3495, loss = 2651776438.91023302\n",
            "Iteration 3496, loss = 2651773423.52488708\n",
            "Iteration 3497, loss = 2651770438.96174908\n",
            "Iteration 3498, loss = 2651767484.87049866\n",
            "Iteration 3499, loss = 2651764560.90454388\n",
            "Iteration 3500, loss = 2651761666.72097778\n",
            "Iteration 3501, loss = 2651758801.98054838\n",
            "Iteration 3502, loss = 2651755966.34761715\n",
            "Iteration 3503, loss = 2651753159.49012470\n",
            "Iteration 3504, loss = 2651750381.07955647\n",
            "Iteration 3505, loss = 2651747630.79090691\n",
            "Iteration 3506, loss = 2651744908.30264187\n",
            "Iteration 3507, loss = 2651742213.29666662\n",
            "Iteration 3508, loss = 2651739545.45829439\n",
            "Iteration 3509, loss = 2651736904.47620392\n",
            "Iteration 3510, loss = 2651734290.04241371\n",
            "Iteration 3511, loss = 2651731701.85224819\n",
            "Iteration 3512, loss = 2651729139.60429573\n",
            "Iteration 3513, loss = 2651726603.00038862\n",
            "Iteration 3514, loss = 2651724091.74556065\n",
            "Iteration 3515, loss = 2651721605.54802227\n",
            "Iteration 3516, loss = 2651719144.11912012\n",
            "Iteration 3517, loss = 2651716707.17331553\n",
            "Iteration 3518, loss = 2651714294.42814445\n",
            "Iteration 3519, loss = 2651711905.60419178\n",
            "Iteration 3520, loss = 2651709540.42505980\n",
            "Iteration 3521, loss = 2651707198.61733437\n",
            "Iteration 3522, loss = 2651704879.91056061\n",
            "Iteration 3523, loss = 2651702584.03720713\n",
            "Iteration 3524, loss = 2651700310.73264122\n",
            "Iteration 3525, loss = 2651698059.73509550\n",
            "Iteration 3526, loss = 2651695830.78564167\n",
            "Iteration 3527, loss = 2651693623.62816238\n",
            "Iteration 3528, loss = 2651691438.00931931\n",
            "Iteration 3529, loss = 2651689273.67852545\n",
            "Iteration 3530, loss = 2651687130.38792276\n",
            "Iteration 3531, loss = 2651685007.89234638\n",
            "Iteration 3532, loss = 2651682905.94930458\n",
            "Iteration 3533, loss = 2651680824.31894302\n",
            "Iteration 3534, loss = 2651678762.76402807\n",
            "Iteration 3535, loss = 2651676721.04991102\n",
            "Iteration 3536, loss = 2651674698.94450998\n",
            "Iteration 3537, loss = 2651672696.21827269\n",
            "Iteration 3538, loss = 2651670712.64416265\n",
            "Iteration 3539, loss = 2651668747.99762487\n",
            "Iteration 3540, loss = 2651666802.05656528\n",
            "Iteration 3541, loss = 2651664874.60132217\n",
            "Iteration 3542, loss = 2651662965.41464233\n",
            "Iteration 3543, loss = 2651661074.28165960\n",
            "Iteration 3544, loss = 2651659200.98986483\n",
            "Iteration 3545, loss = 2651657345.32908392\n",
            "Iteration 3546, loss = 2651655507.09145451\n",
            "Iteration 3547, loss = 2651653686.07140398\n",
            "Iteration 3548, loss = 2651651882.06562042\n",
            "Iteration 3549, loss = 2651650094.87303543\n",
            "Iteration 3550, loss = 2651648324.29479361\n",
            "Iteration 3551, loss = 2651646570.13423824\n",
            "Iteration 3552, loss = 2651644832.19688511\n",
            "Iteration 3553, loss = 2651643110.29039383\n",
            "Iteration 3554, loss = 2651641404.22455549\n",
            "Iteration 3555, loss = 2651639713.81126595\n",
            "Iteration 3556, loss = 2651638038.86450291\n",
            "Iteration 3557, loss = 2651636379.20030451\n",
            "Iteration 3558, loss = 2651634734.63675117\n",
            "Iteration 3559, loss = 2651633104.99394178\n",
            "Iteration 3560, loss = 2651631490.09397316\n",
            "Iteration 3561, loss = 2651629889.76091671\n",
            "Iteration 3562, loss = 2651628303.82080221\n",
            "Iteration 3563, loss = 2651626732.10159826\n",
            "Iteration 3564, loss = 2651625174.43318272\n",
            "Iteration 3565, loss = 2651623630.64733410\n",
            "Iteration 3566, loss = 2651622100.57770634\n",
            "Iteration 3567, loss = 2651620584.05980635\n",
            "Iteration 3568, loss = 2651619080.93098307\n",
            "Iteration 3569, loss = 2651617591.03039837\n",
            "Iteration 3570, loss = 2651616114.19901514\n",
            "Iteration 3571, loss = 2651614650.27957535\n",
            "Iteration 3572, loss = 2651613199.11658096\n",
            "Iteration 3573, loss = 2651611760.55627728\n",
            "Iteration 3574, loss = 2651610334.44663429\n",
            "Iteration 3575, loss = 2651608920.63732576\n",
            "Iteration 3576, loss = 2651607518.97971439\n",
            "Iteration 3577, loss = 2651606129.32683611\n",
            "Iteration 3578, loss = 2651604751.53337288\n",
            "Iteration 3579, loss = 2651603385.45564699\n",
            "Iteration 3580, loss = 2651602030.95159626\n",
            "Iteration 3581, loss = 2651600687.88075876\n",
            "Iteration 3582, loss = 2651599356.10425806\n",
            "Iteration 3583, loss = 2651598035.48478317\n",
            "Iteration 3584, loss = 2651596725.88657284\n",
            "Iteration 3585, loss = 2651595427.17540026\n",
            "Iteration 3586, loss = 2651594139.21855640\n",
            "Iteration 3587, loss = 2651592861.88483429\n",
            "Iteration 3588, loss = 2651591595.04450941\n",
            "Iteration 3589, loss = 2651590338.56933069\n",
            "Iteration 3590, loss = 2651589092.33249760\n",
            "Iteration 3591, loss = 2651587856.20865011\n",
            "Iteration 3592, loss = 2651586630.07384968\n",
            "Iteration 3593, loss = 2651585413.80556726\n",
            "Iteration 3594, loss = 2651584207.28266525\n",
            "Iteration 3595, loss = 2651583010.38538361\n",
            "Iteration 3596, loss = 2651581822.99532795\n",
            "Iteration 3597, loss = 2651580644.99544907\n",
            "Iteration 3598, loss = 2651579476.27003384\n",
            "Iteration 3599, loss = 2651578316.70468903\n",
            "Iteration 3600, loss = 2651577166.18632555\n",
            "Iteration 3601, loss = 2651576024.60314703\n",
            "Iteration 3602, loss = 2651574891.84463310\n",
            "Iteration 3603, loss = 2651573767.80153131\n",
            "Iteration 3604, loss = 2651572652.36583471\n",
            "Iteration 3605, loss = 2651571545.43077469\n",
            "Iteration 3606, loss = 2651570446.89080763\n",
            "Iteration 3607, loss = 2651569356.64159966\n",
            "Iteration 3608, loss = 2651568274.58001280\n",
            "Iteration 3609, loss = 2651567200.60409307\n",
            "Iteration 3610, loss = 2651566134.61306000\n",
            "Iteration 3611, loss = 2651565076.50729227\n",
            "Iteration 3612, loss = 2651564026.18830919\n",
            "Iteration 3613, loss = 2651562983.55877113\n",
            "Iteration 3614, loss = 2651561948.52245474\n",
            "Iteration 3615, loss = 2651560920.98424959\n",
            "Iteration 3616, loss = 2651559900.85013676\n",
            "Iteration 3617, loss = 2651558888.02719069\n",
            "Iteration 3618, loss = 2651557882.42355347\n",
            "Iteration 3619, loss = 2651556883.94843006\n",
            "Iteration 3620, loss = 2651555892.51207638\n",
            "Iteration 3621, loss = 2651554908.02578545\n",
            "Iteration 3622, loss = 2651553930.40188026\n",
            "Iteration 3623, loss = 2651552959.55369902\n",
            "Iteration 3624, loss = 2651551995.39558268\n",
            "Iteration 3625, loss = 2651551037.84286928\n",
            "Iteration 3626, loss = 2651550086.81187820\n",
            "Iteration 3627, loss = 2651549142.21990156\n",
            "Iteration 3628, loss = 2651548203.98519373\n",
            "Iteration 3629, loss = 2651547272.02696180\n",
            "Iteration 3630, loss = 2651546346.26534796\n",
            "Iteration 3631, loss = 2651545426.62143087\n",
            "Iteration 3632, loss = 2651544513.01720619\n",
            "Iteration 3633, loss = 2651543605.37558031\n",
            "Iteration 3634, loss = 2651542703.62035894\n",
            "Iteration 3635, loss = 2651541807.67623997\n",
            "Iteration 3636, loss = 2651540917.46879911\n",
            "Iteration 3637, loss = 2651540032.92448378\n",
            "Iteration 3638, loss = 2651539153.97060108\n",
            "Iteration 3639, loss = 2651538280.53531075\n",
            "Iteration 3640, loss = 2651537412.54761457\n",
            "Iteration 3641, loss = 2651536549.93734598\n",
            "Iteration 3642, loss = 2651535692.63516188\n",
            "Iteration 3643, loss = 2651534840.57253504\n",
            "Iteration 3644, loss = 2651533993.68174076\n",
            "Iteration 3645, loss = 2651533151.89585257\n",
            "Iteration 3646, loss = 2651532315.14873171\n",
            "Iteration 3647, loss = 2651531483.37501764\n",
            "Iteration 3648, loss = 2651530656.51011753\n",
            "Iteration 3649, loss = 2651529834.49020338\n",
            "Iteration 3650, loss = 2651529017.25219822\n",
            "Iteration 3651, loss = 2651528204.73377037\n",
            "Iteration 3652, loss = 2651527396.87332439\n",
            "Iteration 3653, loss = 2651526593.60999107\n",
            "Iteration 3654, loss = 2651525794.88362312\n",
            "Iteration 3655, loss = 2651525000.63478565\n",
            "Iteration 3656, loss = 2651524210.80474567\n",
            "Iteration 3657, loss = 2651523425.33546591\n",
            "Iteration 3658, loss = 2651522644.16959906\n",
            "Iteration 3659, loss = 2651521867.25047684\n",
            "Iteration 3660, loss = 2651521094.52210474\n",
            "Iteration 3661, loss = 2651520325.92915249\n",
            "Iteration 3662, loss = 2651519561.41694832\n",
            "Iteration 3663, loss = 2651518800.93147135\n",
            "Iteration 3664, loss = 2651518044.41934061\n",
            "Iteration 3665, loss = 2651517291.82781410\n",
            "Iteration 3666, loss = 2651516543.10477734\n",
            "Iteration 3667, loss = 2651515798.19874001\n",
            "Iteration 3668, loss = 2651515057.05881834\n",
            "Iteration 3669, loss = 2651514319.63474560\n",
            "Iteration 3670, loss = 2651513585.87685013\n",
            "Iteration 3671, loss = 2651512855.73605537\n",
            "Iteration 3672, loss = 2651512129.16387177\n",
            "Iteration 3673, loss = 2651511406.11239147\n",
            "Iteration 3674, loss = 2651510686.53427935\n",
            "Iteration 3675, loss = 2651509970.38276625\n",
            "Iteration 3676, loss = 2651509257.61164713\n",
            "Iteration 3677, loss = 2651508548.17526913\n",
            "Iteration 3678, loss = 2651507842.02852726\n",
            "Iteration 3679, loss = 2651507139.12686253\n",
            "Iteration 3680, loss = 2651506439.42624569\n",
            "Iteration 3681, loss = 2651505742.88318205\n",
            "Iteration 3682, loss = 2651505049.45469761\n",
            "Iteration 3683, loss = 2651504359.09834003\n",
            "Iteration 3684, loss = 2651503671.77216244\n",
            "Iteration 3685, loss = 2651502987.43472958\n",
            "Iteration 3686, loss = 2651502306.04510403\n",
            "Iteration 3687, loss = 2651501627.56284189\n",
            "Iteration 3688, loss = 2651500951.94798994\n",
            "Iteration 3689, loss = 2651500279.16107702\n",
            "Iteration 3690, loss = 2651499609.16310978\n",
            "Iteration 3691, loss = 2651498941.91556597\n",
            "Iteration 3692, loss = 2651498277.38039112\n",
            "Iteration 3693, loss = 2651497615.51999283\n",
            "Iteration 3694, loss = 2651496956.29723310\n",
            "Iteration 3695, loss = 2651496299.67542458\n",
            "Iteration 3696, loss = 2651495645.61832714\n",
            "Iteration 3697, loss = 2651494994.09013987\n",
            "Iteration 3698, loss = 2651494345.05549717\n",
            "Iteration 3699, loss = 2651493698.47946405\n",
            "Iteration 3700, loss = 2651493054.32753086\n",
            "Iteration 3701, loss = 2651492412.56560755\n",
            "Iteration 3702, loss = 2651491773.16002131\n",
            "Iteration 3703, loss = 2651491136.07750797\n",
            "Iteration 3704, loss = 2651490501.28521061\n",
            "Iteration 3705, loss = 2651489868.75067520\n",
            "Iteration 3706, loss = 2651489238.44183922\n",
            "Iteration 3707, loss = 2651488610.32703876\n",
            "Iteration 3708, loss = 2651487984.37499046\n",
            "Iteration 3709, loss = 2651487360.55479908\n",
            "Iteration 3710, loss = 2651486738.83594656\n",
            "Iteration 3711, loss = 2651486119.18828773\n",
            "Iteration 3712, loss = 2651485501.58204794\n",
            "Iteration 3713, loss = 2651484885.98781824\n",
            "Iteration 3714, loss = 2651484272.37654972\n",
            "Iteration 3715, loss = 2651483660.71955109\n",
            "Iteration 3716, loss = 2651483050.98848438\n",
            "Iteration 3717, loss = 2651482443.15535927\n",
            "Iteration 3718, loss = 2651481837.19252968\n",
            "Iteration 3719, loss = 2651481233.07269096\n",
            "Iteration 3720, loss = 2651480630.76887465\n",
            "Iteration 3721, loss = 2651480030.25444508\n",
            "Iteration 3722, loss = 2651479431.50309372\n",
            "Iteration 3723, loss = 2651478834.48883867\n",
            "Iteration 3724, loss = 2651478239.18601847\n",
            "Iteration 3725, loss = 2651477645.56928921\n",
            "Iteration 3726, loss = 2651477053.61361885\n",
            "Iteration 3727, loss = 2651476463.29428577\n",
            "Iteration 3728, loss = 2651475874.58687592\n",
            "Iteration 3729, loss = 2651475287.46727657\n",
            "Iteration 3730, loss = 2651474701.91167402\n",
            "Iteration 3731, loss = 2651474117.89654875\n",
            "Iteration 3732, loss = 2651473535.39867592\n",
            "Iteration 3733, loss = 2651472954.39511585\n",
            "Iteration 3734, loss = 2651472374.86321640\n",
            "Iteration 3735, loss = 2651471796.78060675\n",
            "Iteration 3736, loss = 2651471220.12519360\n",
            "Iteration 3737, loss = 2651470644.87515831\n",
            "Iteration 3738, loss = 2651470071.00895548\n",
            "Iteration 3739, loss = 2651469498.50530577\n",
            "Iteration 3740, loss = 2651468927.34319878\n",
            "Iteration 3741, loss = 2651468357.50188303\n",
            "Iteration 3742, loss = 2651467788.96086788\n",
            "Iteration 3743, loss = 2651467221.69991779\n",
            "Iteration 3744, loss = 2651466655.69904995\n",
            "Iteration 3745, loss = 2651466090.93853188\n",
            "Iteration 3746, loss = 2651465527.39888000\n",
            "Iteration 3747, loss = 2651464965.06084871\n",
            "Iteration 3748, loss = 2651464403.90544224\n",
            "Iteration 3749, loss = 2651463843.91389465\n",
            "Iteration 3750, loss = 2651463285.06768036\n",
            "Iteration 3751, loss = 2651462727.34850359\n",
            "Iteration 3752, loss = 2651462170.73830032\n",
            "Iteration 3753, loss = 2651461615.21923399\n",
            "Iteration 3754, loss = 2651461060.77368689\n",
            "Iteration 3755, loss = 2651460507.38426924\n",
            "Iteration 3756, loss = 2651459955.03380823\n",
            "Iteration 3757, loss = 2651459403.70534706\n",
            "Iteration 3758, loss = 2651458853.38213921\n",
            "Iteration 3759, loss = 2651458304.04765415\n",
            "Iteration 3760, loss = 2651457755.68556833\n",
            "Iteration 3761, loss = 2651457208.27976274\n",
            "Iteration 3762, loss = 2651456661.81432295\n",
            "Iteration 3763, loss = 2651456116.27353573\n",
            "Iteration 3764, loss = 2651455571.64188623\n",
            "Iteration 3765, loss = 2651455027.90405607\n",
            "Iteration 3766, loss = 2651454485.04491997\n",
            "Iteration 3767, loss = 2651453943.04954529\n",
            "Iteration 3768, loss = 2651453401.90318680\n",
            "Iteration 3769, loss = 2651452861.59128809\n",
            "Iteration 3770, loss = 2651452322.09947538\n",
            "Iteration 3771, loss = 2651451783.41355991\n",
            "Iteration 3772, loss = 2651451245.51952934\n",
            "Iteration 3773, loss = 2651450708.40355396\n",
            "Iteration 3774, loss = 2651450172.05197477\n",
            "Iteration 3775, loss = 2651449636.45131111\n",
            "Iteration 3776, loss = 2651449101.58825111\n",
            "Iteration 3777, loss = 2651448567.44965124\n",
            "Iteration 3778, loss = 2651448034.02253962\n",
            "Iteration 3779, loss = 2651447501.29410553\n",
            "Iteration 3780, loss = 2651446969.25170231\n",
            "Iteration 3781, loss = 2651446437.88284779\n",
            "Iteration 3782, loss = 2651445907.17521477\n",
            "Iteration 3783, loss = 2651445377.11663485\n",
            "Iteration 3784, loss = 2651444847.69509792\n",
            "Iteration 3785, loss = 2651444318.89874411\n",
            "Iteration 3786, loss = 2651443790.71586466\n",
            "Iteration 3787, loss = 2651443263.13490391\n",
            "Iteration 3788, loss = 2651442736.14445114\n",
            "Iteration 3789, loss = 2651442209.73324490\n",
            "Iteration 3790, loss = 2651441683.89016390\n",
            "Iteration 3791, loss = 2651441158.60423326\n",
            "Iteration 3792, loss = 2651440633.86461496\n",
            "Iteration 3793, loss = 2651440109.66061592\n",
            "Iteration 3794, loss = 2651439585.98167419\n",
            "Iteration 3795, loss = 2651439062.81736755\n",
            "Iteration 3796, loss = 2651438540.15740633\n",
            "Iteration 3797, loss = 2651438017.99163103\n",
            "Iteration 3798, loss = 2651437496.31001759\n",
            "Iteration 3799, loss = 2651436975.10266733\n",
            "Iteration 3800, loss = 2651436454.35980988\n",
            "Iteration 3801, loss = 2651435934.07180071\n",
            "Iteration 3802, loss = 2651435414.22912121\n",
            "Iteration 3803, loss = 2651434894.82237387\n",
            "Iteration 3804, loss = 2651434375.84228134\n",
            "Iteration 3805, loss = 2651433857.27968884\n",
            "Iteration 3806, loss = 2651433339.12555695\n",
            "Iteration 3807, loss = 2651432821.37096643\n",
            "Iteration 3808, loss = 2651432304.00711012\n",
            "Iteration 3809, loss = 2651431787.02529716\n",
            "Iteration 3810, loss = 2651431270.41694689\n",
            "Iteration 3811, loss = 2651430754.17359114\n",
            "Iteration 3812, loss = 2651430238.28687191\n",
            "Iteration 3813, loss = 2651429722.74853802\n",
            "Iteration 3814, loss = 2651429207.55044508\n",
            "Iteration 3815, loss = 2651428692.68455696\n",
            "Iteration 3816, loss = 2651428178.14293909\n",
            "Iteration 3817, loss = 2651427663.91776085\n",
            "Iteration 3818, loss = 2651427150.00129366\n",
            "Iteration 3819, loss = 2651426636.38590717\n",
            "Iteration 3820, loss = 2651426123.06407499\n",
            "Iteration 3821, loss = 2651425610.02836323\n",
            "Iteration 3822, loss = 2651425097.27143717\n",
            "Iteration 3823, loss = 2651424584.78605890\n",
            "Iteration 3824, loss = 2651424072.56508207\n",
            "Iteration 3825, loss = 2651423560.60145426\n",
            "Iteration 3826, loss = 2651423048.88821697\n",
            "Iteration 3827, loss = 2651422537.41849756\n",
            "Iteration 3828, loss = 2651422026.18551970\n",
            "Iteration 3829, loss = 2651421515.18258953\n",
            "Iteration 3830, loss = 2651421004.40310383\n",
            "Iteration 3831, loss = 2651420493.84054422\n",
            "Iteration 3832, loss = 2651419983.48847723\n",
            "Iteration 3833, loss = 2651419473.34055662\n",
            "Iteration 3834, loss = 2651418963.39051485\n",
            "Iteration 3835, loss = 2651418453.63216734\n",
            "Iteration 3836, loss = 2651417944.05941105\n",
            "Iteration 3837, loss = 2651417434.66622543\n",
            "Iteration 3838, loss = 2651416925.44666338\n",
            "Iteration 3839, loss = 2651416416.39486122\n",
            "Iteration 3840, loss = 2651415907.50502729\n",
            "Iteration 3841, loss = 2651415398.77144814\n",
            "Iteration 3842, loss = 2651414890.18848515\n",
            "Iteration 3843, loss = 2651414381.75057459\n",
            "Iteration 3844, loss = 2651413873.45222378\n",
            "Iteration 3845, loss = 2651413365.28801346\n",
            "Iteration 3846, loss = 2651412857.25259304\n",
            "Iteration 3847, loss = 2651412349.34068680\n",
            "Iteration 3848, loss = 2651411841.54708433\n",
            "Iteration 3849, loss = 2651411333.86664581\n",
            "Iteration 3850, loss = 2651410826.29429722\n",
            "Iteration 3851, loss = 2651410318.82503366\n",
            "Iteration 3852, loss = 2651409811.45391321\n",
            "Iteration 3853, loss = 2651409304.17606115\n",
            "Iteration 3854, loss = 2651408796.98666620\n",
            "Iteration 3855, loss = 2651408289.88098097\n",
            "Iteration 3856, loss = 2651407782.85431957\n",
            "Iteration 3857, loss = 2651407275.90205717\n",
            "Iteration 3858, loss = 2651406769.01963282\n",
            "Iteration 3859, loss = 2651406262.20254374\n",
            "Iteration 3860, loss = 2651405755.44634581\n",
            "Iteration 3861, loss = 2651405248.74665499\n",
            "Iteration 3862, loss = 2651404742.09914351\n",
            "Iteration 3863, loss = 2651404235.49954271\n",
            "Iteration 3864, loss = 2651403728.94363880\n",
            "Iteration 3865, loss = 2651403222.42727566\n",
            "Iteration 3866, loss = 2651402715.94634676\n",
            "Iteration 3867, loss = 2651402209.49680614\n",
            "Iteration 3868, loss = 2651401703.07465887\n",
            "Iteration 3869, loss = 2651401196.67596149\n",
            "Iteration 3870, loss = 2651400690.29682398\n",
            "Iteration 3871, loss = 2651400183.93340683\n",
            "Iteration 3872, loss = 2651399677.58192348\n",
            "Iteration 3873, loss = 2651399171.23863459\n",
            "Iteration 3874, loss = 2651398664.89985275\n",
            "Iteration 3875, loss = 2651398158.56193733\n",
            "Iteration 3876, loss = 2651397652.22129679\n",
            "Iteration 3877, loss = 2651397145.87438774\n",
            "Iteration 3878, loss = 2651396639.51771116\n",
            "Iteration 3879, loss = 2651396133.14781904\n",
            "Iteration 3880, loss = 2651395626.76130295\n",
            "Iteration 3881, loss = 2651395120.35480642\n",
            "Iteration 3882, loss = 2651394613.92501211\n",
            "Iteration 3883, loss = 2651394107.46864700\n",
            "Iteration 3884, loss = 2651393600.98248529\n",
            "Iteration 3885, loss = 2651393094.46333933\n",
            "Iteration 3886, loss = 2651392587.90806675\n",
            "Iteration 3887, loss = 2651392081.31356621\n",
            "Iteration 3888, loss = 2651391574.67677784\n",
            "Iteration 3889, loss = 2651391067.99467850\n",
            "Iteration 3890, loss = 2651390561.26429129\n",
            "Iteration 3891, loss = 2651390054.48267508\n",
            "Iteration 3892, loss = 2651389547.64692831\n",
            "Iteration 3893, loss = 2651389040.75418758\n",
            "Iteration 3894, loss = 2651388533.80162764\n",
            "Iteration 3895, loss = 2651388026.78646088\n",
            "Iteration 3896, loss = 2651387519.70593834\n",
            "Iteration 3897, loss = 2651387012.55734396\n",
            "Iteration 3898, loss = 2651386505.33800077\n",
            "Iteration 3899, loss = 2651385998.04526520\n",
            "Iteration 3900, loss = 2651385490.67652988\n",
            "Iteration 3901, loss = 2651384983.22922230\n",
            "Iteration 3902, loss = 2651384475.70080280\n",
            "Iteration 3903, loss = 2651383968.08876657\n",
            "Iteration 3904, loss = 2651383460.39064169\n",
            "Iteration 3905, loss = 2651382952.60398865\n",
            "Iteration 3906, loss = 2651382444.72640085\n",
            "Iteration 3907, loss = 2651381936.75550318\n",
            "Iteration 3908, loss = 2651381428.68895245\n",
            "Iteration 3909, loss = 2651380920.52443457\n",
            "Iteration 3910, loss = 2651380412.25966930\n",
            "Iteration 3911, loss = 2651379903.89240503\n",
            "Iteration 3912, loss = 2651379395.42041922\n",
            "Iteration 3913, loss = 2651378886.84152126\n",
            "Iteration 3914, loss = 2651378378.15354538\n",
            "Iteration 3915, loss = 2651377869.35435867\n",
            "Iteration 3916, loss = 2651377360.44185352\n",
            "Iteration 3917, loss = 2651376851.41395187\n",
            "Iteration 3918, loss = 2651376342.26860428\n",
            "Iteration 3919, loss = 2651375833.00378561\n",
            "Iteration 3920, loss = 2651375323.61749697\n",
            "Iteration 3921, loss = 2651374814.10777140\n",
            "Iteration 3922, loss = 2651374304.47266197\n",
            "Iteration 3923, loss = 2651373794.71025133\n",
            "Iteration 3924, loss = 2651373284.81864309\n",
            "Iteration 3925, loss = 2651372774.79597235\n",
            "Iteration 3926, loss = 2651372264.64039373\n",
            "Iteration 3927, loss = 2651371754.35008621\n",
            "Iteration 3928, loss = 2651371243.92325783\n",
            "Iteration 3929, loss = 2651370733.35813189\n",
            "Iteration 3930, loss = 2651370222.65296555\n",
            "Iteration 3931, loss = 2651369711.80603075\n",
            "Iteration 3932, loss = 2651369200.81562471\n",
            "Iteration 3933, loss = 2651368689.68006706\n",
            "Iteration 3934, loss = 2651368178.39770126\n",
            "Iteration 3935, loss = 2651367666.96688938\n",
            "Iteration 3936, loss = 2651367155.38601875\n",
            "Iteration 3937, loss = 2651366643.65349436\n",
            "Iteration 3938, loss = 2651366131.76774502\n",
            "Iteration 3939, loss = 2651365619.72721720\n",
            "Iteration 3940, loss = 2651365107.53038120\n",
            "Iteration 3941, loss = 2651364595.17572451\n",
            "Iteration 3942, loss = 2651364082.66175747\n",
            "Iteration 3943, loss = 2651363569.98700666\n",
            "Iteration 3944, loss = 2651363057.15002012\n",
            "Iteration 3945, loss = 2651362544.14936256\n",
            "Iteration 3946, loss = 2651362030.98362112\n",
            "Iteration 3947, loss = 2651361517.65140057\n",
            "Iteration 3948, loss = 2651361004.15131950\n",
            "Iteration 3949, loss = 2651360490.48201990\n",
            "Iteration 3950, loss = 2651359976.64215994\n",
            "Iteration 3951, loss = 2651359462.63041353\n",
            "Iteration 3952, loss = 2651358948.44547462\n",
            "Iteration 3953, loss = 2651358434.08605146\n",
            "Iteration 3954, loss = 2651357919.55087090\n",
            "Iteration 3955, loss = 2651357404.83867598\n",
            "Iteration 3956, loss = 2651356889.94822598\n",
            "Iteration 3957, loss = 2651356374.87829638\n",
            "Iteration 3958, loss = 2651355859.62767792\n",
            "Iteration 3959, loss = 2651355344.19517899\n",
            "Iteration 3960, loss = 2651354828.57961941\n",
            "Iteration 3961, loss = 2651354312.77983952\n",
            "Iteration 3962, loss = 2651353796.79469061\n",
            "Iteration 3963, loss = 2651353280.62304115\n",
            "Iteration 3964, loss = 2651352764.26377153\n",
            "Iteration 3965, loss = 2651352247.71578026\n",
            "Iteration 3966, loss = 2651351730.97797680\n",
            "Iteration 3967, loss = 2651351214.04928684\n",
            "Iteration 3968, loss = 2651350696.92864943\n",
            "Iteration 3969, loss = 2651350179.61501408\n",
            "Iteration 3970, loss = 2651349662.10734892\n",
            "Iteration 3971, loss = 2651349144.40463257\n",
            "Iteration 3972, loss = 2651348626.50585842\n",
            "Iteration 3973, loss = 2651348108.41002846\n",
            "Iteration 3974, loss = 2651347590.11616182\n",
            "Iteration 3975, loss = 2651347071.62328863\n",
            "Iteration 3976, loss = 2651346552.93045044\n",
            "Iteration 3977, loss = 2651346034.03670454\n",
            "Iteration 3978, loss = 2651345514.94111443\n",
            "Iteration 3979, loss = 2651344995.64276075\n",
            "Iteration 3980, loss = 2651344476.14073181\n",
            "Iteration 3981, loss = 2651343956.43413258\n",
            "Iteration 3982, loss = 2651343436.52207232\n",
            "Iteration 3983, loss = 2651342916.40367842\n",
            "Iteration 3984, loss = 2651342396.07808399\n",
            "Iteration 3985, loss = 2651341875.54443645\n",
            "Iteration 3986, loss = 2651341354.80189276\n",
            "Iteration 3987, loss = 2651340833.84961987\n",
            "Iteration 3988, loss = 2651340312.68679571\n",
            "Iteration 3989, loss = 2651339791.31260824\n",
            "Iteration 3990, loss = 2651339269.72625685\n",
            "Iteration 3991, loss = 2651338747.92694855\n",
            "Iteration 3992, loss = 2651338225.91390228\n",
            "Iteration 3993, loss = 2651337703.68634605\n",
            "Iteration 3994, loss = 2651337181.24351645\n",
            "Iteration 3995, loss = 2651336658.58466196\n",
            "Iteration 3996, loss = 2651336135.70903635\n",
            "Iteration 3997, loss = 2651335612.61590767\n",
            "Iteration 3998, loss = 2651335089.30454874\n",
            "Iteration 3999, loss = 2651334565.77424240\n",
            "Iteration 4000, loss = 2651334042.02428150\n",
            "Iteration 4001, loss = 2651333518.05396748\n",
            "Iteration 4002, loss = 2651332993.86260891\n",
            "Iteration 4003, loss = 2651332469.44952250\n",
            "Iteration 4004, loss = 2651331944.81403589\n",
            "Iteration 4005, loss = 2651331419.95548296\n",
            "Iteration 4006, loss = 2651330894.87320518\n",
            "Iteration 4007, loss = 2651330369.56655312\n",
            "Iteration 4008, loss = 2651329844.03488588\n",
            "Iteration 4009, loss = 2651329318.27756548\n",
            "Iteration 4010, loss = 2651328792.29397011\n",
            "Iteration 4011, loss = 2651328266.08347845\n",
            "Iteration 4012, loss = 2651327739.64547729\n",
            "Iteration 4013, loss = 2651327212.97936440\n",
            "Iteration 4014, loss = 2651326686.08454037\n",
            "Iteration 4015, loss = 2651326158.96041775\n",
            "Iteration 4016, loss = 2651325631.60641098\n",
            "Iteration 4017, loss = 2651325104.02194500\n",
            "Iteration 4018, loss = 2651324576.20644855\n",
            "Iteration 4019, loss = 2651324048.15936041\n",
            "Iteration 4020, loss = 2651323519.88012266\n",
            "Iteration 4021, loss = 2651322991.36818695\n",
            "Iteration 4022, loss = 2651322462.62300873\n",
            "Iteration 4023, loss = 2651321933.64405060\n",
            "Iteration 4024, loss = 2651321404.43078327\n",
            "Iteration 4025, loss = 2651320874.98268080\n",
            "Iteration 4026, loss = 2651320345.29922485\n",
            "Iteration 4027, loss = 2651319815.37990141\n",
            "Iteration 4028, loss = 2651319285.22420359\n",
            "Iteration 4029, loss = 2651318754.83163118\n",
            "Iteration 4030, loss = 2651318224.20168781\n",
            "Iteration 4031, loss = 2651317693.33388472\n",
            "Iteration 4032, loss = 2651317162.22773552\n",
            "Iteration 4033, loss = 2651316630.88276243\n",
            "Iteration 4034, loss = 2651316099.29849148\n",
            "Iteration 4035, loss = 2651315567.47445393\n",
            "Iteration 4036, loss = 2651315035.41018867\n",
            "Iteration 4037, loss = 2651314503.10523558\n",
            "Iteration 4038, loss = 2651313970.55914211\n",
            "Iteration 4039, loss = 2651313437.77145910\n",
            "Iteration 4040, loss = 2651312904.74174595\n",
            "Iteration 4041, loss = 2651312371.46956253\n",
            "Iteration 4042, loss = 2651311837.95447636\n",
            "Iteration 4043, loss = 2651311304.19605875\n",
            "Iteration 4044, loss = 2651310770.19388533\n",
            "Iteration 4045, loss = 2651310235.94753551\n",
            "Iteration 4046, loss = 2651309701.45659590\n",
            "Iteration 4047, loss = 2651309166.72065449\n",
            "Iteration 4048, loss = 2651308631.73930454\n",
            "Iteration 4049, loss = 2651308096.51214457\n",
            "Iteration 4050, loss = 2651307561.03877831\n",
            "Iteration 4051, loss = 2651307025.31880999\n",
            "Iteration 4052, loss = 2651306489.35185099\n",
            "Iteration 4053, loss = 2651305953.13751554\n",
            "Iteration 4054, loss = 2651305416.67542219\n",
            "Iteration 4055, loss = 2651304879.96519327\n",
            "Iteration 4056, loss = 2651304343.00645590\n",
            "Iteration 4057, loss = 2651303805.79883862\n",
            "Iteration 4058, loss = 2651303268.34197712\n",
            "Iteration 4059, loss = 2651302730.63550711\n",
            "Iteration 4060, loss = 2651302192.67907095\n",
            "Iteration 4061, loss = 2651301654.47231388\n",
            "Iteration 4062, loss = 2651301116.01488209\n",
            "Iteration 4063, loss = 2651300577.30643034\n",
            "Iteration 4064, loss = 2651300038.34661102\n",
            "Iteration 4065, loss = 2651299499.13508463\n",
            "Iteration 4066, loss = 2651298959.67151165\n",
            "Iteration 4067, loss = 2651298419.95555925\n",
            "Iteration 4068, loss = 2651297879.98689270\n",
            "Iteration 4069, loss = 2651297339.76518726\n",
            "Iteration 4070, loss = 2651296799.29011536\n",
            "Iteration 4071, loss = 2651296258.56135654\n",
            "Iteration 4072, loss = 2651295717.57858849\n",
            "Iteration 4073, loss = 2651295176.34149837\n",
            "Iteration 4074, loss = 2651294634.84977198\n",
            "Iteration 4075, loss = 2651294093.10309744\n",
            "Iteration 4076, loss = 2651293551.10117102\n",
            "Iteration 4077, loss = 2651293008.84368324\n",
            "Iteration 4078, loss = 2651292466.33033562\n",
            "Iteration 4079, loss = 2651291923.56082916\n",
            "Iteration 4080, loss = 2651291380.53486538\n",
            "Iteration 4081, loss = 2651290837.25215149\n",
            "Iteration 4082, loss = 2651290293.71239662\n",
            "Iteration 4083, loss = 2651289749.91531086\n",
            "Iteration 4084, loss = 2651289205.86061049\n",
            "Iteration 4085, loss = 2651288661.54800987\n",
            "Iteration 4086, loss = 2651288116.97722912\n",
            "Iteration 4087, loss = 2651287572.14798784\n",
            "Iteration 4088, loss = 2651287027.06001282\n",
            "Iteration 4089, loss = 2651286481.71302605\n",
            "Iteration 4090, loss = 2651285936.10675859\n",
            "Iteration 4091, loss = 2651285390.24094009\n",
            "Iteration 4092, loss = 2651284844.11530352\n",
            "Iteration 4093, loss = 2651284297.72958469\n",
            "Iteration 4094, loss = 2651283751.08351851\n",
            "Iteration 4095, loss = 2651283204.17684603\n",
            "Iteration 4096, loss = 2651282657.00930834\n",
            "Iteration 4097, loss = 2651282109.58064890\n",
            "Iteration 4098, loss = 2651281561.89061403\n",
            "Iteration 4099, loss = 2651281013.93894911\n",
            "Iteration 4100, loss = 2651280465.72540569\n",
            "Iteration 4101, loss = 2651279917.24973440\n",
            "Iteration 4102, loss = 2651279368.51168871\n",
            "Iteration 4103, loss = 2651278819.51102209\n",
            "Iteration 4104, loss = 2651278270.24749517\n",
            "Iteration 4105, loss = 2651277720.72086525\n",
            "Iteration 4106, loss = 2651277170.93089104\n",
            "Iteration 4107, loss = 2651276620.87733746\n",
            "Iteration 4108, loss = 2651276070.55996799\n",
            "Iteration 4109, loss = 2651275519.97854757\n",
            "Iteration 4110, loss = 2651274969.13284540\n",
            "Iteration 4111, loss = 2651274418.02263021\n",
            "Iteration 4112, loss = 2651273866.64767122\n",
            "Iteration 4113, loss = 2651273315.00774431\n",
            "Iteration 4114, loss = 2651272763.10262012\n",
            "Iteration 4115, loss = 2651272210.93207741\n",
            "Iteration 4116, loss = 2651271658.49589014\n",
            "Iteration 4117, loss = 2651271105.79383945\n",
            "Iteration 4118, loss = 2651270552.82570410\n",
            "Iteration 4119, loss = 2651269999.59126759\n",
            "Iteration 4120, loss = 2651269446.09031057\n",
            "Iteration 4121, loss = 2651268892.32261848\n",
            "Iteration 4122, loss = 2651268338.28797865\n",
            "Iteration 4123, loss = 2651267783.98617554\n",
            "Iteration 4124, loss = 2651267229.41699982\n",
            "Iteration 4125, loss = 2651266674.58023977\n",
            "Iteration 4126, loss = 2651266119.47568893\n",
            "Iteration 4127, loss = 2651265564.10313797\n",
            "Iteration 4128, loss = 2651265008.46238136\n",
            "Iteration 4129, loss = 2651264452.55321407\n",
            "Iteration 4130, loss = 2651263896.37543249\n",
            "Iteration 4131, loss = 2651263339.92883348\n",
            "Iteration 4132, loss = 2651262783.21321678\n",
            "Iteration 4133, loss = 2651262226.22838020\n",
            "Iteration 4134, loss = 2651261668.97412634\n",
            "Iteration 4135, loss = 2651261111.45025730\n",
            "Iteration 4136, loss = 2651260553.65657568\n",
            "Iteration 4137, loss = 2651259995.59288597\n",
            "Iteration 4138, loss = 2651259437.25899363\n",
            "Iteration 4139, loss = 2651258878.65470409\n",
            "Iteration 4140, loss = 2651258319.77982616\n",
            "Iteration 4141, loss = 2651257760.63416767\n",
            "Iteration 4142, loss = 2651257201.21753883\n",
            "Iteration 4143, loss = 2651256641.52974892\n",
            "Iteration 4144, loss = 2651256081.57060909\n",
            "Iteration 4145, loss = 2651255521.33993435\n",
            "Iteration 4146, loss = 2651254960.83753443\n",
            "Iteration 4147, loss = 2651254400.06322718\n",
            "Iteration 4148, loss = 2651253839.01682425\n",
            "Iteration 4149, loss = 2651253277.69814539\n",
            "Iteration 4150, loss = 2651252716.10700464\n",
            "Iteration 4151, loss = 2651252154.24322081\n",
            "Iteration 4152, loss = 2651251592.10661316\n",
            "Iteration 4153, loss = 2651251029.69700050\n",
            "Iteration 4154, loss = 2651250467.01420355\n",
            "Iteration 4155, loss = 2651249904.05804205\n",
            "Iteration 4156, loss = 2651249340.82833958\n",
            "Iteration 4157, loss = 2651248777.32491922\n",
            "Iteration 4158, loss = 2651248213.54760313\n",
            "Iteration 4159, loss = 2651247649.49621534\n",
            "Iteration 4160, loss = 2651247085.17058229\n",
            "Iteration 4161, loss = 2651246520.57052946\n",
            "Iteration 4162, loss = 2651245955.69588280\n",
            "Iteration 4163, loss = 2651245390.54646873\n",
            "Iteration 4164, loss = 2651244825.12211657\n",
            "Iteration 4165, loss = 2651244259.42265415\n",
            "Iteration 4166, loss = 2651243693.44790983\n",
            "Iteration 4167, loss = 2651243127.19771481\n",
            "Iteration 4168, loss = 2651242560.67189932\n",
            "Iteration 4169, loss = 2651241993.87029457\n",
            "Iteration 4170, loss = 2651241426.79273129\n",
            "Iteration 4171, loss = 2651240859.43904352\n",
            "Iteration 4172, loss = 2651240291.80906391\n",
            "Iteration 4173, loss = 2651239723.90262365\n",
            "Iteration 4174, loss = 2651239155.71956015\n",
            "Iteration 4175, loss = 2651238587.25970745\n",
            "Iteration 4176, loss = 2651238018.52289820\n",
            "Iteration 4177, loss = 2651237449.50897169\n",
            "Iteration 4178, loss = 2651236880.21776295\n",
            "Iteration 4179, loss = 2651236310.64910841\n",
            "Iteration 4180, loss = 2651235740.80284739\n",
            "Iteration 4181, loss = 2651235170.67881536\n",
            "Iteration 4182, loss = 2651234600.27685261\n",
            "Iteration 4183, loss = 2651234029.59679699\n",
            "Iteration 4184, loss = 2651233458.63848972\n",
            "Iteration 4185, loss = 2651232887.40176868\n",
            "Iteration 4186, loss = 2651232315.88647652\n",
            "Iteration 4187, loss = 2651231744.09245157\n",
            "Iteration 4188, loss = 2651231172.01953697\n",
            "Iteration 4189, loss = 2651230599.66757441\n",
            "Iteration 4190, loss = 2651230027.03640556\n",
            "Iteration 4191, loss = 2651229454.12587404\n",
            "Iteration 4192, loss = 2651228880.93582296\n",
            "Iteration 4193, loss = 2651228307.46609354\n",
            "Iteration 4194, loss = 2651227733.71653271\n",
            "Iteration 4195, loss = 2651227159.68698263\n",
            "Iteration 4196, loss = 2651226585.37728834\n",
            "Iteration 4197, loss = 2651226010.78729677\n",
            "Iteration 4198, loss = 2651225435.91685200\n",
            "Iteration 4199, loss = 2651224860.76580000\n",
            "Iteration 4200, loss = 2651224285.33398628\n",
            "Iteration 4201, loss = 2651223709.62125778\n",
            "Iteration 4202, loss = 2651223133.62746429\n",
            "Iteration 4203, loss = 2651222557.35244942\n",
            "Iteration 4204, loss = 2651221980.79606247\n",
            "Iteration 4205, loss = 2651221403.95814991\n",
            "Iteration 4206, loss = 2651220826.83856153\n",
            "Iteration 4207, loss = 2651220249.43714523\n",
            "Iteration 4208, loss = 2651219671.75375175\n",
            "Iteration 4209, loss = 2651219093.78822708\n",
            "Iteration 4210, loss = 2651218515.54042387\n",
            "Iteration 4211, loss = 2651217937.01018858\n",
            "Iteration 4212, loss = 2651217358.19737530\n",
            "Iteration 4213, loss = 2651216779.10183144\n",
            "Iteration 4214, loss = 2651216199.72340965\n",
            "Iteration 4215, loss = 2651215620.06195879\n",
            "Iteration 4216, loss = 2651215040.11733103\n",
            "Iteration 4217, loss = 2651214459.88937807\n",
            "Iteration 4218, loss = 2651213879.37795210\n",
            "Iteration 4219, loss = 2651213298.58290434\n",
            "Iteration 4220, loss = 2651212717.50408840\n",
            "Iteration 4221, loss = 2651212136.14135456\n",
            "Iteration 4222, loss = 2651211554.49455643\n",
            "Iteration 4223, loss = 2651210972.56354809\n",
            "Iteration 4224, loss = 2651210390.34818077\n",
            "Iteration 4225, loss = 2651209807.84831047\n",
            "Iteration 4226, loss = 2651209225.06378841\n",
            "Iteration 4227, loss = 2651208641.99446869\n",
            "Iteration 4228, loss = 2651208058.64020681\n",
            "Iteration 4229, loss = 2651207475.00085592\n",
            "Iteration 4230, loss = 2651206891.07627106\n",
            "Iteration 4231, loss = 2651206306.86630583\n",
            "Iteration 4232, loss = 2651205722.37081623\n",
            "Iteration 4233, loss = 2651205137.58965731\n",
            "Iteration 4234, loss = 2651204552.52268410\n",
            "Iteration 4235, loss = 2651203967.16974974\n",
            "Iteration 4236, loss = 2651203381.53071451\n",
            "Iteration 4237, loss = 2651202795.60543060\n",
            "Iteration 4238, loss = 2651202209.39375401\n",
            "Iteration 4239, loss = 2651201622.89554262\n",
            "Iteration 4240, loss = 2651201036.11065149\n",
            "Iteration 4241, loss = 2651200449.03893757\n",
            "Iteration 4242, loss = 2651199861.68025684\n",
            "Iteration 4243, loss = 2651199274.03446722\n",
            "Iteration 4244, loss = 2651198686.10142279\n",
            "Iteration 4245, loss = 2651198097.88098335\n",
            "Iteration 4246, loss = 2651197509.37300444\n",
            "Iteration 4247, loss = 2651196920.57734537\n",
            "Iteration 4248, loss = 2651196331.49386215\n",
            "Iteration 4249, loss = 2651195742.12241030\n",
            "Iteration 4250, loss = 2651195152.46285152\n",
            "Iteration 4251, loss = 2651194562.51504183\n",
            "Iteration 4252, loss = 2651193972.27883816\n",
            "Iteration 4253, loss = 2651193381.75409937\n",
            "Iteration 4254, loss = 2651192790.94068289\n",
            "Iteration 4255, loss = 2651192199.83844995\n",
            "Iteration 4256, loss = 2651191608.44725418\n",
            "Iteration 4257, loss = 2651191016.76695776\n",
            "Iteration 4258, loss = 2651190424.79741859\n",
            "Iteration 4259, loss = 2651189832.53849459\n",
            "Iteration 4260, loss = 2651189239.99004412\n",
            "Iteration 4261, loss = 2651188647.15192699\n",
            "Iteration 4262, loss = 2651188054.02400208\n",
            "Iteration 4263, loss = 2651187460.60612965\n",
            "Iteration 4264, loss = 2651186866.89816570\n",
            "Iteration 4265, loss = 2651186272.89997244\n",
            "Iteration 4266, loss = 2651185678.61140728\n",
            "Iteration 4267, loss = 2651185084.03233099\n",
            "Iteration 4268, loss = 2651184489.16260338\n",
            "Iteration 4269, loss = 2651183894.00208235\n",
            "Iteration 4270, loss = 2651183298.55062771\n",
            "Iteration 4271, loss = 2651182702.80810118\n",
            "Iteration 4272, loss = 2651182106.77436113\n",
            "Iteration 4273, loss = 2651181510.44926691\n",
            "Iteration 4274, loss = 2651180913.83267927\n",
            "Iteration 4275, loss = 2651180316.92445755\n",
            "Iteration 4276, loss = 2651179719.72446203\n",
            "Iteration 4277, loss = 2651179122.23255396\n",
            "Iteration 4278, loss = 2651178524.44859171\n",
            "Iteration 4279, loss = 2651177926.37243700\n",
            "Iteration 4280, loss = 2651177328.00394964\n",
            "Iteration 4281, loss = 2651176729.34298992\n",
            "Iteration 4282, loss = 2651176130.38941717\n",
            "Iteration 4283, loss = 2651175531.14309311\n",
            "Iteration 4284, loss = 2651174931.60387754\n",
            "Iteration 4285, loss = 2651174331.77163172\n",
            "Iteration 4286, loss = 2651173731.64621496\n",
            "Iteration 4287, loss = 2651173131.22748947\n",
            "Iteration 4288, loss = 2651172530.51531553\n",
            "Iteration 4289, loss = 2651171929.50955153\n",
            "Iteration 4290, loss = 2651171328.21006107\n",
            "Iteration 4291, loss = 2651170726.61670351\n",
            "Iteration 4292, loss = 2651170124.72934103\n",
            "Iteration 4293, loss = 2651169522.54783249\n",
            "Iteration 4294, loss = 2651168920.07203960\n",
            "Iteration 4295, loss = 2651168317.30182362\n",
            "Iteration 4296, loss = 2651167714.23704386\n",
            "Iteration 4297, loss = 2651167110.87756443\n",
            "Iteration 4298, loss = 2651166507.22324133\n",
            "Iteration 4299, loss = 2651165903.27394104\n",
            "Iteration 4300, loss = 2651165299.02952147\n",
            "Iteration 4301, loss = 2651164694.48984337\n",
            "Iteration 4302, loss = 2651164089.65476894\n",
            "Iteration 4303, loss = 2651163484.52415895\n",
            "Iteration 4304, loss = 2651162879.09787512\n",
            "Iteration 4305, loss = 2651162273.37577677\n",
            "Iteration 4306, loss = 2651161667.35772514\n",
            "Iteration 4307, loss = 2651161061.04358292\n",
            "Iteration 4308, loss = 2651160454.43321085\n",
            "Iteration 4309, loss = 2651159847.52646971\n",
            "Iteration 4310, loss = 2651159240.32321978\n",
            "Iteration 4311, loss = 2651158632.82332325\n",
            "Iteration 4312, loss = 2651158025.02664089\n",
            "Iteration 4313, loss = 2651157416.93303394\n",
            "Iteration 4314, loss = 2651156808.54236412\n",
            "Iteration 4315, loss = 2651156199.85449171\n",
            "Iteration 4316, loss = 2651155590.86927700\n",
            "Iteration 4317, loss = 2651154981.58658409\n",
            "Iteration 4318, loss = 2651154372.00627136\n",
            "Iteration 4319, loss = 2651153762.12820148\n",
            "Iteration 4320, loss = 2651153151.95223427\n",
            "Iteration 4321, loss = 2651152541.47823191\n",
            "Iteration 4322, loss = 2651151930.70605564\n",
            "Iteration 4323, loss = 2651151319.63556576\n",
            "Iteration 4324, loss = 2651150708.26662445\n",
            "Iteration 4325, loss = 2651150096.59909201\n",
            "Iteration 4326, loss = 2651149484.63282967\n",
            "Iteration 4327, loss = 2651148872.36769962\n",
            "Iteration 4328, loss = 2651148259.80356121\n",
            "Iteration 4329, loss = 2651147646.94027567\n",
            "Iteration 4330, loss = 2651147033.77770472\n",
            "Iteration 4331, loss = 2651146420.31571102\n",
            "Iteration 4332, loss = 2651145806.55415201\n",
            "Iteration 4333, loss = 2651145192.49289179\n",
            "Iteration 4334, loss = 2651144578.13179016\n",
            "Iteration 4335, loss = 2651143963.47070885\n",
            "Iteration 4336, loss = 2651143348.50950766\n",
            "Iteration 4337, loss = 2651142733.24804735\n",
            "Iteration 4338, loss = 2651142117.68619156\n",
            "Iteration 4339, loss = 2651141501.82379818\n",
            "Iteration 4340, loss = 2651140885.66072845\n",
            "Iteration 4341, loss = 2651140269.19684601\n",
            "Iteration 4342, loss = 2651139652.43200874\n",
            "Iteration 4343, loss = 2651139035.36607885\n",
            "Iteration 4344, loss = 2651138417.99891663\n",
            "Iteration 4345, loss = 2651137800.33038330\n",
            "Iteration 4346, loss = 2651137182.36033916\n",
            "Iteration 4347, loss = 2651136564.08864546\n",
            "Iteration 4348, loss = 2651135945.51516294\n",
            "Iteration 4349, loss = 2651135326.63975143\n",
            "Iteration 4350, loss = 2651134707.46227312\n",
            "Iteration 4351, loss = 2651134087.98258638\n",
            "Iteration 4352, loss = 2651133468.20055485\n",
            "Iteration 4353, loss = 2651132848.11603737\n",
            "Iteration 4354, loss = 2651132227.72889423\n",
            "Iteration 4355, loss = 2651131607.03898621\n",
            "Iteration 4356, loss = 2651130986.04617453\n",
            "Iteration 4357, loss = 2651130364.75031900\n",
            "Iteration 4358, loss = 2651129743.15127993\n",
            "Iteration 4359, loss = 2651129121.24891806\n",
            "Iteration 4360, loss = 2651128499.04309416\n",
            "Iteration 4361, loss = 2651127876.53366852\n",
            "Iteration 4362, loss = 2651127253.72049999\n",
            "Iteration 4363, loss = 2651126630.60345173\n",
            "Iteration 4364, loss = 2651126007.18238068\n",
            "Iteration 4365, loss = 2651125383.45714998\n",
            "Iteration 4366, loss = 2651124759.42761707\n",
            "Iteration 4367, loss = 2651124135.09364367\n",
            "Iteration 4368, loss = 2651123510.45509100\n",
            "Iteration 4369, loss = 2651122885.51181698\n",
            "Iteration 4370, loss = 2651122260.26368237\n",
            "Iteration 4371, loss = 2651121634.71054792\n",
            "Iteration 4372, loss = 2651121008.85227251\n",
            "Iteration 4373, loss = 2651120382.68871784\n",
            "Iteration 4374, loss = 2651119756.21974087\n",
            "Iteration 4375, loss = 2651119129.44520426\n",
            "Iteration 4376, loss = 2651118502.36496639\n",
            "Iteration 4377, loss = 2651117874.97888756\n",
            "Iteration 4378, loss = 2651117247.28682709\n",
            "Iteration 4379, loss = 2651116619.28864431\n",
            "Iteration 4380, loss = 2651115990.98420048\n",
            "Iteration 4381, loss = 2651115362.37335396\n",
            "Iteration 4382, loss = 2651114733.45596361\n",
            "Iteration 4383, loss = 2651114104.23189020\n",
            "Iteration 4384, loss = 2651113474.70099401\n",
            "Iteration 4385, loss = 2651112844.86313248\n",
            "Iteration 4386, loss = 2651112214.71816683\n",
            "Iteration 4387, loss = 2651111584.26595497\n",
            "Iteration 4388, loss = 2651110953.50635719\n",
            "Iteration 4389, loss = 2651110322.43923235\n",
            "Iteration 4390, loss = 2651109691.06443930\n",
            "Iteration 4391, loss = 2651109059.38183784\n",
            "Iteration 4392, loss = 2651108427.39128685\n",
            "Iteration 4393, loss = 2651107795.09264565\n",
            "Iteration 4394, loss = 2651107162.48577309\n",
            "Iteration 4395, loss = 2651106529.57052755\n",
            "Iteration 4396, loss = 2651105896.34677029\n",
            "Iteration 4397, loss = 2651105262.81435728\n",
            "Iteration 4398, loss = 2651104628.97314978\n",
            "Iteration 4399, loss = 2651103994.82300472\n",
            "Iteration 4400, loss = 2651103360.36378241\n",
            "Iteration 4401, loss = 2651102725.59534025\n",
            "Iteration 4402, loss = 2651102090.51753902\n",
            "Iteration 4403, loss = 2651101455.13023472\n",
            "Iteration 4404, loss = 2651100819.43328714\n",
            "Iteration 4405, loss = 2651100183.42655468\n",
            "Iteration 4406, loss = 2651099547.10989714\n",
            "Iteration 4407, loss = 2651098910.48317051\n",
            "Iteration 4408, loss = 2651098273.54623556\n",
            "Iteration 4409, loss = 2651097636.29894924\n",
            "Iteration 4410, loss = 2651096998.74116993\n",
            "Iteration 4411, loss = 2651096360.87275648\n",
            "Iteration 4412, loss = 2651095722.69356680\n",
            "Iteration 4413, loss = 2651095084.20345974\n",
            "Iteration 4414, loss = 2651094445.40229177\n",
            "Iteration 4415, loss = 2651093806.28992224\n",
            "Iteration 4416, loss = 2651093166.86620903\n",
            "Iteration 4417, loss = 2651092527.13100910\n",
            "Iteration 4418, loss = 2651091887.08418131\n",
            "Iteration 4419, loss = 2651091246.72558403\n",
            "Iteration 4420, loss = 2651090606.05507469\n",
            "Iteration 4421, loss = 2651089965.07250929\n",
            "Iteration 4422, loss = 2651089323.77774715\n",
            "Iteration 4423, loss = 2651088682.17064667\n",
            "Iteration 4424, loss = 2651088040.25106478\n",
            "Iteration 4425, loss = 2651087398.01885653\n",
            "Iteration 4426, loss = 2651086755.47388315\n",
            "Iteration 4427, loss = 2651086112.61600018\n",
            "Iteration 4428, loss = 2651085469.44506598\n",
            "Iteration 4429, loss = 2651084825.96093702\n",
            "Iteration 4430, loss = 2651084182.16346979\n",
            "Iteration 4431, loss = 2651083538.05252409\n",
            "Iteration 4432, loss = 2651082893.62795496\n",
            "Iteration 4433, loss = 2651082248.88961983\n",
            "Iteration 4434, loss = 2651081603.83737659\n",
            "Iteration 4435, loss = 2651080958.47108173\n",
            "Iteration 4436, loss = 2651080312.79059172\n",
            "Iteration 4437, loss = 2651079666.79576397\n",
            "Iteration 4438, loss = 2651079020.48645496\n",
            "Iteration 4439, loss = 2651078373.86252260\n",
            "Iteration 4440, loss = 2651077726.92382288\n",
            "Iteration 4441, loss = 2651077079.67021179\n",
            "Iteration 4442, loss = 2651076432.10154724\n",
            "Iteration 4443, loss = 2651075784.21768522\n",
            "Iteration 4444, loss = 2651075136.01848316\n",
            "Iteration 4445, loss = 2651074487.50379515\n",
            "Iteration 4446, loss = 2651073838.67348003\n",
            "Iteration 4447, loss = 2651073189.52739191\n",
            "Iteration 4448, loss = 2651072540.06539106\n",
            "Iteration 4449, loss = 2651071890.28732824\n",
            "Iteration 4450, loss = 2651071240.19306469\n",
            "Iteration 4451, loss = 2651070589.78245306\n",
            "Iteration 4452, loss = 2651069939.05535173\n",
            "Iteration 4453, loss = 2651069288.01161480\n",
            "Iteration 4454, loss = 2651068636.65110016\n",
            "Iteration 4455, loss = 2651067984.97366238\n",
            "Iteration 4456, loss = 2651067332.97915745\n",
            "Iteration 4457, loss = 2651066680.66744184\n",
            "Iteration 4458, loss = 2651066028.03836966\n",
            "Iteration 4459, loss = 2651065375.09179926\n",
            "Iteration 4460, loss = 2651064721.82758427\n",
            "Iteration 4461, loss = 2651064068.24558067\n",
            "Iteration 4462, loss = 2651063414.34564400\n",
            "Iteration 4463, loss = 2651062760.12762976\n",
            "Iteration 4464, loss = 2651062105.59139490\n",
            "Iteration 4465, loss = 2651061450.73679161\n",
            "Iteration 4466, loss = 2651060795.56367826\n",
            "Iteration 4467, loss = 2651060140.07190847\n",
            "Iteration 4468, loss = 2651059484.26133680\n",
            "Iteration 4469, loss = 2651058828.13181973\n",
            "Iteration 4470, loss = 2651058171.68321228\n",
            "Iteration 4471, loss = 2651057514.91536808\n",
            "Iteration 4472, loss = 2651056857.82814407\n",
            "Iteration 4473, loss = 2651056200.42139387\n",
            "Iteration 4474, loss = 2651055542.69497252\n",
            "Iteration 4475, loss = 2651054884.64873314\n",
            "Iteration 4476, loss = 2651054226.28253460\n",
            "Iteration 4477, loss = 2651053567.59622717\n",
            "Iteration 4478, loss = 2651052908.58966827\n",
            "Iteration 4479, loss = 2651052249.26271200\n",
            "Iteration 4480, loss = 2651051589.61521196\n",
            "Iteration 4481, loss = 2651050929.64702225\n",
            "Iteration 4482, loss = 2651050269.35799837\n",
            "Iteration 4483, loss = 2651049608.74799490\n",
            "Iteration 4484, loss = 2651048947.81686449\n",
            "Iteration 4485, loss = 2651048286.56446314\n",
            "Iteration 4486, loss = 2651047624.99064350\n",
            "Iteration 4487, loss = 2651046963.09526014\n",
            "Iteration 4488, loss = 2651046300.87816811\n",
            "Iteration 4489, loss = 2651045638.33921957\n",
            "Iteration 4490, loss = 2651044975.47826862\n",
            "Iteration 4491, loss = 2651044312.29517126\n",
            "Iteration 4492, loss = 2651043648.78977919\n",
            "Iteration 4493, loss = 2651042984.96194601\n",
            "Iteration 4494, loss = 2651042320.81152630\n",
            "Iteration 4495, loss = 2651041656.33837366\n",
            "Iteration 4496, loss = 2651040991.54234171\n",
            "Iteration 4497, loss = 2651040326.42328358\n",
            "Iteration 4498, loss = 2651039660.98105192\n",
            "Iteration 4499, loss = 2651038995.21550131\n",
            "Iteration 4500, loss = 2651038329.12648582\n",
            "Iteration 4501, loss = 2651037662.71385670\n",
            "Iteration 4502, loss = 2651036995.97746754\n",
            "Iteration 4503, loss = 2651036328.91717196\n",
            "Iteration 4504, loss = 2651035661.53282261\n",
            "Iteration 4505, loss = 2651034993.82427359\n",
            "Iteration 4506, loss = 2651034325.79137564\n",
            "Iteration 4507, loss = 2651033657.43398523\n",
            "Iteration 4508, loss = 2651032988.75195122\n",
            "Iteration 4509, loss = 2651032319.74512911\n",
            "Iteration 4510, loss = 2651031650.41337013\n",
            "Iteration 4511, loss = 2651030980.75652695\n",
            "Iteration 4512, loss = 2651030310.77445364\n",
            "Iteration 4513, loss = 2651029640.46700191\n",
            "Iteration 4514, loss = 2651028969.83402300\n",
            "Iteration 4515, loss = 2651028298.87537146\n",
            "Iteration 4516, loss = 2651027627.59089804\n",
            "Iteration 4517, loss = 2651026955.98045588\n",
            "Iteration 4518, loss = 2651026284.04389668\n",
            "Iteration 4519, loss = 2651025611.78107262\n",
            "Iteration 4520, loss = 2651024939.19183540\n",
            "Iteration 4521, loss = 2651024266.27603722\n",
            "Iteration 4522, loss = 2651023593.03353214\n",
            "Iteration 4523, loss = 2651022919.46416903\n",
            "Iteration 4524, loss = 2651022245.56780148\n",
            "Iteration 4525, loss = 2651021571.34428120\n",
            "Iteration 4526, loss = 2651020896.79345942\n",
            "Iteration 4527, loss = 2651020221.91518736\n",
            "Iteration 4528, loss = 2651019546.70931816\n",
            "Iteration 4529, loss = 2651018871.17570114\n",
            "Iteration 4530, loss = 2651018195.31418991\n",
            "Iteration 4531, loss = 2651017519.12463570\n",
            "Iteration 4532, loss = 2651016842.60688877\n",
            "Iteration 4533, loss = 2651016165.76079988\n",
            "Iteration 4534, loss = 2651015488.58622265\n",
            "Iteration 4535, loss = 2651014811.08300638\n",
            "Iteration 4536, loss = 2651014133.25100327\n",
            "Iteration 4537, loss = 2651013455.09006262\n",
            "Iteration 4538, loss = 2651012776.60003805\n",
            "Iteration 4539, loss = 2651012097.78077841\n",
            "Iteration 4540, loss = 2651011418.63213587\n",
            "Iteration 4541, loss = 2651010739.15396023\n",
            "Iteration 4542, loss = 2651010059.34610224\n",
            "Iteration 4543, loss = 2651009379.20841312\n",
            "Iteration 4544, loss = 2651008698.74074411\n",
            "Iteration 4545, loss = 2651008017.94294500\n",
            "Iteration 4546, loss = 2651007336.81486607\n",
            "Iteration 4547, loss = 2651006655.35635710\n",
            "Iteration 4548, loss = 2651005973.56727028\n",
            "Iteration 4549, loss = 2651005291.44745541\n",
            "Iteration 4550, loss = 2651004608.99676085\n",
            "Iteration 4551, loss = 2651003926.21504021\n",
            "Iteration 4552, loss = 2651003243.10214043\n",
            "Iteration 4553, loss = 2651002559.65791368\n",
            "Iteration 4554, loss = 2651001875.88220978\n",
            "Iteration 4555, loss = 2651001191.77487755\n",
            "Iteration 4556, loss = 2651000507.33576679\n",
            "Iteration 4557, loss = 2650999822.56472826\n",
            "Iteration 4558, loss = 2650999137.46161222\n",
            "Iteration 4559, loss = 2650998452.02626657\n",
            "Iteration 4560, loss = 2650997766.25854206\n",
            "Iteration 4561, loss = 2650997080.15828896\n",
            "Iteration 4562, loss = 2650996393.72535515\n",
            "Iteration 4563, loss = 2650995706.95959187\n",
            "Iteration 4564, loss = 2650995019.86084652\n",
            "Iteration 4565, loss = 2650994332.42896986\n",
            "Iteration 4566, loss = 2650993644.66381121\n",
            "Iteration 4567, loss = 2650992956.56521797\n",
            "Iteration 4568, loss = 2650992268.13304234\n",
            "Iteration 4569, loss = 2650991579.36713076\n",
            "Iteration 4570, loss = 2650990890.26733303\n",
            "Iteration 4571, loss = 2650990200.83349943\n",
            "Iteration 4572, loss = 2650989511.06547594\n",
            "Iteration 4573, loss = 2650988820.96311331\n",
            "Iteration 4574, loss = 2650988130.52626181\n",
            "Iteration 4575, loss = 2650987439.75476694\n",
            "Iteration 4576, loss = 2650986748.64848042\n",
            "Iteration 4577, loss = 2650986057.20724678\n",
            "Iteration 4578, loss = 2650985365.43091869\n",
            "Iteration 4579, loss = 2650984673.31934261\n",
            "Iteration 4580, loss = 2650983980.87236786\n",
            "Iteration 4581, loss = 2650983288.08984089\n",
            "Iteration 4582, loss = 2650982594.97161245\n",
            "Iteration 4583, loss = 2650981901.51752853\n",
            "Iteration 4584, loss = 2650981207.72743940\n",
            "Iteration 4585, loss = 2650980513.60119104\n",
            "Iteration 4586, loss = 2650979819.13863230\n",
            "Iteration 4587, loss = 2650979124.33961153\n",
            "Iteration 4588, loss = 2650978429.20397615\n",
            "Iteration 4589, loss = 2650977733.73157406\n",
            "Iteration 4590, loss = 2650977037.92225361\n",
            "Iteration 4591, loss = 2650976341.77586174\n",
            "Iteration 4592, loss = 2650975645.29224634\n",
            "Iteration 4593, loss = 2650974948.47125530\n",
            "Iteration 4594, loss = 2650974251.31273556\n",
            "Iteration 4595, loss = 2650973553.81653500\n",
            "Iteration 4596, loss = 2650972855.98250055\n",
            "Iteration 4597, loss = 2650972157.81048012\n",
            "Iteration 4598, loss = 2650971459.30032015\n",
            "Iteration 4599, loss = 2650970760.45186853\n",
            "Iteration 4600, loss = 2650970061.26497221\n",
            "Iteration 4601, loss = 2650969361.73947811\n",
            "Iteration 4602, loss = 2650968661.87523365\n",
            "Iteration 4603, loss = 2650967961.67208576\n",
            "Iteration 4604, loss = 2650967261.12988091\n",
            "Iteration 4605, loss = 2650966560.24846554\n",
            "Iteration 4606, loss = 2650965859.02768755\n",
            "Iteration 4607, loss = 2650965157.46739244\n",
            "Iteration 4608, loss = 2650964455.56742811\n",
            "Iteration 4609, loss = 2650963753.32764006\n",
            "Iteration 4610, loss = 2650963050.74787426\n",
            "Iteration 4611, loss = 2650962347.82797813\n",
            "Iteration 4612, loss = 2650961644.56779957\n",
            "Iteration 4613, loss = 2650960940.96718168\n",
            "Iteration 4614, loss = 2650960237.02597332\n",
            "Iteration 4615, loss = 2650959532.74401760\n",
            "Iteration 4616, loss = 2650958828.12116575\n",
            "Iteration 4617, loss = 2650958123.15725803\n",
            "Iteration 4618, loss = 2650957417.85214472\n",
            "Iteration 4619, loss = 2650956712.20566797\n",
            "Iteration 4620, loss = 2650956006.21767855\n",
            "Iteration 4621, loss = 2650955299.88801813\n",
            "Iteration 4622, loss = 2650954593.21653318\n",
            "Iteration 4623, loss = 2650953886.20307112\n",
            "Iteration 4624, loss = 2650953178.84747553\n",
            "Iteration 4625, loss = 2650952471.14959383\n",
            "Iteration 4626, loss = 2650951763.10927057\n",
            "Iteration 4627, loss = 2650951054.72635031\n",
            "Iteration 4628, loss = 2650950346.00067949\n",
            "Iteration 4629, loss = 2650949636.93210268\n",
            "Iteration 4630, loss = 2650948927.52046680\n",
            "Iteration 4631, loss = 2650948217.76561546\n",
            "Iteration 4632, loss = 2650947507.66739321\n",
            "Iteration 4633, loss = 2650946797.22564602\n",
            "Iteration 4634, loss = 2650946086.44021893\n",
            "Iteration 4635, loss = 2650945375.31095743\n",
            "Iteration 4636, loss = 2650944663.83770418\n",
            "Iteration 4637, loss = 2650943952.02030754\n",
            "Iteration 4638, loss = 2650943239.85860825\n",
            "Iteration 4639, loss = 2650942527.35245323\n",
            "Iteration 4640, loss = 2650941814.50168610\n",
            "Iteration 4641, loss = 2650941101.30615282\n",
            "Iteration 4642, loss = 2650940387.76569653\n",
            "Iteration 4643, loss = 2650939673.88016272\n",
            "Iteration 4644, loss = 2650938959.64939356\n",
            "Iteration 4645, loss = 2650938245.07323599\n",
            "Iteration 4646, loss = 2650937530.15153217\n",
            "Iteration 4647, loss = 2650936814.88412762\n",
            "Iteration 4648, loss = 2650936099.27086496\n",
            "Iteration 4649, loss = 2650935383.31158972\n",
            "Iteration 4650, loss = 2650934667.00614548\n",
            "Iteration 4651, loss = 2650933950.35437489\n",
            "Iteration 4652, loss = 2650933233.35612249\n",
            "Iteration 4653, loss = 2650932516.01123381\n",
            "Iteration 4654, loss = 2650931798.31955004\n",
            "Iteration 4655, loss = 2650931080.28091574\n",
            "Iteration 4656, loss = 2650930361.89517403\n",
            "Iteration 4657, loss = 2650929643.16216946\n",
            "Iteration 4658, loss = 2650928924.08174467\n",
            "Iteration 4659, loss = 2650928204.65374327\n",
            "Iteration 4660, loss = 2650927484.87800789\n",
            "Iteration 4661, loss = 2650926764.75438309\n",
            "Iteration 4662, loss = 2650926044.28271055\n",
            "Iteration 4663, loss = 2650925323.46283436\n",
            "Iteration 4664, loss = 2650924602.29459763\n",
            "Iteration 4665, loss = 2650923880.77784204\n",
            "Iteration 4666, loss = 2650923158.91241312\n",
            "Iteration 4667, loss = 2650922436.69815016\n",
            "Iteration 4668, loss = 2650921714.13489962\n",
            "Iteration 4669, loss = 2650920991.22250032\n",
            "Iteration 4670, loss = 2650920267.96079779\n",
            "Iteration 4671, loss = 2650919544.34963512\n",
            "Iteration 4672, loss = 2650918820.38885307\n",
            "Iteration 4673, loss = 2650918096.07829380\n",
            "Iteration 4674, loss = 2650917371.41780090\n",
            "Iteration 4675, loss = 2650916646.40721607\n",
            "Iteration 4676, loss = 2650915921.04638243\n",
            "Iteration 4677, loss = 2650915195.33514118\n",
            "Iteration 4678, loss = 2650914469.27333355\n",
            "Iteration 4679, loss = 2650913742.86080408\n",
            "Iteration 4680, loss = 2650913016.09739494\n",
            "Iteration 4681, loss = 2650912288.98294497\n",
            "Iteration 4682, loss = 2650911561.51729774\n",
            "Iteration 4683, loss = 2650910833.70029497\n",
            "Iteration 4684, loss = 2650910105.53177977\n",
            "Iteration 4685, loss = 2650909377.01159096\n",
            "Iteration 4686, loss = 2650908648.13957405\n",
            "Iteration 4687, loss = 2650907918.91556597\n",
            "Iteration 4688, loss = 2650907189.33941126\n",
            "Iteration 4689, loss = 2650906459.41095114\n",
            "Iteration 4690, loss = 2650905729.13002634\n",
            "Iteration 4691, loss = 2650904998.49647665\n",
            "Iteration 4692, loss = 2650904267.51014709\n",
            "Iteration 4693, loss = 2650903536.17087650\n",
            "Iteration 4694, loss = 2650902804.47850418\n",
            "Iteration 4695, loss = 2650902072.43287516\n",
            "Iteration 4696, loss = 2650901340.03382635\n",
            "Iteration 4697, loss = 2650900607.28120184\n",
            "Iteration 4698, loss = 2650899874.17484140\n",
            "Iteration 4699, loss = 2650899140.71458530\n",
            "Iteration 4700, loss = 2650898406.90027428\n",
            "Iteration 4701, loss = 2650897672.73175049\n",
            "Iteration 4702, loss = 2650896938.20885086\n",
            "Iteration 4703, loss = 2650896203.33142138\n",
            "Iteration 4704, loss = 2650895468.09929705\n",
            "Iteration 4705, loss = 2650894732.51232147\n",
            "Iteration 4706, loss = 2650893996.57033396\n",
            "Iteration 4707, loss = 2650893260.27317524\n",
            "Iteration 4708, loss = 2650892523.62068462\n",
            "Iteration 4709, loss = 2650891786.61270332\n",
            "Iteration 4710, loss = 2650891049.24907112\n",
            "Iteration 4711, loss = 2650890311.52962685\n",
            "Iteration 4712, loss = 2650889573.45421171\n",
            "Iteration 4713, loss = 2650888835.02266550\n",
            "Iteration 4714, loss = 2650888096.23482704\n",
            "Iteration 4715, loss = 2650887357.09053659\n",
            "Iteration 4716, loss = 2650886617.58963537\n",
            "Iteration 4717, loss = 2650885877.73195887\n",
            "Iteration 4718, loss = 2650885137.51735115\n",
            "Iteration 4719, loss = 2650884396.94565010\n",
            "Iteration 4720, loss = 2650883656.01669312\n",
            "Iteration 4721, loss = 2650882914.73032236\n",
            "Iteration 4722, loss = 2650882173.08637524\n",
            "Iteration 4723, loss = 2650881431.08469200\n",
            "Iteration 4724, loss = 2650880688.72511053\n",
            "Iteration 4725, loss = 2650879946.00747108\n",
            "Iteration 4726, loss = 2650879202.93161392\n",
            "Iteration 4727, loss = 2650878459.49737501\n",
            "Iteration 4728, loss = 2650877715.70459461\n",
            "Iteration 4729, loss = 2650876971.55311203\n",
            "Iteration 4730, loss = 2650876227.04276514\n",
            "Iteration 4731, loss = 2650875482.17339277\n",
            "Iteration 4732, loss = 2650874736.94483328\n",
            "Iteration 4733, loss = 2650873991.35692692\n",
            "Iteration 4734, loss = 2650873245.40951014\n",
            "Iteration 4735, loss = 2650872499.10242176\n",
            "Iteration 4736, loss = 2650871752.43550110\n",
            "Iteration 4737, loss = 2650871005.40858507\n",
            "Iteration 4738, loss = 2650870258.02151251\n",
            "Iteration 4739, loss = 2650869510.27412224\n",
            "Iteration 4740, loss = 2650868762.16625214\n",
            "Iteration 4741, loss = 2650868013.69773960\n",
            "Iteration 4742, loss = 2650867264.86842251\n",
            "Iteration 4743, loss = 2650866515.67813873\n",
            "Iteration 4744, loss = 2650865766.12672663\n",
            "Iteration 4745, loss = 2650865016.21402407\n",
            "Iteration 4746, loss = 2650864265.93986845\n",
            "Iteration 4747, loss = 2650863515.30409622\n",
            "Iteration 4748, loss = 2650862764.30654621\n",
            "Iteration 4749, loss = 2650862012.94705725\n",
            "Iteration 4750, loss = 2650861261.22546434\n",
            "Iteration 4751, loss = 2650860509.14160490\n",
            "Iteration 4752, loss = 2650859756.69531822\n",
            "Iteration 4753, loss = 2650859003.88643932\n",
            "Iteration 4754, loss = 2650858250.71480703\n",
            "Iteration 4755, loss = 2650857497.18025827\n",
            "Iteration 4756, loss = 2650856743.28262901\n",
            "Iteration 4757, loss = 2650855989.02175617\n",
            "Iteration 4758, loss = 2650855234.39747763\n",
            "Iteration 4759, loss = 2650854479.40962982\n",
            "Iteration 4760, loss = 2650853724.05804968\n",
            "Iteration 4761, loss = 2650852968.34257364\n",
            "Iteration 4762, loss = 2650852212.26303864\n",
            "Iteration 4763, loss = 2650851455.81928015\n",
            "Iteration 4764, loss = 2650850699.01113558\n",
            "Iteration 4765, loss = 2650849941.83844137\n",
            "Iteration 4766, loss = 2650849184.30103445\n",
            "Iteration 4767, loss = 2650848426.39874983\n",
            "Iteration 4768, loss = 2650847668.13142395\n",
            "Iteration 4769, loss = 2650846909.49889469\n",
            "Iteration 4770, loss = 2650846150.50099564\n",
            "Iteration 4771, loss = 2650845391.13756418\n",
            "Iteration 4772, loss = 2650844631.40843534\n",
            "Iteration 4773, loss = 2650843871.31344652\n",
            "Iteration 4774, loss = 2650843110.85243320\n",
            "Iteration 4775, loss = 2650842350.02522993\n",
            "Iteration 4776, loss = 2650841588.83167315\n",
            "Iteration 4777, loss = 2650840827.27159882\n",
            "Iteration 4778, loss = 2650840065.34484291\n",
            "Iteration 4779, loss = 2650839303.05123854\n",
            "Iteration 4780, loss = 2650838540.39062452\n",
            "Iteration 4781, loss = 2650837777.36283398\n",
            "Iteration 4782, loss = 2650837013.96770191\n",
            "Iteration 4783, loss = 2650836250.20506525\n",
            "Iteration 4784, loss = 2650835486.07475758\n",
            "Iteration 4785, loss = 2650834721.57661438\n",
            "Iteration 4786, loss = 2650833956.71047068\n",
            "Iteration 4787, loss = 2650833191.47616291\n",
            "Iteration 4788, loss = 2650832425.87352419\n",
            "Iteration 4789, loss = 2650831659.90238905\n",
            "Iteration 4790, loss = 2650830893.56259489\n",
            "Iteration 4791, loss = 2650830126.85397387\n",
            "Iteration 4792, loss = 2650829359.77636099\n",
            "Iteration 4793, loss = 2650828592.32959127\n",
            "Iteration 4794, loss = 2650827824.51349878\n",
            "Iteration 4795, loss = 2650827056.32791805\n",
            "Iteration 4796, loss = 2650826287.77268457\n",
            "Iteration 4797, loss = 2650825518.84763145\n",
            "Iteration 4798, loss = 2650824749.55259275\n",
            "Iteration 4799, loss = 2650823979.88740349\n",
            "Iteration 4800, loss = 2650823209.85189724\n",
            "Iteration 4801, loss = 2650822439.44590807\n",
            "Iteration 4802, loss = 2650821668.66926908\n",
            "Iteration 4803, loss = 2650820897.52181673\n",
            "Iteration 4804, loss = 2650820126.00338125\n",
            "Iteration 4805, loss = 2650819354.11379862\n",
            "Iteration 4806, loss = 2650818581.85290384\n",
            "Iteration 4807, loss = 2650817809.22052765\n",
            "Iteration 4808, loss = 2650817036.21650457\n",
            "Iteration 4809, loss = 2650816262.84066916\n",
            "Iteration 4810, loss = 2650815489.09285355\n",
            "Iteration 4811, loss = 2650814714.97289085\n",
            "Iteration 4812, loss = 2650813940.48061562\n",
            "Iteration 4813, loss = 2650813165.61586142\n",
            "Iteration 4814, loss = 2650812390.37845898\n",
            "Iteration 4815, loss = 2650811614.76824379\n",
            "Iteration 4816, loss = 2650810838.78504705\n",
            "Iteration 4817, loss = 2650810062.42870426\n",
            "Iteration 4818, loss = 2650809285.69904423\n",
            "Iteration 4819, loss = 2650808508.59590387\n",
            "Iteration 4820, loss = 2650807731.11911440\n",
            "Iteration 4821, loss = 2650806953.26850748\n",
            "Iteration 4822, loss = 2650806175.04391718\n",
            "Iteration 4823, loss = 2650805396.44517517\n",
            "Iteration 4824, loss = 2650804617.47211361\n",
            "Iteration 4825, loss = 2650803838.12456656\n",
            "Iteration 4826, loss = 2650803058.40236378\n",
            "Iteration 4827, loss = 2650802278.30534077\n",
            "Iteration 4828, loss = 2650801497.83332729\n",
            "Iteration 4829, loss = 2650800716.98615551\n",
            "Iteration 4830, loss = 2650799935.76365900\n",
            "Iteration 4831, loss = 2650799154.16566849\n",
            "Iteration 4832, loss = 2650798372.19201660\n",
            "Iteration 4833, loss = 2650797589.84253502\n",
            "Iteration 4834, loss = 2650796807.11705542\n",
            "Iteration 4835, loss = 2650796024.01540852\n",
            "Iteration 4836, loss = 2650795240.53742886\n",
            "Iteration 4837, loss = 2650794456.68294621\n",
            "Iteration 4838, loss = 2650793672.45179081\n",
            "Iteration 4839, loss = 2650792887.84379578\n",
            "Iteration 4840, loss = 2650792102.85879183\n",
            "Iteration 4841, loss = 2650791317.49661207\n",
            "Iteration 4842, loss = 2650790531.75708437\n",
            "Iteration 4843, loss = 2650789745.64004326\n",
            "Iteration 4844, loss = 2650788959.14531803\n",
            "Iteration 4845, loss = 2650788172.27273989\n",
            "Iteration 4846, loss = 2650787385.02213955\n",
            "Iteration 4847, loss = 2650786597.39335012\n",
            "Iteration 4848, loss = 2650785809.38619995\n",
            "Iteration 4849, loss = 2650785021.00051928\n",
            "Iteration 4850, loss = 2650784232.23614216\n",
            "Iteration 4851, loss = 2650783443.09289742\n",
            "Iteration 4852, loss = 2650782653.57061481\n",
            "Iteration 4853, loss = 2650781863.66912460\n",
            "Iteration 4854, loss = 2650781073.38825893\n",
            "Iteration 4855, loss = 2650780282.72784758\n",
            "Iteration 4856, loss = 2650779491.68772173\n",
            "Iteration 4857, loss = 2650778700.26770878\n",
            "Iteration 4858, loss = 2650777908.46764135\n",
            "Iteration 4859, loss = 2650777116.28734922\n",
            "Iteration 4860, loss = 2650776323.72666168\n",
            "Iteration 4861, loss = 2650775530.78540850\n",
            "Iteration 4862, loss = 2650774737.46342182\n",
            "Iteration 4863, loss = 2650773943.76052809\n",
            "Iteration 4864, loss = 2650773149.67655993\n",
            "Iteration 4865, loss = 2650772355.21134472\n",
            "Iteration 4866, loss = 2650771560.36471558\n",
            "Iteration 4867, loss = 2650770765.13649702\n",
            "Iteration 4868, loss = 2650769969.52652311\n",
            "Iteration 4869, loss = 2650769173.53462076\n",
            "Iteration 4870, loss = 2650768377.16062021\n",
            "Iteration 4871, loss = 2650767580.40435028\n",
            "Iteration 4872, loss = 2650766783.26564026\n",
            "Iteration 4873, loss = 2650765985.74432087\n",
            "Iteration 4874, loss = 2650765187.84021807\n",
            "Iteration 4875, loss = 2650764389.55316353\n",
            "Iteration 4876, loss = 2650763590.88298512\n",
            "Iteration 4877, loss = 2650762791.82951117\n",
            "Iteration 4878, loss = 2650761992.39257240\n",
            "Iteration 4879, loss = 2650761192.57199621\n",
            "Iteration 4880, loss = 2650760392.36761045\n",
            "Iteration 4881, loss = 2650759591.77924538\n",
            "Iteration 4882, loss = 2650758790.80672789\n",
            "Iteration 4883, loss = 2650757989.44988823\n",
            "Iteration 4884, loss = 2650757187.70855379\n",
            "Iteration 4885, loss = 2650756385.58255291\n",
            "Iteration 4886, loss = 2650755583.07171345\n",
            "Iteration 4887, loss = 2650754780.17586470\n",
            "Iteration 4888, loss = 2650753976.89483452\n",
            "Iteration 4889, loss = 2650753173.22844934\n",
            "Iteration 4890, loss = 2650752369.17653942\n",
            "Iteration 4891, loss = 2650751564.73893213\n",
            "Iteration 4892, loss = 2650750759.91545391\n",
            "Iteration 4893, loss = 2650749954.70593452\n",
            "Iteration 4894, loss = 2650749149.11019993\n",
            "Iteration 4895, loss = 2650748343.12807894\n",
            "Iteration 4896, loss = 2650747536.75939846\n",
            "Iteration 4897, loss = 2650746730.00398588\n",
            "Iteration 4898, loss = 2650745922.86166811\n",
            "Iteration 4899, loss = 2650745115.33227491\n",
            "Iteration 4900, loss = 2650744307.41563225\n",
            "Iteration 4901, loss = 2650743499.11156702\n",
            "Iteration 4902, loss = 2650742690.41990566\n",
            "Iteration 4903, loss = 2650741881.34047604\n",
            "Iteration 4904, loss = 2650741071.87310600\n",
            "Iteration 4905, loss = 2650740262.01762199\n",
            "Iteration 4906, loss = 2650739451.77384949\n",
            "Iteration 4907, loss = 2650738641.14161777\n",
            "Iteration 4908, loss = 2650737830.12075233\n",
            "Iteration 4909, loss = 2650737018.71107817\n",
            "Iteration 4910, loss = 2650736206.91242504\n",
            "Iteration 4911, loss = 2650735394.72461748\n",
            "Iteration 4912, loss = 2650734582.14748287\n",
            "Iteration 4913, loss = 2650733769.18084669\n",
            "Iteration 4914, loss = 2650732955.82453585\n",
            "Iteration 4915, loss = 2650732142.07837629\n",
            "Iteration 4916, loss = 2650731327.94219446\n",
            "Iteration 4917, loss = 2650730513.41581726\n",
            "Iteration 4918, loss = 2650729698.49907017\n",
            "Iteration 4919, loss = 2650728883.19177818\n",
            "Iteration 4920, loss = 2650728067.49376774\n",
            "Iteration 4921, loss = 2650727251.40486574\n",
            "Iteration 4922, loss = 2650726434.92489719\n",
            "Iteration 4923, loss = 2650725618.05368710\n",
            "Iteration 4924, loss = 2650724800.79106283\n",
            "Iteration 4925, loss = 2650723983.13684845\n",
            "Iteration 4926, loss = 2650723165.09087038\n",
            "Iteration 4927, loss = 2650722346.65295219\n",
            "Iteration 4928, loss = 2650721527.82292175\n",
            "Iteration 4929, loss = 2650720708.60060263\n",
            "Iteration 4930, loss = 2650719888.98582172\n",
            "Iteration 4931, loss = 2650719068.97840261\n",
            "Iteration 4932, loss = 2650718248.57817173\n",
            "Iteration 4933, loss = 2650717427.78495216\n",
            "Iteration 4934, loss = 2650716606.59857082\n",
            "Iteration 4935, loss = 2650715785.01885176\n",
            "Iteration 4936, loss = 2650714963.04561853\n",
            "Iteration 4937, loss = 2650714140.67869854\n",
            "Iteration 4938, loss = 2650713317.91791439\n",
            "Iteration 4939, loss = 2650712494.76309204\n",
            "Iteration 4940, loss = 2650711671.21405458\n",
            "Iteration 4941, loss = 2650710847.27062798\n",
            "Iteration 4942, loss = 2650710022.93263578\n",
            "Iteration 4943, loss = 2650709198.19990253\n",
            "Iteration 4944, loss = 2650708373.07225132\n",
            "Iteration 4945, loss = 2650707547.54950857\n",
            "Iteration 4946, loss = 2650706721.63149738\n",
            "Iteration 4947, loss = 2650705895.31804037\n",
            "Iteration 4948, loss = 2650705068.60896397\n",
            "Iteration 4949, loss = 2650704241.50409031\n",
            "Iteration 4950, loss = 2650703414.00324392\n",
            "Iteration 4951, loss = 2650702586.10624886\n",
            "Iteration 4952, loss = 2650701757.81292868\n",
            "Iteration 4953, loss = 2650700929.12310505\n",
            "Iteration 4954, loss = 2650700100.03660536\n",
            "Iteration 4955, loss = 2650699270.55324984\n",
            "Iteration 4956, loss = 2650698440.67286396\n",
            "Iteration 4957, loss = 2650697610.39526892\n",
            "Iteration 4958, loss = 2650696779.72029018\n",
            "Iteration 4959, loss = 2650695948.64774990\n",
            "Iteration 4960, loss = 2650695117.17747021\n",
            "Iteration 4961, loss = 2650694285.30927706\n",
            "Iteration 4962, loss = 2650693453.04299116\n",
            "Iteration 4963, loss = 2650692620.37843561\n",
            "Iteration 4964, loss = 2650691787.31543398\n",
            "Iteration 4965, loss = 2650690953.85380793\n",
            "Iteration 4966, loss = 2650690119.99338245\n",
            "Iteration 4967, loss = 2650689285.73397732\n",
            "Iteration 4968, loss = 2650688451.07541704\n",
            "Iteration 4969, loss = 2650687616.01752377\n",
            "Iteration 4970, loss = 2650686780.56012058\n",
            "Iteration 4971, loss = 2650685944.70302820\n",
            "Iteration 4972, loss = 2650685108.44607019\n",
            "Iteration 4973, loss = 2650684271.78906822\n",
            "Iteration 4974, loss = 2650683434.73184490\n",
            "Iteration 4975, loss = 2650682597.27422190\n",
            "Iteration 4976, loss = 2650681759.41602087\n",
            "Iteration 4977, loss = 2650680921.15706444\n",
            "Iteration 4978, loss = 2650680082.49717474\n",
            "Iteration 4979, loss = 2650679243.43617344\n",
            "Iteration 4980, loss = 2650678403.97388124\n",
            "Iteration 4981, loss = 2650677564.11012125\n",
            "Iteration 4982, loss = 2650676723.84471369\n",
            "Iteration 4983, loss = 2650675883.17748260\n",
            "Iteration 4984, loss = 2650675042.10824537\n",
            "Iteration 4985, loss = 2650674200.63682747\n",
            "Iteration 4986, loss = 2650673358.76304722\n",
            "Iteration 4987, loss = 2650672516.48672771\n",
            "Iteration 4988, loss = 2650671673.80769014\n",
            "Iteration 4989, loss = 2650670830.72575378\n",
            "Iteration 4990, loss = 2650669987.24074268\n",
            "Iteration 4991, loss = 2650669143.35247278\n",
            "Iteration 4992, loss = 2650668299.06077147\n",
            "Iteration 4993, loss = 2650667454.36545515\n",
            "Iteration 4994, loss = 2650666609.26634455\n",
            "Iteration 4995, loss = 2650665763.76326370\n",
            "Iteration 4996, loss = 2650664917.85603046\n",
            "Iteration 4997, loss = 2650664071.54446554\n",
            "Iteration 4998, loss = 2650663224.82838917\n",
            "Iteration 4999, loss = 2650662377.70762396\n",
            "Iteration 5000, loss = 2650661530.18198872\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Igor\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(hidden_layer_sizes=(10, 5), max_iter=5000, random_state=20,\n",
              "             validation_fraction=0.2, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.neural_network.MLPRegressor.html\">?<span>Documentation for MLPRegressor</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPRegressor(hidden_layer_sizes=(10, 5), max_iter=5000, random_state=20,\n",
              "             validation_fraction=0.2, verbose=True)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(10, 5), max_iter=5000, random_state=20,\n",
              "             validation_fraction=0.2, verbose=True)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c_jOfFs6pz8A"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(modelo.loss_curve_)\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ie7Czj49dESt"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados de treinamento\n",
            "r2: 0.03532595062344501\n",
            "MAE: 50594.41213548546\n",
            "MSE: 5301321364.501808\n",
            "RMSE: 72810.17349589142\n"
          ]
        }
      ],
      "source": [
        "print('Dados de treinamento')\n",
        "\n",
        "predicao = modelo.predict(X_train)\n",
        "\n",
        "print('r2:', metrics.r2_score(y_train, predicao))\n",
        "print('MAE:', metrics.mean_absolute_error(y_train, predicao))\n",
        "print('MSE:', metrics.mean_squared_error(y_train, predicao))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_train, predicao)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "L3UPD1qQqmCH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dados de teste\n",
            "r2: -0.02446083379879016\n",
            "MAE: 60121.60739473957\n",
            "MSE: 16303125019.790754\n",
            "RMSE: 127683.69128354159\n"
          ]
        }
      ],
      "source": [
        "print('Dados de teste')\n",
        "\n",
        "predicao = modelo.predict(X_test)\n",
        "\n",
        "print('r2:', metrics.r2_score(y_test, predicao))\n",
        "print('MAE:', metrics.mean_absolute_error(y_test, predicao))\n",
        "print('MSE:', metrics.mean_squared_error(y_test, predicao))\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, predicao)))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
